{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import ShuffleSplit, GridSearchCV\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(span = 5):\n",
    "    path = os.path.abspath(f'../../data/dataset/women/{span}span_training_set.csv')\n",
    "    training_df = pd.read_csv(path)\n",
    "\n",
    "    path = os.path.abspath(f'../../data/dataset/women/{span}span_testing_set.csv')\n",
    "    testing_df = pd.read_csv(path)\n",
    "\n",
    "    train_true, test_true = training_df.pop('Win'), testing_df.pop('Win')\n",
    "\n",
    "    print(f'{len(training_df)} train examples')\n",
    "    print(f'{len(testing_df)} test examples')\n",
    "\n",
    "    return training_df, testing_df, train_true, test_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(estimator, param_grid, training_df, train_true, n_splits = 5):\n",
    "    # Create the grid search object\n",
    "    grid_search = GridSearchCV(estimator, param_grid, cv=ShuffleSplit(n_splits), verbose=5)\n",
    "\n",
    "    # Fit the grid search to the data\n",
    "    grid_search.fit(training_df, train_true)\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(clf, testing_df, test_true):\n",
    "    y_pred = clf.predict(testing_df)\n",
    "\n",
    "    accuracy = accuracy_score(test_true, y_pred)\n",
    "    print(f\"Accuracy: {(accuracy*100):.2f}\")\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(test_true, y_pred))\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(test_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename):\n",
    "    path = os.path.abspath(f'../model/womens/{filename}')\n",
    "    pickle.dump(model, open(path, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPANS = [3, 5, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_save(estimator, param_grid, filename, spans = [3, 5, 7], n_splits = 5):\n",
    "    for span in spans:\n",
    "        print(f'----- Span: {span} -----')\n",
    "        \n",
    "        training_df, testing_df, train_true, test_true = get_datasets(span)\n",
    "        clf = train_model(estimator, param_grid, training_df, train_true, n_splits)\n",
    "        test_model(clf, testing_df, test_true)\n",
    "        save_model(clf, f'{span}span_{filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Span: 3 -----\n",
      "12390 train examples\n",
      "5310 test examples\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[CV 1/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.706 total time=   0.8s\n",
      "[CV 2/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.704 total time=   0.7s\n",
      "[CV 3/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.719 total time=   1.0s\n",
      "[CV 4/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.726 total time=   0.8s\n",
      "[CV 5/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.730 total time=   0.9s\n",
      "[CV 1/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.705 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.704 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.718 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.726 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.710 total time=   2.5s\n",
      "[CV 2/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.712 total time=   2.3s\n",
      "[CV 3/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.714 total time=   2.2s\n",
      "[CV 4/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.721 total time=   1.8s\n",
      "[CV 5/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.729 total time=   2.0s\n",
      "[CV 1/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.713 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.713 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.714 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.720 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.728 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.713 total time=   5.3s\n",
      "[CV 2/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.712 total time=   5.4s\n",
      "[CV 3/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.713 total time=   5.5s\n",
      "[CV 4/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.714 total time=   4.9s\n",
      "[CV 5/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.727 total time=   5.7s\n",
      "[CV 1/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.713 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.713 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.713 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.714 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.714 total time=  12.9s\n",
      "[CV 2/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.709 total time=  13.3s\n",
      "[CV 3/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.716 total time=  11.6s\n",
      "[CV 4/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.716 total time=  12.5s\n",
      "[CV 5/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.729 total time=  12.2s\n",
      "[CV 1/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.713 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.709 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.717 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.716 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.730 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.710 total time=  16.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.706 total time=  18.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.716 total time=  17.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.716 total time=  17.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.731 total time=  16.9s\n",
      "[CV 1/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.711 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.705 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.716 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.713 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.728 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.709 total time=  17.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.706 total time=  18.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.716 total time=  17.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.713 total time=  17.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.731 total time=  18.4s\n",
      "[CV 1/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.712 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.702 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.716 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.730 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.710 total time=  17.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.707 total time=  17.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.718 total time=  17.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.712 total time=  17.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.731 total time=  17.4s\n",
      "[CV 1/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.711 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.702 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.706 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.714 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.730 total time=   0.0s\n",
      "Best hyperparameters: {'C': 0.01, 'max_iter': 100000000000, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n",
      "Accuracy: 72.86\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.62      0.66      2199\n",
      "           1       0.75      0.80      0.78      3111\n",
      "\n",
      "    accuracy                           0.73      5310\n",
      "   macro avg       0.72      0.71      0.72      5310\n",
      "weighted avg       0.73      0.73      0.73      5310\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1370  829]\n",
      " [ 612 2499]]\n",
      "----- Span: 5 -----\n",
      "11282 train examples\n",
      "4836 test examples\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[CV 1/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.709 total time=   0.8s\n",
      "[CV 2/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.711 total time=   0.5s\n",
      "[CV 3/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.721 total time=   0.5s\n",
      "[CV 4/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.709 total time=   0.5s\n",
      "[CV 5/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.738 total time=   0.4s\n",
      "[CV 1/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.710 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.713 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.719 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.709 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.739 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.709 total time=   1.6s\n",
      "[CV 2/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.710 total time=   1.5s\n",
      "[CV 3/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.732 total time=   1.5s\n",
      "[CV 4/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.705 total time=   1.7s\n",
      "[CV 5/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.744 total time=   1.4s\n",
      "[CV 1/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.709 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.709 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.732 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.704 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.742 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.705 total time=   3.4s\n",
      "[CV 2/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.712 total time=   3.8s\n",
      "[CV 3/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.732 total time=   3.8s\n",
      "[CV 4/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.702 total time=   3.9s\n",
      "[CV 5/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.750 total time=   3.9s\n",
      "[CV 1/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.705 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.711 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.733 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.699 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.749 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.700 total time=   9.7s\n",
      "[CV 2/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.709 total time=   9.2s\n",
      "[CV 3/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.726 total time=   8.4s\n",
      "[CV 4/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.703 total time=   9.5s\n",
      "[CV 5/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.748 total time=   8.1s\n",
      "[CV 1/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.709 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.725 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.701 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.748 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.701 total time=  14.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.713 total time=  14.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.725 total time=  13.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.702 total time=  13.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.749 total time=  13.6s\n",
      "[CV 1/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.713 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.720 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.702 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.749 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.697 total time=  13.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.713 total time=  14.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.722 total time=  14.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.701 total time=  13.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.748 total time=  13.4s\n",
      "[CV 1/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.706 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.708 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.726 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.701 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.747 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.702 total time=  14.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.712 total time=  15.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.722 total time=  15.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.704 total time=  14.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.749 total time=  14.1s\n",
      "[CV 1/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.709 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.704 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.721 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.699 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.752 total time=   0.0s\n",
      "Best hyperparameters: {'C': 0.1, 'max_iter': 100000000000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Accuracy: 72.91\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.62      0.65      1992\n",
      "           1       0.75      0.81      0.78      2844\n",
      "\n",
      "    accuracy                           0.73      4836\n",
      "   macro avg       0.72      0.71      0.72      4836\n",
      "weighted avg       0.73      0.73      0.73      4836\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1235  757]\n",
      " [ 553 2291]]\n",
      "----- Span: 7 -----\n",
      "10200 train examples\n",
      "4372 test examples\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[CV 1/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.716 total time=   0.4s\n",
      "[CV 2/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.717 total time=   0.5s\n",
      "[CV 3/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.733 total time=   0.4s\n",
      "[CV 4/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.745 total time=   0.3s\n",
      "[CV 5/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.701 total time=   0.4s\n",
      "[CV 1/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.716 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.717 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.733 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.745 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.702 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.715 total time=   1.3s\n",
      "[CV 2/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.722 total time=   1.3s\n",
      "[CV 3/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.734 total time=   1.2s\n",
      "[CV 4/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.749 total time=   1.1s\n",
      "[CV 5/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.698 total time=   1.0s\n",
      "[CV 1/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.715 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.722 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.733 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.749 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.698 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.711 total time=   2.9s\n",
      "[CV 2/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.722 total time=   3.0s\n",
      "[CV 3/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.727 total time=   3.0s\n",
      "[CV 4/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.751 total time=   3.1s\n",
      "[CV 5/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.699 total time=   2.8s\n",
      "[CV 1/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.711 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.724 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.728 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.753 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.698 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.718 total time=   7.2s\n",
      "[CV 2/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.725 total time=   6.7s\n",
      "[CV 3/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.729 total time=   8.2s\n",
      "[CV 4/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.749 total time=   5.8s\n",
      "[CV 5/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.700 total time=   8.0s\n",
      "[CV 1/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.720 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.725 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.728 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.700 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.723 total time=  11.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.721 total time=  11.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.728 total time=  11.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.751 total time=  10.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.700 total time=  10.2s\n",
      "[CV 1/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.726 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.720 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.731 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.746 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.703 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.725 total time=  11.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.718 total time=  11.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.732 total time=  11.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.752 total time=  11.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.703 total time=  10.5s\n",
      "[CV 1/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.724 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.718 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.735 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.704 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.725 total time=  10.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.720 total time=   9.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.728 total time=  10.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.751 total time=  11.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.709 total time=  12.0s\n",
      "[CV 1/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.729 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.720 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.732 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.748 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.708 total time=   0.0s\n",
      "Best hyperparameters: {'C': 1000, 'max_iter': 100000000000, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n",
      "Accuracy: 73.10\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.62      0.66      1829\n",
      "           1       0.75      0.81      0.78      2543\n",
      "\n",
      "    accuracy                           0.73      4372\n",
      "   macro avg       0.72      0.72      0.72      4372\n",
      "weighted avg       0.73      0.73      0.73      4372\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1142  687]\n",
      " [ 489 2054]]\n"
     ]
    }
   ],
   "source": [
    "# Define the Logistic Regression model\n",
    "logreg_model = LogisticRegression()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'penalty': ['l2'],  # Vary the regularization type\n",
    "    'solver': ['lbfgs', 'newton-cholesky'],\n",
    "    'max_iter': [int(10e10)]\n",
    "}\n",
    "\n",
    "filename = 'logistic_regression_model.pkl'\n",
    "\n",
    "train_test_save(logreg_model, param_grid, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Span: 3 -----\n",
      "12390 train examples\n",
      "5310 test examples\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "[CV 1/1] END C=0.01, gamma=0.1, kernel=linear, probability=True;, score=0.724 total time= 1.5min\n",
      "Best hyperparameters: {'C': 0.01, 'gamma': 0.1, 'kernel': 'linear', 'probability': True}\n",
      "Accuracy: 73.03\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.62      0.66      2199\n",
      "           1       0.75      0.81      0.78      3111\n",
      "\n",
      "    accuracy                           0.73      5310\n",
      "   macro avg       0.72      0.71      0.72      5310\n",
      "weighted avg       0.73      0.73      0.73      5310\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1370  829]\n",
      " [ 603 2508]]\n",
      "----- Span: 5 -----\n",
      "11282 train examples\n",
      "4836 test examples\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "[CV 1/1] END C=0.01, gamma=0.1, kernel=linear, probability=True;, score=0.714 total time= 1.1min\n",
      "Best hyperparameters: {'C': 0.01, 'gamma': 0.1, 'kernel': 'linear', 'probability': True}\n",
      "Accuracy: 72.70\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.62      0.65      1992\n",
      "           1       0.75      0.80      0.78      2844\n",
      "\n",
      "    accuracy                           0.73      4836\n",
      "   macro avg       0.72      0.71      0.71      4836\n",
      "weighted avg       0.72      0.73      0.72      4836\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1229  763]\n",
      " [ 557 2287]]\n",
      "----- Span: 7 -----\n",
      "10200 train examples\n",
      "4372 test examples\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "[CV 1/1] END C=0.01, gamma=0.1, kernel=linear, probability=True;, score=0.729 total time=  46.0s\n",
      "Best hyperparameters: {'C': 0.01, 'gamma': 0.1, 'kernel': 'linear', 'probability': True}\n",
      "Accuracy: 73.33\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.62      0.66      1829\n",
      "           1       0.75      0.82      0.78      2543\n",
      "\n",
      "    accuracy                           0.73      4372\n",
      "   macro avg       0.73      0.72      0.72      4372\n",
      "weighted avg       0.73      0.73      0.73      4372\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1132  697]\n",
      " [ 469 2074]]\n"
     ]
    }
   ],
   "source": [
    "# Define the SVM model\n",
    "svm_model = SVC()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "# param_grid = {\n",
    "#     'C': [0.01, 0.1, 1, 10],\n",
    "#     'kernel': ['linear', 'rbf', 'sigmoid'],\n",
    "#     'gamma': [0.1, 0.01, 0.001],\n",
    "#     # 'probability': [True]\n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01],\n",
    "    'kernel': ['linear'],\n",
    "    'gamma': [0.1],\n",
    "    'probability': [True]\n",
    "}\n",
    "\n",
    "filename = 'support_vector_machine_model.pkl'\n",
    "\n",
    "train_test_save(svm_model, param_grid, filename, n_splits=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Span: 3 -----\n",
      "12390 train examples\n",
      "5310 test examples\n",
      "Fitting 1 folds for each of 240 candidates, totalling 240 fits\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=1, p=1, weights=uniform;, score=0.628 total time=   0.5s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=1, p=1, weights=distance;, score=0.628 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=1, p=2, weights=uniform;, score=0.621 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=1, p=2, weights=distance;, score=0.621 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.662 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=3, p=1, weights=distance;, score=0.661 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.662 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=3, p=2, weights=distance;, score=0.662 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.671 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=5, p=1, weights=distance;, score=0.671 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.686 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=5, p=2, weights=distance;, score=0.686 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.677 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=7, p=1, weights=distance;, score=0.678 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.690 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=7, p=2, weights=distance;, score=0.690 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=10, p=1, weights=uniform;, score=0.690 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=10, p=1, weights=distance;, score=0.698 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=10, p=2, weights=uniform;, score=0.695 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=10, p=2, weights=distance;, score=0.696 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=1, p=1, weights=uniform;, score=0.628 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=1, p=1, weights=distance;, score=0.628 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=1, p=2, weights=uniform;, score=0.621 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=1, p=2, weights=distance;, score=0.621 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.662 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=3, p=1, weights=distance;, score=0.661 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.662 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=3, p=2, weights=distance;, score=0.662 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.671 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=5, p=1, weights=distance;, score=0.671 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.686 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=5, p=2, weights=distance;, score=0.686 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.677 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=7, p=1, weights=distance;, score=0.678 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.690 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=7, p=2, weights=distance;, score=0.690 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=10, p=1, weights=uniform;, score=0.690 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=10, p=1, weights=distance;, score=0.698 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=10, p=2, weights=uniform;, score=0.695 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=10, p=2, weights=distance;, score=0.696 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=1, p=1, weights=uniform;, score=0.628 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=1, p=1, weights=distance;, score=0.628 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=1, p=2, weights=uniform;, score=0.621 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=1, p=2, weights=distance;, score=0.621 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.662 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=3, p=1, weights=distance;, score=0.661 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.662 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=3, p=2, weights=distance;, score=0.662 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.671 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=5, p=1, weights=distance;, score=0.671 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.686 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=5, p=2, weights=distance;, score=0.686 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.677 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=7, p=1, weights=distance;, score=0.678 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.690 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=7, p=2, weights=distance;, score=0.690 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=10, p=1, weights=uniform;, score=0.690 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=10, p=1, weights=distance;, score=0.698 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=10, p=2, weights=uniform;, score=0.695 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=10, p=2, weights=distance;, score=0.696 total time=   0.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=1, p=1, weights=uniform;, score=0.628 total time=   3.5s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=1, p=1, weights=distance;, score=0.628 total time=   3.4s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=1, p=2, weights=uniform;, score=0.621 total time=   3.4s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=1, p=2, weights=distance;, score=0.621 total time=   3.4s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.662 total time=   3.5s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=3, p=1, weights=distance;, score=0.661 total time=   3.4s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.662 total time=   3.4s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=3, p=2, weights=distance;, score=0.662 total time=   3.4s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.671 total time=   3.5s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=5, p=1, weights=distance;, score=0.671 total time=   3.4s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.686 total time=   3.5s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=5, p=2, weights=distance;, score=0.686 total time=   3.6s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.677 total time=   3.5s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=7, p=1, weights=distance;, score=0.678 total time=   3.5s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.690 total time=   3.4s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=7, p=2, weights=distance;, score=0.690 total time=   3.4s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=10, p=1, weights=uniform;, score=0.690 total time=   3.5s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=10, p=1, weights=distance;, score=0.698 total time=   3.5s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=10, p=2, weights=uniform;, score=0.695 total time=   3.5s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=10, p=2, weights=distance;, score=0.696 total time=   3.4s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=1, p=1, weights=uniform;, score=0.628 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=1, p=1, weights=distance;, score=0.628 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=1, p=2, weights=uniform;, score=0.621 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=1, p=2, weights=distance;, score=0.621 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.662 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=3, p=1, weights=distance;, score=0.661 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.662 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=3, p=2, weights=distance;, score=0.662 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.671 total time=   3.4s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=5, p=1, weights=distance;, score=0.671 total time=   3.4s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.686 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=5, p=2, weights=distance;, score=0.686 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.677 total time=   3.5s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=7, p=1, weights=distance;, score=0.678 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.690 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=7, p=2, weights=distance;, score=0.690 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=10, p=1, weights=uniform;, score=0.690 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=10, p=1, weights=distance;, score=0.698 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=10, p=2, weights=uniform;, score=0.695 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=10, p=2, weights=distance;, score=0.696 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=1, p=1, weights=uniform;, score=0.628 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=1, p=1, weights=distance;, score=0.628 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=1, p=2, weights=uniform;, score=0.621 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=1, p=2, weights=distance;, score=0.621 total time=   3.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.662 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=3, p=1, weights=distance;, score=0.661 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.662 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=3, p=2, weights=distance;, score=0.662 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.671 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=5, p=1, weights=distance;, score=0.671 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.686 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=5, p=2, weights=distance;, score=0.686 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.677 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=7, p=1, weights=distance;, score=0.678 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.690 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=7, p=2, weights=distance;, score=0.690 total time=   3.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=10, p=1, weights=uniform;, score=0.690 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=10, p=1, weights=distance;, score=0.698 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=10, p=2, weights=uniform;, score=0.695 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=10, p=2, weights=distance;, score=0.696 total time=   3.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=1, p=1, weights=uniform;, score=0.628 total time=   4.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=1, p=1, weights=distance;, score=0.628 total time=   4.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=1, p=2, weights=uniform;, score=0.621 total time=   5.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=1, p=2, weights=distance;, score=0.621 total time=   5.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.662 total time=   4.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=3, p=1, weights=distance;, score=0.661 total time=   4.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.662 total time=   5.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=3, p=2, weights=distance;, score=0.662 total time=   5.3s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.671 total time=   4.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=5, p=1, weights=distance;, score=0.671 total time=   4.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.686 total time=   5.3s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=5, p=2, weights=distance;, score=0.686 total time=   5.3s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.677 total time=   4.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=7, p=1, weights=distance;, score=0.678 total time=   4.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.690 total time=   5.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=7, p=2, weights=distance;, score=0.690 total time=   5.3s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=10, p=1, weights=uniform;, score=0.690 total time=   4.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=10, p=1, weights=distance;, score=0.698 total time=   4.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=10, p=2, weights=uniform;, score=0.695 total time=   5.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=10, p=2, weights=distance;, score=0.696 total time=   5.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=1, p=1, weights=uniform;, score=0.628 total time=   3.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=1, p=1, weights=distance;, score=0.628 total time=   3.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=1, p=2, weights=uniform;, score=0.621 total time=   3.9s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=1, p=2, weights=distance;, score=0.621 total time=   3.9s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.662 total time=   3.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=3, p=1, weights=distance;, score=0.661 total time=   3.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.662 total time=   4.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=3, p=2, weights=distance;, score=0.662 total time=   4.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.671 total time=   3.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=5, p=1, weights=distance;, score=0.671 total time=   3.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.686 total time=   4.3s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=5, p=2, weights=distance;, score=0.686 total time=   4.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.677 total time=   3.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=7, p=1, weights=distance;, score=0.678 total time=   3.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.690 total time=   4.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=7, p=2, weights=distance;, score=0.690 total time=   4.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=10, p=1, weights=uniform;, score=0.690 total time=   3.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=10, p=1, weights=distance;, score=0.698 total time=   3.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=10, p=2, weights=uniform;, score=0.695 total time=   4.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=10, p=2, weights=distance;, score=0.696 total time=   4.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=1, p=1, weights=uniform;, score=0.628 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=1, p=1, weights=distance;, score=0.628 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=1, p=2, weights=uniform;, score=0.621 total time=   3.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=1, p=2, weights=distance;, score=0.621 total time=   3.5s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.662 total time=   3.5s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=3, p=1, weights=distance;, score=0.661 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.662 total time=   3.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=3, p=2, weights=distance;, score=0.662 total time=   3.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.671 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=5, p=1, weights=distance;, score=0.671 total time=   3.5s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.686 total time=   3.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=5, p=2, weights=distance;, score=0.686 total time=   3.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.677 total time=   3.5s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=7, p=1, weights=distance;, score=0.678 total time=   3.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.690 total time=   3.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=7, p=2, weights=distance;, score=0.690 total time=   3.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=10, p=1, weights=uniform;, score=0.690 total time=   3.5s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=10, p=1, weights=distance;, score=0.698 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=10, p=2, weights=uniform;, score=0.695 total time=   3.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=10, p=2, weights=distance;, score=0.696 total time=   3.6s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=1, p=1, weights=uniform;, score=0.628 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=1, p=1, weights=distance;, score=0.628 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=1, p=2, weights=uniform;, score=0.621 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=1, p=2, weights=distance;, score=0.621 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.662 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=3, p=1, weights=distance;, score=0.661 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.662 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=3, p=2, weights=distance;, score=0.662 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.671 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=5, p=1, weights=distance;, score=0.671 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.686 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=5, p=2, weights=distance;, score=0.686 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.677 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=7, p=1, weights=distance;, score=0.678 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.690 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=7, p=2, weights=distance;, score=0.690 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=10, p=1, weights=uniform;, score=0.690 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=10, p=1, weights=distance;, score=0.698 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=10, p=2, weights=uniform;, score=0.695 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=10, p=2, weights=distance;, score=0.696 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=1, p=1, weights=uniform;, score=0.628 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=1, p=1, weights=distance;, score=0.628 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=1, p=2, weights=uniform;, score=0.621 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=1, p=2, weights=distance;, score=0.621 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.662 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=3, p=1, weights=distance;, score=0.661 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.662 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=3, p=2, weights=distance;, score=0.662 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.671 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=5, p=1, weights=distance;, score=0.671 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.686 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=5, p=2, weights=distance;, score=0.686 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.677 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=7, p=1, weights=distance;, score=0.678 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.690 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=7, p=2, weights=distance;, score=0.690 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=10, p=1, weights=uniform;, score=0.690 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=10, p=1, weights=distance;, score=0.698 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=10, p=2, weights=uniform;, score=0.695 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=10, p=2, weights=distance;, score=0.696 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=1, p=1, weights=uniform;, score=0.628 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=1, p=1, weights=distance;, score=0.628 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=1, p=2, weights=uniform;, score=0.621 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=1, p=2, weights=distance;, score=0.621 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.662 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=3, p=1, weights=distance;, score=0.661 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.662 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=3, p=2, weights=distance;, score=0.662 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.671 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=5, p=1, weights=distance;, score=0.671 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.686 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=5, p=2, weights=distance;, score=0.686 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.677 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=7, p=1, weights=distance;, score=0.678 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.690 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=7, p=2, weights=distance;, score=0.690 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=10, p=1, weights=uniform;, score=0.690 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=10, p=1, weights=distance;, score=0.698 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=10, p=2, weights=uniform;, score=0.695 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=10, p=2, weights=distance;, score=0.696 total time=   0.0s\n",
      "Best hyperparameters: {'algorithm': 'auto', 'leaf_size': 15, 'n_neighbors': 10, 'p': 1, 'weights': 'distance'}\n",
      "Accuracy: 67.97\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.56      0.59      2199\n",
      "           1       0.71      0.77      0.74      3111\n",
      "\n",
      "    accuracy                           0.68      5310\n",
      "   macro avg       0.67      0.66      0.66      5310\n",
      "weighted avg       0.68      0.68      0.68      5310\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1225  974]\n",
      " [ 727 2384]]\n",
      "----- Span: 5 -----\n",
      "11282 train examples\n",
      "4836 test examples\n",
      "Fitting 1 folds for each of 240 candidates, totalling 240 fits\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=1, p=1, weights=uniform;, score=0.605 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=1, p=1, weights=distance;, score=0.605 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=1, p=2, weights=uniform;, score=0.617 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=1, p=2, weights=distance;, score=0.617 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.645 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=3, p=1, weights=distance;, score=0.646 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.656 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=3, p=2, weights=distance;, score=0.655 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.672 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=5, p=1, weights=distance;, score=0.676 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.654 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=5, p=2, weights=distance;, score=0.654 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.663 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=7, p=1, weights=distance;, score=0.663 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.665 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=7, p=2, weights=distance;, score=0.666 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=10, p=1, weights=uniform;, score=0.662 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=10, p=1, weights=distance;, score=0.665 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=10, p=2, weights=uniform;, score=0.658 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=10, p=2, weights=distance;, score=0.672 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=1, p=1, weights=uniform;, score=0.605 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=1, p=1, weights=distance;, score=0.605 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=1, p=2, weights=uniform;, score=0.617 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=1, p=2, weights=distance;, score=0.617 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.645 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=3, p=1, weights=distance;, score=0.646 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.656 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=3, p=2, weights=distance;, score=0.655 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.672 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=5, p=1, weights=distance;, score=0.676 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.654 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=5, p=2, weights=distance;, score=0.654 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.663 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=7, p=1, weights=distance;, score=0.663 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.665 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=7, p=2, weights=distance;, score=0.666 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=10, p=1, weights=uniform;, score=0.662 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=10, p=1, weights=distance;, score=0.665 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=10, p=2, weights=uniform;, score=0.658 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=10, p=2, weights=distance;, score=0.672 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=1, p=1, weights=uniform;, score=0.605 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=1, p=1, weights=distance;, score=0.605 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=1, p=2, weights=uniform;, score=0.617 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=1, p=2, weights=distance;, score=0.617 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.645 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=3, p=1, weights=distance;, score=0.646 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.656 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=3, p=2, weights=distance;, score=0.655 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.672 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=5, p=1, weights=distance;, score=0.676 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.654 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=5, p=2, weights=distance;, score=0.654 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.663 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=7, p=1, weights=distance;, score=0.663 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.665 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=7, p=2, weights=distance;, score=0.666 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=10, p=1, weights=uniform;, score=0.662 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=10, p=1, weights=distance;, score=0.665 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=10, p=2, weights=uniform;, score=0.658 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=10, p=2, weights=distance;, score=0.672 total time=   0.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=1, p=1, weights=uniform;, score=0.605 total time=   3.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=1, p=1, weights=distance;, score=0.605 total time=   2.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=1, p=2, weights=uniform;, score=0.617 total time=   2.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=1, p=2, weights=distance;, score=0.617 total time=   3.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.645 total time=   2.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=3, p=1, weights=distance;, score=0.646 total time=   2.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.656 total time=   3.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=3, p=2, weights=distance;, score=0.655 total time=   2.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.672 total time=   2.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=5, p=1, weights=distance;, score=0.676 total time=   2.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.654 total time=   2.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=5, p=2, weights=distance;, score=0.654 total time=   2.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.663 total time=   2.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=7, p=1, weights=distance;, score=0.663 total time=   2.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.665 total time=   2.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=7, p=2, weights=distance;, score=0.666 total time=   2.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=10, p=1, weights=uniform;, score=0.662 total time=   2.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=10, p=1, weights=distance;, score=0.665 total time=   2.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=10, p=2, weights=uniform;, score=0.658 total time=   2.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=10, p=2, weights=distance;, score=0.672 total time=   2.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=1, p=1, weights=uniform;, score=0.605 total time=   2.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=1, p=1, weights=distance;, score=0.605 total time=   2.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=1, p=2, weights=uniform;, score=0.617 total time=   2.6s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=1, p=2, weights=distance;, score=0.617 total time=   2.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.645 total time=   2.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=3, p=1, weights=distance;, score=0.646 total time=   2.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.656 total time=   2.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=3, p=2, weights=distance;, score=0.655 total time=   2.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.672 total time=   2.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=5, p=1, weights=distance;, score=0.676 total time=   2.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.654 total time=   2.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=5, p=2, weights=distance;, score=0.654 total time=   2.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.663 total time=   2.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=7, p=1, weights=distance;, score=0.663 total time=   2.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.665 total time=   2.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=7, p=2, weights=distance;, score=0.666 total time=   2.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=10, p=1, weights=uniform;, score=0.662 total time=   2.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=10, p=1, weights=distance;, score=0.665 total time=   2.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=10, p=2, weights=uniform;, score=0.658 total time=   2.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=10, p=2, weights=distance;, score=0.672 total time=   2.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=1, p=1, weights=uniform;, score=0.605 total time=   2.6s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=1, p=1, weights=distance;, score=0.605 total time=   2.6s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=1, p=2, weights=uniform;, score=0.617 total time=   2.6s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=1, p=2, weights=distance;, score=0.617 total time=   2.5s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.645 total time=   2.6s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=3, p=1, weights=distance;, score=0.646 total time=   2.6s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.656 total time=   2.6s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=3, p=2, weights=distance;, score=0.655 total time=   2.5s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.672 total time=   2.6s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=5, p=1, weights=distance;, score=0.676 total time=   2.6s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.654 total time=   2.6s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=5, p=2, weights=distance;, score=0.654 total time=   2.6s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.663 total time=   2.6s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=7, p=1, weights=distance;, score=0.663 total time=   2.6s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.665 total time=   2.6s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=7, p=2, weights=distance;, score=0.666 total time=   2.6s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=10, p=1, weights=uniform;, score=0.662 total time=   2.6s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=10, p=1, weights=distance;, score=0.665 total time=   2.6s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=10, p=2, weights=uniform;, score=0.658 total time=   2.6s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=10, p=2, weights=distance;, score=0.672 total time=   2.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=1, p=1, weights=uniform;, score=0.605 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=1, p=1, weights=distance;, score=0.605 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=1, p=2, weights=uniform;, score=0.617 total time=   4.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=1, p=2, weights=distance;, score=0.617 total time=   4.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.645 total time=   3.5s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=3, p=1, weights=distance;, score=0.646 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.656 total time=   4.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=3, p=2, weights=distance;, score=0.655 total time=   4.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.672 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=5, p=1, weights=distance;, score=0.676 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.654 total time=   4.5s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=5, p=2, weights=distance;, score=0.654 total time=   4.5s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.663 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=7, p=1, weights=distance;, score=0.663 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.665 total time=   4.5s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=7, p=2, weights=distance;, score=0.666 total time=   4.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=10, p=1, weights=uniform;, score=0.662 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=10, p=1, weights=distance;, score=0.665 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=10, p=2, weights=uniform;, score=0.658 total time=   4.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=10, p=2, weights=distance;, score=0.672 total time=   4.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=1, p=1, weights=uniform;, score=0.605 total time=   3.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=1, p=1, weights=distance;, score=0.605 total time=   3.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=1, p=2, weights=uniform;, score=0.617 total time=   3.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=1, p=2, weights=distance;, score=0.617 total time=   3.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.645 total time=   3.3s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=3, p=1, weights=distance;, score=0.646 total time=   3.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.656 total time=   3.9s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=3, p=2, weights=distance;, score=0.655 total time=   4.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.672 total time=   3.5s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=5, p=1, weights=distance;, score=0.676 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.654 total time=   3.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=5, p=2, weights=distance;, score=0.654 total time=   3.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.663 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=7, p=1, weights=distance;, score=0.663 total time=   3.3s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.665 total time=   3.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=7, p=2, weights=distance;, score=0.666 total time=   3.9s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=10, p=1, weights=uniform;, score=0.662 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=10, p=1, weights=distance;, score=0.665 total time=   3.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=10, p=2, weights=uniform;, score=0.658 total time=   3.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=10, p=2, weights=distance;, score=0.672 total time=   3.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=1, p=1, weights=uniform;, score=0.605 total time=   3.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=1, p=1, weights=distance;, score=0.605 total time=   3.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=1, p=2, weights=uniform;, score=0.617 total time=   3.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=1, p=2, weights=distance;, score=0.617 total time=   3.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.645 total time=   2.9s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=3, p=1, weights=distance;, score=0.646 total time=   2.9s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.656 total time=   3.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=3, p=2, weights=distance;, score=0.655 total time=   3.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.672 total time=   2.9s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=5, p=1, weights=distance;, score=0.676 total time=   3.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.654 total time=   3.3s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=5, p=2, weights=distance;, score=0.654 total time=   3.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.663 total time=   3.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=7, p=1, weights=distance;, score=0.663 total time=   2.9s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.665 total time=   3.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=7, p=2, weights=distance;, score=0.666 total time=   3.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=10, p=1, weights=uniform;, score=0.662 total time=   2.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=10, p=1, weights=distance;, score=0.665 total time=   2.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=10, p=2, weights=uniform;, score=0.658 total time=   3.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=10, p=2, weights=distance;, score=0.672 total time=   3.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=1, p=1, weights=uniform;, score=0.605 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=1, p=1, weights=distance;, score=0.605 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=1, p=2, weights=uniform;, score=0.617 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=1, p=2, weights=distance;, score=0.617 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.645 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=3, p=1, weights=distance;, score=0.646 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.656 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=3, p=2, weights=distance;, score=0.655 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.672 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=5, p=1, weights=distance;, score=0.676 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.654 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=5, p=2, weights=distance;, score=0.654 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.663 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=7, p=1, weights=distance;, score=0.663 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.665 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=7, p=2, weights=distance;, score=0.666 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=10, p=1, weights=uniform;, score=0.662 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=10, p=1, weights=distance;, score=0.665 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=10, p=2, weights=uniform;, score=0.658 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=10, p=2, weights=distance;, score=0.672 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=1, p=1, weights=uniform;, score=0.605 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=1, p=1, weights=distance;, score=0.605 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=1, p=2, weights=uniform;, score=0.617 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=1, p=2, weights=distance;, score=0.617 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.645 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=3, p=1, weights=distance;, score=0.646 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.656 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=3, p=2, weights=distance;, score=0.655 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.672 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=5, p=1, weights=distance;, score=0.676 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.654 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=5, p=2, weights=distance;, score=0.654 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.663 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=7, p=1, weights=distance;, score=0.663 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.665 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=7, p=2, weights=distance;, score=0.666 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=10, p=1, weights=uniform;, score=0.662 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=10, p=1, weights=distance;, score=0.665 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=10, p=2, weights=uniform;, score=0.658 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=10, p=2, weights=distance;, score=0.672 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=1, p=1, weights=uniform;, score=0.605 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=1, p=1, weights=distance;, score=0.605 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=1, p=2, weights=uniform;, score=0.617 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=1, p=2, weights=distance;, score=0.617 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.645 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=3, p=1, weights=distance;, score=0.646 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.656 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=3, p=2, weights=distance;, score=0.655 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.672 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=5, p=1, weights=distance;, score=0.676 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.654 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=5, p=2, weights=distance;, score=0.654 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.663 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=7, p=1, weights=distance;, score=0.663 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.665 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=7, p=2, weights=distance;, score=0.666 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=10, p=1, weights=uniform;, score=0.662 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=10, p=1, weights=distance;, score=0.665 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=10, p=2, weights=uniform;, score=0.658 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=10, p=2, weights=distance;, score=0.672 total time=   0.0s\n",
      "Best hyperparameters: {'algorithm': 'auto', 'leaf_size': 15, 'n_neighbors': 5, 'p': 1, 'weights': 'distance'}\n",
      "Accuracy: 68.32\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.58      0.60      1992\n",
      "           1       0.72      0.76      0.74      2844\n",
      "\n",
      "    accuracy                           0.68      4836\n",
      "   macro avg       0.67      0.67      0.67      4836\n",
      "weighted avg       0.68      0.68      0.68      4836\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1150  842]\n",
      " [ 690 2154]]\n",
      "----- Span: 7 -----\n",
      "10200 train examples\n",
      "4372 test examples\n",
      "Fitting 1 folds for each of 240 candidates, totalling 240 fits\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=1, p=1, weights=uniform;, score=0.644 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=1, p=1, weights=distance;, score=0.644 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=1, p=2, weights=uniform;, score=0.643 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=1, p=2, weights=distance;, score=0.643 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.661 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=3, p=1, weights=distance;, score=0.661 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.678 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=3, p=2, weights=distance;, score=0.676 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.685 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=5, p=1, weights=distance;, score=0.685 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.704 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=5, p=2, weights=distance;, score=0.701 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.696 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=7, p=1, weights=distance;, score=0.694 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.699 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=7, p=2, weights=distance;, score=0.699 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=10, p=1, weights=uniform;, score=0.707 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=10, p=1, weights=distance;, score=0.698 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=10, p=2, weights=uniform;, score=0.690 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=10, p=2, weights=distance;, score=0.702 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=1, p=1, weights=uniform;, score=0.644 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=1, p=1, weights=distance;, score=0.644 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=1, p=2, weights=uniform;, score=0.643 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=1, p=2, weights=distance;, score=0.643 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.661 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=3, p=1, weights=distance;, score=0.661 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.678 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=3, p=2, weights=distance;, score=0.676 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.685 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=5, p=1, weights=distance;, score=0.685 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.704 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=5, p=2, weights=distance;, score=0.701 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.696 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=7, p=1, weights=distance;, score=0.694 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.699 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=7, p=2, weights=distance;, score=0.699 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=10, p=1, weights=uniform;, score=0.707 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=10, p=1, weights=distance;, score=0.698 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=10, p=2, weights=uniform;, score=0.690 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=10, p=2, weights=distance;, score=0.702 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=1, p=1, weights=uniform;, score=0.644 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=1, p=1, weights=distance;, score=0.644 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=1, p=2, weights=uniform;, score=0.643 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=1, p=2, weights=distance;, score=0.643 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.661 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=3, p=1, weights=distance;, score=0.661 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.678 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=3, p=2, weights=distance;, score=0.676 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.685 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=5, p=1, weights=distance;, score=0.685 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.704 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=5, p=2, weights=distance;, score=0.701 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.696 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=7, p=1, weights=distance;, score=0.694 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.699 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=7, p=2, weights=distance;, score=0.699 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=10, p=1, weights=uniform;, score=0.707 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=10, p=1, weights=distance;, score=0.698 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=10, p=2, weights=uniform;, score=0.690 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=10, p=2, weights=distance;, score=0.702 total time=   0.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=1, p=1, weights=uniform;, score=0.644 total time=   2.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=1, p=1, weights=distance;, score=0.644 total time=   2.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=1, p=2, weights=uniform;, score=0.643 total time=   2.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=1, p=2, weights=distance;, score=0.643 total time=   2.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.661 total time=   2.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=3, p=1, weights=distance;, score=0.661 total time=   2.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.678 total time=   2.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=3, p=2, weights=distance;, score=0.676 total time=   2.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.685 total time=   2.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=5, p=1, weights=distance;, score=0.685 total time=   2.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.704 total time=   2.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=5, p=2, weights=distance;, score=0.701 total time=   2.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.696 total time=   2.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=7, p=1, weights=distance;, score=0.694 total time=   2.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.699 total time=   2.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=7, p=2, weights=distance;, score=0.699 total time=   2.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=10, p=1, weights=uniform;, score=0.707 total time=   2.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=10, p=1, weights=distance;, score=0.698 total time=   2.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=10, p=2, weights=uniform;, score=0.690 total time=   2.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=10, p=2, weights=distance;, score=0.702 total time=   2.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=1, p=1, weights=uniform;, score=0.644 total time=   2.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=1, p=1, weights=distance;, score=0.644 total time=   2.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=1, p=2, weights=uniform;, score=0.643 total time=   2.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=1, p=2, weights=distance;, score=0.643 total time=   2.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.661 total time=   2.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=3, p=1, weights=distance;, score=0.661 total time=   2.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.678 total time=   2.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=3, p=2, weights=distance;, score=0.676 total time=   2.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.685 total time=   2.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=5, p=1, weights=distance;, score=0.685 total time=   2.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.704 total time=   2.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=5, p=2, weights=distance;, score=0.701 total time=   2.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.696 total time=   2.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=7, p=1, weights=distance;, score=0.694 total time=   2.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.699 total time=   2.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=7, p=2, weights=distance;, score=0.699 total time=   2.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=10, p=1, weights=uniform;, score=0.707 total time=   2.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=10, p=1, weights=distance;, score=0.698 total time=   2.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=10, p=2, weights=uniform;, score=0.690 total time=   2.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=10, p=2, weights=distance;, score=0.702 total time=   2.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=1, p=1, weights=uniform;, score=0.644 total time=   2.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=1, p=1, weights=distance;, score=0.644 total time=   2.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=1, p=2, weights=uniform;, score=0.643 total time=   2.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=1, p=2, weights=distance;, score=0.643 total time=   2.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.661 total time=   2.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=3, p=1, weights=distance;, score=0.661 total time=   2.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.678 total time=   2.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=3, p=2, weights=distance;, score=0.676 total time=   2.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.685 total time=   2.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=5, p=1, weights=distance;, score=0.685 total time=   2.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.704 total time=   2.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=5, p=2, weights=distance;, score=0.701 total time=   2.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.696 total time=   2.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=7, p=1, weights=distance;, score=0.694 total time=   2.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.699 total time=   2.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=7, p=2, weights=distance;, score=0.699 total time=   2.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=10, p=1, weights=uniform;, score=0.707 total time=   2.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=10, p=1, weights=distance;, score=0.698 total time=   2.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=10, p=2, weights=uniform;, score=0.690 total time=   2.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=10, p=2, weights=distance;, score=0.702 total time=   2.3s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=1, p=1, weights=uniform;, score=0.644 total time=   2.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=1, p=1, weights=distance;, score=0.644 total time=   2.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=1, p=2, weights=uniform;, score=0.643 total time=   3.3s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=1, p=2, weights=distance;, score=0.643 total time=   3.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.661 total time=   2.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=3, p=1, weights=distance;, score=0.661 total time=   2.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.678 total time=   3.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=3, p=2, weights=distance;, score=0.676 total time=   3.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.685 total time=   2.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=5, p=1, weights=distance;, score=0.685 total time=   2.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.704 total time=   3.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=5, p=2, weights=distance;, score=0.701 total time=   3.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.696 total time=   2.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=7, p=1, weights=distance;, score=0.694 total time=   2.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.699 total time=   3.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=7, p=2, weights=distance;, score=0.699 total time=   3.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=10, p=1, weights=uniform;, score=0.707 total time=   2.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=10, p=1, weights=distance;, score=0.698 total time=   2.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=10, p=2, weights=uniform;, score=0.690 total time=   3.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=10, p=2, weights=distance;, score=0.702 total time=   3.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=1, p=1, weights=uniform;, score=0.644 total time=   2.3s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=1, p=1, weights=distance;, score=0.644 total time=   2.3s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=1, p=2, weights=uniform;, score=0.643 total time=   2.5s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=1, p=2, weights=distance;, score=0.643 total time=   2.5s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.661 total time=   2.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=3, p=1, weights=distance;, score=0.661 total time=   2.3s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.678 total time=   2.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=3, p=2, weights=distance;, score=0.676 total time=   2.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.685 total time=   2.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=5, p=1, weights=distance;, score=0.685 total time=   2.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.704 total time=   2.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=5, p=2, weights=distance;, score=0.701 total time=   2.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.696 total time=   2.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=7, p=1, weights=distance;, score=0.694 total time=   3.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.699 total time=   2.9s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=7, p=2, weights=distance;, score=0.699 total time=   2.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=10, p=1, weights=uniform;, score=0.707 total time=   2.5s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=10, p=1, weights=distance;, score=0.698 total time=   2.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=10, p=2, weights=uniform;, score=0.690 total time=   2.9s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=10, p=2, weights=distance;, score=0.702 total time=   2.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=1, p=1, weights=uniform;, score=0.644 total time=   2.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=1, p=1, weights=distance;, score=0.644 total time=   2.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=1, p=2, weights=uniform;, score=0.643 total time=   2.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=1, p=2, weights=distance;, score=0.643 total time=   2.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.661 total time=   2.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=3, p=1, weights=distance;, score=0.661 total time=   2.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.678 total time=   2.3s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=3, p=2, weights=distance;, score=0.676 total time=   2.3s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.685 total time=   2.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=5, p=1, weights=distance;, score=0.685 total time=   2.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.704 total time=   2.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=5, p=2, weights=distance;, score=0.701 total time=   2.3s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.696 total time=   2.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=7, p=1, weights=distance;, score=0.694 total time=   2.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.699 total time=   2.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=7, p=2, weights=distance;, score=0.699 total time=   2.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=10, p=1, weights=uniform;, score=0.707 total time=   2.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=10, p=1, weights=distance;, score=0.698 total time=   2.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=10, p=2, weights=uniform;, score=0.690 total time=   2.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=10, p=2, weights=distance;, score=0.702 total time=   2.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=1, p=1, weights=uniform;, score=0.644 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=1, p=1, weights=distance;, score=0.644 total time=   0.1s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=1, p=2, weights=uniform;, score=0.643 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=1, p=2, weights=distance;, score=0.643 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.661 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=3, p=1, weights=distance;, score=0.661 total time=   0.1s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.678 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=3, p=2, weights=distance;, score=0.676 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.685 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=5, p=1, weights=distance;, score=0.685 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.704 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=5, p=2, weights=distance;, score=0.701 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.696 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=7, p=1, weights=distance;, score=0.694 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.699 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=7, p=2, weights=distance;, score=0.699 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=10, p=1, weights=uniform;, score=0.707 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=10, p=1, weights=distance;, score=0.698 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=10, p=2, weights=uniform;, score=0.690 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=10, p=2, weights=distance;, score=0.702 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=1, p=1, weights=uniform;, score=0.644 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=1, p=1, weights=distance;, score=0.644 total time=   0.1s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=1, p=2, weights=uniform;, score=0.643 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=1, p=2, weights=distance;, score=0.643 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.661 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=3, p=1, weights=distance;, score=0.661 total time=   0.1s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.678 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=3, p=2, weights=distance;, score=0.676 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.685 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=5, p=1, weights=distance;, score=0.685 total time=   0.1s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.704 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=5, p=2, weights=distance;, score=0.701 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.696 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=7, p=1, weights=distance;, score=0.694 total time=   0.1s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.699 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=7, p=2, weights=distance;, score=0.699 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=10, p=1, weights=uniform;, score=0.707 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=10, p=1, weights=distance;, score=0.698 total time=   0.1s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=10, p=2, weights=uniform;, score=0.690 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=10, p=2, weights=distance;, score=0.702 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=1, p=1, weights=uniform;, score=0.644 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=1, p=1, weights=distance;, score=0.644 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=1, p=2, weights=uniform;, score=0.643 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=1, p=2, weights=distance;, score=0.643 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.661 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=3, p=1, weights=distance;, score=0.661 total time=   0.1s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.678 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=3, p=2, weights=distance;, score=0.676 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.685 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=5, p=1, weights=distance;, score=0.685 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.704 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=5, p=2, weights=distance;, score=0.701 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.696 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=7, p=1, weights=distance;, score=0.694 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.699 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=7, p=2, weights=distance;, score=0.699 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=10, p=1, weights=uniform;, score=0.707 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=10, p=1, weights=distance;, score=0.698 total time=   0.1s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=10, p=2, weights=uniform;, score=0.690 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=10, p=2, weights=distance;, score=0.702 total time=   0.0s\n",
      "Best hyperparameters: {'algorithm': 'auto', 'leaf_size': 15, 'n_neighbors': 10, 'p': 1, 'weights': 'uniform'}\n",
      "Accuracy: 68.66\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.62      0.62      1829\n",
      "           1       0.73      0.73      0.73      2543\n",
      "\n",
      "    accuracy                           0.69      4372\n",
      "   macro avg       0.68      0.68      0.68      4372\n",
      "weighted avg       0.69      0.69      0.69      4372\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1140  689]\n",
      " [ 681 1862]]\n"
     ]
    }
   ],
   "source": [
    "# Define the KNN model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_neighbors': [1, 3, 5, 7, 10],  # Number of neighbors\n",
    "    'weights': ['uniform', 'distance'],  # Weighting scheme\n",
    "    'p': [1, 2],  # Distance metric (1 for Manhattan, 2 for Euclidean)\n",
    "    'leaf_size': [15, 30, 45],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "filename = 'knn_model.pkl'\n",
    "\n",
    "train_test_save(knn, param_grid, filename, n_splits=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Span: 3 -----\n",
      "12390 train examples\n",
      "5310 test examples\n",
      "Fitting 1 folds for each of 162 candidates, totalling 162 fits\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100;, score=0.716 total time=   3.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.719 total time=   6.2s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.705 total time=  15.7s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100;, score=0.707 total time=   1.7s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=log2, n_estimators=200;, score=0.710 total time=   3.5s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=log2, n_estimators=500;, score=0.712 total time=   8.7s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.711 total time=   3.8s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.713 total time=   7.7s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.719 total time=  19.4s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100;, score=0.708 total time=   2.1s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=log2, n_estimators=200;, score=0.709 total time=   4.3s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=log2, n_estimators=500;, score=0.706 total time=  10.8s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=100;, score=0.715 total time=   4.6s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.705 total time=   9.2s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.714 total time=  23.1s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=log2, n_estimators=100;, score=0.710 total time=   2.5s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=log2, n_estimators=200;, score=0.705 total time=   5.1s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=log2, n_estimators=500;, score=0.704 total time=  12.9s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=100;, score=0.714 total time=   5.4s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.709 total time=  10.8s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.718 total time=  26.8s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=log2, n_estimators=100;, score=0.704 total time=   2.9s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=log2, n_estimators=200;, score=0.708 total time=   5.9s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=log2, n_estimators=500;, score=0.712 total time=  14.9s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.707 total time=   6.1s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.717 total time=  12.2s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.712 total time=  30.6s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=log2, n_estimators=100;, score=0.709 total time=   3.3s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=log2, n_estimators=200;, score=0.713 total time=   6.7s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=log2, n_estimators=500;, score=0.714 total time=  17.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100;, score=0.705 total time=  10.5s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=200;, score=0.718 total time=  21.1s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=500;, score=0.716 total time=  53.2s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100;, score=0.705 total time=   5.7s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=log2, n_estimators=200;, score=0.704 total time=  11.5s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=log2, n_estimators=500;, score=0.708 total time=  28.8s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100;, score=0.709 total time=   4.1s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.713 total time=   8.3s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.714 total time=  20.8s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100;, score=0.709 total time=   2.3s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=200;, score=0.707 total time=   4.6s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=500;, score=0.707 total time=  11.6s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.708 total time=   5.2s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.716 total time=  10.4s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.710 total time=  26.4s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100;, score=0.705 total time=   2.9s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=200;, score=0.701 total time=   5.8s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=500;, score=0.709 total time=  14.6s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=100;, score=0.705 total time=   6.3s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.709 total time=  12.6s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.714 total time=  31.6s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=100;, score=0.709 total time=   3.4s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=200;, score=0.708 total time=   7.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=500;, score=0.708 total time=  17.4s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=100;, score=0.711 total time=   7.3s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.718 total time=  14.7s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.713 total time=  36.9s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=100;, score=0.707 total time=   4.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=200;, score=0.711 total time=   8.2s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=500;, score=0.709 total time=  20.4s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.720 total time=   8.3s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.708 total time=  16.8s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.717 total time=  42.3s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=100;, score=0.713 total time=   4.6s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=200;, score=0.710 total time=   9.3s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=500;, score=0.711 total time=  23.3s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100;, score=0.716 total time=  13.4s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=200;, score=0.716 total time=  26.7s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=500;, score=0.716 total time= 1.1min\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100;, score=0.713 total time=   7.5s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=200;, score=0.715 total time=  15.2s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=500;, score=0.720 total time=  38.3s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=100;, score=0.705 total time=   4.1s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.718 total time=   8.2s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.709 total time=  20.8s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=100;, score=0.700 total time=   2.3s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=200;, score=0.701 total time=   4.6s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=500;, score=0.715 total time=  11.6s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.707 total time=   5.2s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.709 total time=  10.4s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.709 total time=  26.1s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=0.709 total time=   2.9s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=0.708 total time=   5.8s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=500;, score=0.708 total time=  14.5s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=100;, score=0.714 total time=   6.3s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.711 total time=  12.5s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.717 total time=  31.6s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=log2, n_estimators=100;, score=0.703 total time=   3.4s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=log2, n_estimators=200;, score=0.701 total time=   7.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=log2, n_estimators=500;, score=0.709 total time=  17.5s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=100;, score=0.713 total time=   7.4s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.709 total time=  14.8s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.711 total time=  37.1s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=log2, n_estimators=100;, score=0.709 total time=   4.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=log2, n_estimators=200;, score=0.707 total time=   8.2s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=log2, n_estimators=500;, score=0.709 total time=  20.5s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.710 total time=   8.4s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.709 total time=  16.9s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.712 total time=  42.4s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=log2, n_estimators=100;, score=0.708 total time=   4.6s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=log2, n_estimators=200;, score=0.709 total time=   9.3s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=log2, n_estimators=500;, score=0.715 total time=  23.3s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100;, score=0.712 total time=  13.4s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=200;, score=0.715 total time=  27.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=500;, score=0.713 total time= 1.1min\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100;, score=0.720 total time=   7.7s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=200;, score=0.715 total time=  15.7s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=500;, score=0.713 total time=  38.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "54 fits failed out of a total of 162.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.71589992 0.71912833 0.70540759\n",
      " 0.70702179 0.7102502  0.71186441        nan        nan        nan\n",
      " 0.7110573  0.71267151 0.71912833 0.70782889 0.708636   0.70621469\n",
      "        nan        nan        nan 0.71509282 0.70540759 0.71428571\n",
      " 0.7102502  0.70540759 0.70379338        nan        nan        nan\n",
      " 0.71428571 0.708636   0.71751412 0.70379338 0.70782889 0.71186441\n",
      "        nan        nan        nan 0.70702179 0.71670702 0.71186441\n",
      " 0.7094431  0.71267151 0.71428571        nan        nan        nan\n",
      " 0.70540759 0.71832123 0.71589992 0.70460048 0.70379338 0.70782889\n",
      "        nan        nan        nan 0.708636   0.71347861 0.71428571\n",
      " 0.7094431  0.70702179 0.70702179        nan        nan        nan\n",
      " 0.70782889 0.71589992 0.7102502  0.70460048 0.70137207 0.708636\n",
      "        nan        nan        nan 0.70540759 0.7094431  0.71428571\n",
      " 0.708636   0.70782889 0.70782889        nan        nan        nan\n",
      " 0.7110573  0.71832123 0.71347861 0.70702179 0.7110573  0.7094431\n",
      "        nan        nan        nan 0.71993543 0.70782889 0.71670702\n",
      " 0.71347861 0.7102502  0.7110573         nan        nan        nan\n",
      " 0.71589992 0.71589992 0.71589992 0.71267151 0.71509282 0.71993543\n",
      "        nan        nan        nan 0.70540759 0.71751412 0.7094431\n",
      " 0.69975787 0.70137207 0.71509282        nan        nan        nan\n",
      " 0.70702179 0.708636   0.708636   0.7094431  0.70782889 0.70782889\n",
      "        nan        nan        nan 0.71428571 0.7110573  0.71670702\n",
      " 0.70298628 0.70137207 0.7094431         nan        nan        nan\n",
      " 0.71347861 0.7094431  0.7110573  0.7094431  0.70702179 0.708636\n",
      "        nan        nan        nan 0.7102502  0.708636   0.71186441\n",
      " 0.70782889 0.7094431  0.71509282        nan        nan        nan\n",
      " 0.71186441 0.71509282 0.71267151 0.71993543 0.71509282 0.71267151]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "Accuracy: 71.15\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.55      0.61      2199\n",
      "           1       0.72      0.82      0.77      3111\n",
      "\n",
      "    accuracy                           0.71      5310\n",
      "   macro avg       0.71      0.69      0.69      5310\n",
      "weighted avg       0.71      0.71      0.70      5310\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1213  986]\n",
      " [ 546 2565]]\n",
      "----- Span: 5 -----\n",
      "11282 train examples\n",
      "4836 test examples\n",
      "Fitting 1 folds for each of 162 candidates, totalling 162 fits\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100;, score=0.696 total time=   2.9s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.698 total time=   5.9s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.702 total time=  14.7s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100;, score=0.693 total time=   1.6s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=log2, n_estimators=200;, score=0.702 total time=   3.3s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=log2, n_estimators=500;, score=0.696 total time=   8.3s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.703 total time=   3.6s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.704 total time=   7.3s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.703 total time=  18.3s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100;, score=0.705 total time=   2.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=log2, n_estimators=200;, score=0.701 total time=   4.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=log2, n_estimators=500;, score=0.701 total time=  10.2s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=100;, score=0.713 total time=   4.3s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.705 total time=   8.6s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.713 total time=  21.8s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=log2, n_estimators=100;, score=0.696 total time=   2.4s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=log2, n_estimators=200;, score=0.704 total time=   4.8s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=log2, n_estimators=500;, score=0.709 total time=  12.2s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=100;, score=0.715 total time=   5.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.708 total time=  10.1s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.717 total time=  25.3s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=log2, n_estimators=100;, score=0.708 total time=   2.8s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=log2, n_estimators=200;, score=0.709 total time=   5.6s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=log2, n_estimators=500;, score=0.715 total time=  14.1s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.713 total time=   5.7s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.717 total time=  11.5s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.714 total time=  28.9s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=log2, n_estimators=100;, score=0.704 total time=   3.1s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=log2, n_estimators=200;, score=0.704 total time=   6.3s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=log2, n_estimators=500;, score=0.715 total time=  16.1s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100;, score=0.712 total time=   9.8s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=200;, score=0.709 total time=  19.6s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=500;, score=0.717 total time=  49.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100;, score=0.705 total time=   5.3s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=log2, n_estimators=200;, score=0.711 total time=  10.7s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=log2, n_estimators=500;, score=0.716 total time=  26.7s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100;, score=0.700 total time=   3.9s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.702 total time=   8.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.700 total time=  19.9s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100;, score=0.700 total time=   2.2s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=200;, score=0.690 total time=   4.4s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=500;, score=0.694 total time=  11.2s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.705 total time=   5.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.702 total time=  10.1s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.708 total time=  25.1s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100;, score=0.702 total time=   2.7s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=200;, score=0.702 total time=   5.5s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=500;, score=0.702 total time=  13.9s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=100;, score=0.708 total time=   6.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.709 total time=  12.1s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.709 total time=  30.3s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=100;, score=0.702 total time=   3.3s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=200;, score=0.709 total time=   6.6s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=500;, score=0.704 total time=  16.8s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=100;, score=0.715 total time=   7.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.712 total time=  14.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.714 total time=  35.2s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=100;, score=0.707 total time=   3.8s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=200;, score=0.709 total time=   7.7s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=500;, score=0.711 total time=  19.4s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.714 total time=   8.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.717 total time=  16.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.710 total time=  40.1s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=100;, score=0.710 total time=   4.3s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=200;, score=0.713 total time=   8.8s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=500;, score=0.715 total time=  22.1s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100;, score=0.721 total time=  12.4s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=200;, score=0.708 total time=  24.8s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=500;, score=0.714 total time= 1.0min\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100;, score=0.714 total time=   7.1s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=200;, score=0.715 total time=  14.1s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=500;, score=0.714 total time=  35.6s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=100;, score=0.702 total time=   3.9s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.699 total time=   7.9s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.694 total time=  19.9s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=100;, score=0.691 total time=   2.2s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=200;, score=0.698 total time=   4.4s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=500;, score=0.694 total time=  11.1s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.700 total time=   4.9s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.703 total time=  10.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.705 total time=  25.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=0.700 total time=   2.7s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=0.700 total time=   5.5s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=500;, score=0.702 total time=  13.9s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=100;, score=0.711 total time=   6.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.705 total time=  12.2s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.714 total time=  30.2s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=log2, n_estimators=100;, score=0.713 total time=   3.3s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=log2, n_estimators=200;, score=0.707 total time=   6.7s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=log2, n_estimators=500;, score=0.708 total time=  16.7s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=100;, score=0.712 total time=   7.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.717 total time=  14.1s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.711 total time=  35.3s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=log2, n_estimators=100;, score=0.711 total time=   3.8s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=log2, n_estimators=200;, score=0.709 total time=   7.7s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=log2, n_estimators=500;, score=0.711 total time=  19.4s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.714 total time=   7.9s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.717 total time=  16.1s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.716 total time=  40.1s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=log2, n_estimators=100;, score=0.714 total time=   4.3s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=log2, n_estimators=200;, score=0.708 total time=   8.8s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=log2, n_estimators=500;, score=0.714 total time=  22.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100;, score=0.697 total time=  12.4s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=200;, score=0.711 total time=  25.1s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=500;, score=0.718 total time= 1.1min\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100;, score=0.715 total time=   7.3s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=200;, score=0.711 total time=  14.5s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=500;, score=0.709 total time=  37.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "54 fits failed out of a total of 162.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.69619132 0.6979628  0.70150576\n",
      " 0.69264836 0.7023915  0.69619132        nan        nan        nan\n",
      " 0.70327724 0.70416298 0.70327724 0.70504872 0.70062002 0.70062002\n",
      "        nan        nan        nan 0.71302037 0.70504872 0.71302037\n",
      " 0.69619132 0.70416298 0.70947741        nan        nan        nan\n",
      " 0.71479185 0.70770593 0.71656333 0.70770593 0.70947741 0.71479185\n",
      "        nan        nan        nan 0.71302037 0.71656333 0.71390611\n",
      " 0.70416298 0.70416298 0.71479185        nan        nan        nan\n",
      " 0.71213463 0.70947741 0.71744907 0.70504872 0.71124889 0.71567759\n",
      "        nan        nan        nan 0.69973428 0.7023915  0.69973428\n",
      " 0.69973428 0.68999114 0.69441984        nan        nan        nan\n",
      " 0.70504872 0.70150576 0.70770593 0.7023915  0.7023915  0.7023915\n",
      "        nan        nan        nan 0.70770593 0.70859167 0.70859167\n",
      " 0.7023915  0.70859167 0.70416298        nan        nan        nan\n",
      " 0.71479185 0.71213463 0.71390611 0.70682019 0.70947741 0.71124889\n",
      "        nan        nan        nan 0.71390611 0.71744907 0.71036315\n",
      " 0.71036315 0.71302037 0.71479185        nan        nan        nan\n",
      " 0.72099203 0.70770593 0.71390611 0.71390611 0.71479185 0.71390611\n",
      "        nan        nan        nan 0.7023915  0.69884854 0.6935341\n",
      " 0.69087688 0.6979628  0.6935341         nan        nan        nan\n",
      " 0.69973428 0.70327724 0.70504872 0.69973428 0.69973428 0.7023915\n",
      "        nan        nan        nan 0.71124889 0.70504872 0.71390611\n",
      " 0.71302037 0.70682019 0.70770593        nan        nan        nan\n",
      " 0.71213463 0.71744907 0.71124889 0.71124889 0.70947741 0.71124889\n",
      "        nan        nan        nan 0.71390611 0.71656333 0.71567759\n",
      " 0.71390611 0.70770593 0.71390611        nan        nan        nan\n",
      " 0.69707706 0.71124889 0.71833481 0.71479185 0.71124889 0.70859167]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "Accuracy: 71.79\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.60      0.64      1992\n",
      "           1       0.74      0.80      0.77      2844\n",
      "\n",
      "    accuracy                           0.72      4836\n",
      "   macro avg       0.71      0.70      0.70      4836\n",
      "weighted avg       0.72      0.72      0.71      4836\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1200  792]\n",
      " [ 572 2272]]\n",
      "----- Span: 7 -----\n",
      "10200 train examples\n",
      "4372 test examples\n",
      "Fitting 1 folds for each of 162 candidates, totalling 162 fits\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100;, score=0.724 total time=   2.7s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.726 total time=   5.4s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.723 total time=  13.9s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100;, score=0.723 total time=   1.5s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=log2, n_estimators=200;, score=0.729 total time=   3.1s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=log2, n_estimators=500;, score=0.724 total time=   8.1s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.719 total time=   3.4s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.718 total time=   6.9s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.725 total time=  17.6s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100;, score=0.723 total time=   1.9s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=log2, n_estimators=200;, score=0.730 total time=   4.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=log2, n_estimators=500;, score=0.729 total time=  10.3s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=100;, score=0.731 total time=   4.1s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.730 total time=   8.2s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.726 total time=  20.4s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=log2, n_estimators=100;, score=0.725 total time=   2.2s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=log2, n_estimators=200;, score=0.726 total time=   4.5s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=log2, n_estimators=500;, score=0.725 total time=  11.3s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=100;, score=0.724 total time=   4.7s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.727 total time=   9.4s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.726 total time=  23.4s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=log2, n_estimators=100;, score=0.734 total time=   2.6s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=log2, n_estimators=200;, score=0.723 total time=   5.2s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=log2, n_estimators=500;, score=0.722 total time=  13.1s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.737 total time=   5.2s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.725 total time=  10.5s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.728 total time=  26.6s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=log2, n_estimators=100;, score=0.729 total time=   2.9s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=log2, n_estimators=200;, score=0.720 total time=   6.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=log2, n_estimators=500;, score=0.729 total time=  15.3s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100;, score=0.725 total time=   9.2s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=200;, score=0.726 total time=  18.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=500;, score=0.729 total time=  45.5s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100;, score=0.727 total time=   4.9s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=log2, n_estimators=200;, score=0.731 total time=  10.2s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=log2, n_estimators=500;, score=0.726 total time=  24.8s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100;, score=0.725 total time=   3.8s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.725 total time=   7.7s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.723 total time=  18.9s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100;, score=0.719 total time=   2.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=200;, score=0.715 total time=   4.1s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=500;, score=0.720 total time=  10.6s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.725 total time=   4.7s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.726 total time=   9.4s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.727 total time=  23.5s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100;, score=0.726 total time=   2.6s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=200;, score=0.725 total time=   5.2s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=500;, score=0.728 total time=  13.1s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=100;, score=0.730 total time=   5.6s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.721 total time=  11.3s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.719 total time=  28.6s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=100;, score=0.720 total time=   3.1s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=200;, score=0.723 total time=   6.2s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=500;, score=0.725 total time=  15.8s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=100;, score=0.724 total time=   6.6s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.726 total time=  13.1s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.730 total time=  33.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=100;, score=0.729 total time=   3.6s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=200;, score=0.722 total time=   7.2s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=500;, score=0.723 total time=  18.3s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.735 total time=   7.4s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.731 total time=  14.9s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.730 total time=  37.8s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=100;, score=0.725 total time=   4.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=200;, score=0.724 total time=   8.3s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=500;, score=0.731 total time=  20.7s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100;, score=0.719 total time=  11.5s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=200;, score=0.725 total time=  22.8s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=500;, score=0.739 total time=  57.3s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100;, score=0.733 total time=   6.5s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=200;, score=0.730 total time=  13.1s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=500;, score=0.726 total time=  32.6s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=100;, score=0.715 total time=   3.7s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.722 total time=   7.4s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.727 total time=  18.7s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=100;, score=0.726 total time=   2.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=200;, score=0.724 total time=   4.2s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=500;, score=0.722 total time=  10.5s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.726 total time=   4.6s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.723 total time=   9.3s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.725 total time=  24.2s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=0.721 total time=   2.7s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=0.725 total time=   5.5s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=500;, score=0.725 total time=  13.3s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=100;, score=0.727 total time=   5.7s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.723 total time=  11.6s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.725 total time=  29.2s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=log2, n_estimators=100;, score=0.727 total time=   3.1s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=log2, n_estimators=200;, score=0.725 total time=   6.3s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=log2, n_estimators=500;, score=0.724 total time=  15.9s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=100;, score=0.730 total time=   6.6s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.723 total time=  13.4s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.728 total time=  33.1s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=log2, n_estimators=100;, score=0.726 total time=   3.6s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=log2, n_estimators=200;, score=0.725 total time=   7.2s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=log2, n_estimators=500;, score=0.722 total time=  18.2s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.728 total time=   7.5s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.726 total time=  14.9s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.731 total time=  37.3s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=log2, n_estimators=100;, score=0.728 total time=   4.1s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=log2, n_estimators=200;, score=0.731 total time=   8.3s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=log2, n_estimators=500;, score=0.729 total time=  20.8s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100;, score=0.727 total time=  11.5s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=200;, score=0.737 total time=  23.2s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=500;, score=0.733 total time=  57.2s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100;, score=0.726 total time=   6.5s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=200;, score=0.734 total time=  13.1s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=500;, score=0.731 total time=  32.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "54 fits failed out of a total of 162.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.72352941 0.72647059 0.72254902\n",
      " 0.72254902 0.72941176 0.72352941        nan        nan        nan\n",
      " 0.71862745 0.71764706 0.7254902  0.72254902 0.73039216 0.72941176\n",
      "        nan        nan        nan 0.73137255 0.73039216 0.72647059\n",
      " 0.7245098  0.72647059 0.7245098         nan        nan        nan\n",
      " 0.72352941 0.72745098 0.72647059 0.73431373 0.72254902 0.72156863\n",
      "        nan        nan        nan 0.7372549  0.7254902  0.72843137\n",
      " 0.72941176 0.71960784 0.72941176        nan        nan        nan\n",
      " 0.7245098  0.72647059 0.72941176 0.72745098 0.73137255 0.72647059\n",
      "        nan        nan        nan 0.7254902  0.7245098  0.72254902\n",
      " 0.71862745 0.71470588 0.71960784        nan        nan        nan\n",
      " 0.7254902  0.72647059 0.72745098 0.72647059 0.7245098  0.72843137\n",
      "        nan        nan        nan 0.73039216 0.72058824 0.71862745\n",
      " 0.71960784 0.72254902 0.7245098         nan        nan        nan\n",
      " 0.72352941 0.72647059 0.73039216 0.72941176 0.72156863 0.72254902\n",
      "        nan        nan        nan 0.73529412 0.73137255 0.73039216\n",
      " 0.7254902  0.72352941 0.73137255        nan        nan        nan\n",
      " 0.71862745 0.7254902  0.73921569 0.73333333 0.73039216 0.72647059\n",
      "        nan        nan        nan 0.71470588 0.72156863 0.72745098\n",
      " 0.72647059 0.72352941 0.72156863        nan        nan        nan\n",
      " 0.72647059 0.72254902 0.7254902  0.72058824 0.7245098  0.7245098\n",
      "        nan        nan        nan 0.72745098 0.72254902 0.7254902\n",
      " 0.72745098 0.7254902  0.72352941        nan        nan        nan\n",
      " 0.73039216 0.72254902 0.72843137 0.72647059 0.7245098  0.72156863\n",
      "        nan        nan        nan 0.72843137 0.72647059 0.73137255\n",
      " 0.72843137 0.73137255 0.72941176        nan        nan        nan\n",
      " 0.72745098 0.7372549  0.73333333 0.72647059 0.73431373 0.73137255]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Accuracy: 72.60\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.59      0.64      1829\n",
      "           1       0.74      0.82      0.78      2543\n",
      "\n",
      "    accuracy                           0.73      4372\n",
      "   macro avg       0.72      0.71      0.71      4372\n",
      "weighted avg       0.72      0.73      0.72      4372\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1082  747]\n",
      " [ 451 2092]]\n"
     ]
    }
   ],
   "source": [
    "# Define the Random Forest model\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],  # Number of trees in the forest\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # Maximum number of features considered for splitting\n",
    "    'max_depth': [4, 5, 6, 7, 8, None],  # Maximum depth of each tree\n",
    "    'criterion': ['gini', 'entropy', 'log_loss']  # Split quality criterion\n",
    "}\n",
    "\n",
    "filename = 'random_forest.pkl'\n",
    "\n",
    "train_test_save(rfc, param_grid, filename, n_splits=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Span: 3 -----\n",
      "12390 train examples\n",
      "5310 test examples\n",
      "Fitting 1 folds for each of 162 candidates, totalling 162 fits\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, n_estimators=100;, score=0.672 total time=   1.9s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, n_estimators=200;, score=0.712 total time=   3.9s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, n_estimators=300;, score=0.720 total time=   5.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.681 total time=   3.4s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.718 total time=   6.9s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.718 total time=  10.3s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=0.709 total time=   3.3s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=0.719 total time=   6.6s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, n_estimators=300;, score=0.724 total time=   9.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.710 total time=   5.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.730 total time=  12.2s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.726 total time=  17.5s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, n_estimators=100;, score=0.718 total time=   6.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, n_estimators=200;, score=0.730 total time=  12.1s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, n_estimators=300;, score=0.730 total time=  18.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.715 total time=  10.3s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.730 total time=  20.5s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.730 total time=  30.6s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, n_estimators=100;, score=0.657 total time=   1.9s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, n_estimators=200;, score=0.708 total time=   3.9s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, n_estimators=300;, score=0.716 total time=   5.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.684 total time=   3.4s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.712 total time=   6.9s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.722 total time=  10.6s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, n_estimators=100;, score=0.705 total time=   3.3s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, n_estimators=200;, score=0.724 total time=   6.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, n_estimators=300;, score=0.730 total time=  10.2s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.706 total time=   5.9s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.730 total time=  11.7s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.726 total time=  17.6s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=log2, n_estimators=100;, score=0.713 total time=   6.1s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=log2, n_estimators=200;, score=0.727 total time=  12.6s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=log2, n_estimators=300;, score=0.738 total time=  18.9s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.725 total time=  10.4s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.734 total time=  20.7s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.734 total time=  30.9s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=log2, n_estimators=100;, score=0.728 total time=   1.9s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=log2, n_estimators=200;, score=0.728 total time=   3.8s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=log2, n_estimators=300;, score=0.726 total time=   5.7s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.728 total time=   3.3s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.739 total time=   6.8s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.734 total time=  10.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=0.733 total time=   3.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=0.727 total time=   6.5s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=log2, n_estimators=300;, score=0.731 total time=   9.7s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.734 total time=   5.8s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.722 total time=  11.5s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.730 total time=  17.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=log2, n_estimators=100;, score=0.735 total time=   5.9s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=log2, n_estimators=200;, score=0.735 total time=  11.6s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=log2, n_estimators=300;, score=0.724 total time=  17.4s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.733 total time=   9.9s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.725 total time=  20.1s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.733 total time=  29.8s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=100;, score=0.725 total time=   1.9s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=200;, score=0.723 total time=   3.8s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=300;, score=0.734 total time=   5.7s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.726 total time=   3.4s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.731 total time=   6.9s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.724 total time=  10.1s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=100;, score=0.730 total time=   3.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=200;, score=0.735 total time=   6.5s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=300;, score=0.731 total time=   9.7s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.732 total time=   5.8s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.729 total time=  11.6s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.726 total time=  17.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=log2, n_estimators=100;, score=0.733 total time=   5.9s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=log2, n_estimators=200;, score=0.735 total time=  11.9s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=log2, n_estimators=300;, score=0.726 total time=  17.9s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.730 total time=  10.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.732 total time=  20.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.722 total time=  29.9s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, n_estimators=100;, score=0.734 total time=   1.9s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, n_estimators=200;, score=0.725 total time=   3.8s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, n_estimators=300;, score=0.734 total time=   5.7s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.723 total time=   3.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.732 total time=   6.8s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.738 total time=  10.1s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=0.726 total time=   3.2s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=0.724 total time=   6.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, n_estimators=300;, score=0.735 total time=   9.7s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.727 total time=   5.7s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.726 total time=  11.5s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.731 total time=  17.1s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, n_estimators=100;, score=0.722 total time=   5.8s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, n_estimators=200;, score=0.718 total time=  11.8s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, n_estimators=300;, score=0.730 total time=  17.5s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.723 total time=   9.9s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.732 total time=  19.7s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.722 total time=  29.6s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, n_estimators=100;, score=0.732 total time=   1.9s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, n_estimators=200;, score=0.727 total time=   3.8s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, n_estimators=300;, score=0.722 total time=   5.7s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.729 total time=   3.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.741 total time=   6.8s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.733 total time=  10.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=log2, n_estimators=100;, score=0.727 total time=   3.2s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=log2, n_estimators=200;, score=0.724 total time=   6.5s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=log2, n_estimators=300;, score=0.731 total time=   9.8s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.729 total time=   5.7s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.738 total time=  11.6s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.722 total time=  17.1s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=log2, n_estimators=100;, score=0.734 total time=   5.8s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=log2, n_estimators=200;, score=0.726 total time=  11.7s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=log2, n_estimators=300;, score=0.720 total time=  17.6s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.718 total time=   9.9s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.722 total time=  19.7s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.722 total time=  29.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "54 fits failed out of a total of 162.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.67231638 0.71186441 0.71993543 0.68119451 0.71832123 0.71832123\n",
      " 0.708636   0.71912833 0.72397094 0.7102502  0.73042776 0.72639225\n",
      " 0.71832123 0.72962066 0.72962066 0.71509282 0.72962066 0.72962066\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.65698144 0.70782889 0.71589992 0.68442292 0.71186441 0.72154964\n",
      " 0.70540759 0.72397094 0.73042776 0.70621469 0.72962066 0.72639225\n",
      " 0.71347861 0.72719935 0.73849879 0.72477805 0.73446328 0.73446328\n",
      " 0.72800646 0.72800646 0.72639225 0.72800646 0.73930589 0.73365617\n",
      " 0.73284907 0.72719935 0.73123487 0.73365617 0.72235674 0.72962066\n",
      " 0.73527038 0.73527038 0.72397094 0.73284907 0.72477805 0.73284907\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.72477805 0.72316384 0.73446328 0.72639225 0.73123487 0.72397094\n",
      " 0.73042776 0.73527038 0.73123487 0.73204197 0.72881356 0.72558515\n",
      " 0.73284907 0.73527038 0.72639225 0.73042776 0.73204197 0.72154964\n",
      " 0.73446328 0.72477805 0.73446328 0.72316384 0.73204197 0.73769169\n",
      " 0.72639225 0.72397094 0.73527038 0.72719935 0.72558515 0.73123487\n",
      " 0.72154964 0.71832123 0.72962066 0.72316384 0.73204197 0.72154964\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73204197 0.72719935 0.72235674 0.72881356 0.7409201  0.73284907\n",
      " 0.72719935 0.72397094 0.73123487 0.72881356 0.73769169 0.72154964\n",
      " 0.73365617 0.72558515 0.71993543 0.71832123 0.72235674 0.72154964]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Accuracy: 71.98\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65      2199\n",
      "           1       0.75      0.79      0.77      3111\n",
      "\n",
      "    accuracy                           0.72      5310\n",
      "   macro avg       0.71      0.71      0.71      5310\n",
      "weighted avg       0.72      0.72      0.72      5310\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1364  835]\n",
      " [ 653 2458]]\n",
      "----- Span: 5 -----\n",
      "11282 train examples\n",
      "4836 test examples\n",
      "Fitting 1 folds for each of 162 candidates, totalling 162 fits\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, n_estimators=100;, score=0.686 total time=   1.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, n_estimators=200;, score=0.720 total time=   3.6s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, n_estimators=300;, score=0.731 total time=   5.6s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.695 total time=   3.3s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.725 total time=   6.6s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.719 total time=   9.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=0.712 total time=   3.1s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=0.717 total time=   6.3s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, n_estimators=300;, score=0.729 total time=   9.5s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.720 total time=   5.5s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.725 total time=  11.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.723 total time=  16.6s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, n_estimators=100;, score=0.717 total time=   5.7s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, n_estimators=200;, score=0.733 total time=  11.4s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, n_estimators=300;, score=0.734 total time=  17.2s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.721 total time=   9.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.728 total time=  19.4s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.724 total time=  28.9s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, n_estimators=100;, score=0.683 total time=   1.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, n_estimators=200;, score=0.723 total time=   3.7s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, n_estimators=300;, score=0.728 total time=   5.7s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.697 total time=   3.2s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.727 total time=   6.5s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.731 total time=   9.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, n_estimators=100;, score=0.711 total time=   3.1s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, n_estimators=200;, score=0.727 total time=   6.2s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, n_estimators=300;, score=0.734 total time=   9.5s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.725 total time=   5.6s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.728 total time=  11.1s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.725 total time=  16.5s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=log2, n_estimators=100;, score=0.717 total time=   5.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=log2, n_estimators=200;, score=0.725 total time=  11.6s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=log2, n_estimators=300;, score=0.736 total time=  17.4s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.708 total time=   9.7s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.732 total time=  19.6s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.735 total time=  28.9s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=log2, n_estimators=100;, score=0.729 total time=   1.8s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=log2, n_estimators=200;, score=0.738 total time=   3.6s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=log2, n_estimators=300;, score=0.735 total time=   5.4s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.726 total time=   3.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.728 total time=   6.4s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.720 total time=   9.7s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=0.731 total time=   3.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=0.733 total time=   6.1s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=log2, n_estimators=300;, score=0.731 total time=   9.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.731 total time=   5.5s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.729 total time=  10.8s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.741 total time=  16.4s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=log2, n_estimators=100;, score=0.715 total time=   5.9s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=log2, n_estimators=200;, score=0.717 total time=  11.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=log2, n_estimators=300;, score=0.723 total time=  16.6s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.718 total time=   9.5s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.709 total time=  18.7s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.733 total time=  28.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=100;, score=0.727 total time=   1.8s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=200;, score=0.730 total time=   3.6s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=300;, score=0.736 total time=   5.4s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.725 total time=   3.3s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.728 total time=   6.4s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.728 total time=   9.8s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=100;, score=0.733 total time=   3.1s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=200;, score=0.729 total time=   6.1s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=300;, score=0.713 total time=   9.1s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.725 total time=   5.5s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.729 total time=  10.9s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.727 total time=  16.3s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=log2, n_estimators=100;, score=0.726 total time=   5.5s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=log2, n_estimators=200;, score=0.716 total time=  11.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=log2, n_estimators=300;, score=0.727 total time=  17.1s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.726 total time=   9.6s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.715 total time=  19.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.717 total time=  28.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, n_estimators=100;, score=0.728 total time=   1.8s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, n_estimators=200;, score=0.715 total time=   3.6s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, n_estimators=300;, score=0.727 total time=   5.5s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.739 total time=   3.2s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.733 total time=   6.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.722 total time=   9.8s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=0.730 total time=   3.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=0.717 total time=   6.1s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, n_estimators=300;, score=0.715 total time=   9.2s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.705 total time=   5.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.717 total time=  10.9s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.739 total time=  16.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, n_estimators=100;, score=0.713 total time=   5.5s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, n_estimators=200;, score=0.727 total time=  11.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, n_estimators=300;, score=0.713 total time=  16.5s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.709 total time=   9.3s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.718 total time=  18.6s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.737 total time=  28.1s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, n_estimators=100;, score=0.727 total time=   1.8s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, n_estimators=200;, score=0.724 total time=   3.6s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, n_estimators=300;, score=0.717 total time=   5.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.729 total time=   3.2s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.718 total time=   6.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.729 total time=   9.7s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=log2, n_estimators=100;, score=0.726 total time=   3.1s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=log2, n_estimators=200;, score=0.728 total time=   6.1s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=log2, n_estimators=300;, score=0.725 total time=   9.2s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.718 total time=   5.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.716 total time=  10.8s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.721 total time=  16.3s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=log2, n_estimators=100;, score=0.724 total time=   5.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=log2, n_estimators=200;, score=0.717 total time=  11.1s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=log2, n_estimators=300;, score=0.709 total time=  16.9s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.707 total time=   9.5s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.717 total time=  19.2s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.704 total time=  28.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "54 fits failed out of a total of 162.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.68556244 0.72010629 0.73073516 0.69530558 0.72542073 0.71922055\n",
      " 0.71213463 0.71744907 0.72896368 0.72010629 0.72542073 0.72276351\n",
      " 0.71656333 0.73339238 0.73427812 0.72099203 0.72807795 0.72364925\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.68290523 0.72276351 0.72807795 0.69707706 0.72719221 0.73073516\n",
      " 0.71124889 0.72719221 0.73427812 0.72453499 0.72807795 0.72542073\n",
      " 0.71656333 0.72542073 0.7360496  0.70770593 0.7316209  0.73516386\n",
      " 0.72896368 0.73782108 0.73516386 0.72630647 0.72807795 0.72010629\n",
      " 0.73073516 0.73339238 0.73073516 0.73073516 0.72896368 0.74136404\n",
      " 0.71479185 0.71656333 0.72276351 0.71833481 0.70859167 0.73339238\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.72719221 0.72984942 0.7360496  0.72453499 0.72807795 0.72807795\n",
      " 0.73250664 0.72896368 0.71302037 0.72542073 0.72896368 0.72719221\n",
      " 0.72630647 0.71567759 0.72719221 0.72630647 0.71479185 0.71744907\n",
      " 0.72807795 0.71479185 0.72719221 0.73870682 0.73339238 0.72187777\n",
      " 0.72984942 0.71656333 0.71479185 0.70504872 0.71656333 0.73870682\n",
      " 0.71302037 0.72719221 0.71302037 0.70947741 0.71833481 0.73693534\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.72719221 0.72364925 0.71744907 0.72896368 0.71833481 0.72896368\n",
      " 0.72630647 0.72807795 0.72542073 0.71833481 0.71567759 0.72099203\n",
      " 0.72364925 0.71656333 0.70947741 0.70682019 0.71744907 0.70416298]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.05, 'loss': 'log_loss', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 300}\n",
      "Accuracy: 71.79\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.61      0.64      1992\n",
      "           1       0.75      0.79      0.77      2844\n",
      "\n",
      "    accuracy                           0.72      4836\n",
      "   macro avg       0.71      0.70      0.70      4836\n",
      "weighted avg       0.72      0.72      0.72      4836\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1222  770]\n",
      " [ 594 2250]]\n",
      "----- Span: 7 -----\n",
      "10200 train examples\n",
      "4372 test examples\n",
      "Fitting 1 folds for each of 162 candidates, totalling 162 fits\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, n_estimators=100;, score=0.694 total time=   1.7s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, n_estimators=200;, score=0.721 total time=   3.4s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, n_estimators=300;, score=0.720 total time=   5.2s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.702 total time=   3.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.720 total time=   6.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.718 total time=   9.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=0.722 total time=   2.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=0.724 total time=   5.7s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, n_estimators=300;, score=0.723 total time=   8.6s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.725 total time=   5.1s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.722 total time=  10.1s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.722 total time=  15.2s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, n_estimators=100;, score=0.720 total time=   5.2s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, n_estimators=200;, score=0.720 total time=  10.5s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, n_estimators=300;, score=0.717 total time=  15.7s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.720 total time=   8.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.728 total time=  17.6s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.725 total time=  26.1s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, n_estimators=100;, score=0.690 total time=   1.6s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, n_estimators=200;, score=0.725 total time=   3.3s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, n_estimators=300;, score=0.713 total time=   5.1s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.704 total time=   2.9s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.720 total time=   6.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.722 total time=   9.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, n_estimators=100;, score=0.724 total time=   2.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, n_estimators=200;, score=0.723 total time=   5.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, n_estimators=300;, score=0.723 total time=   8.6s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.725 total time=   5.3s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.723 total time=  10.4s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.725 total time=  15.5s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=log2, n_estimators=100;, score=0.730 total time=   5.4s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=log2, n_estimators=200;, score=0.724 total time=  10.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=log2, n_estimators=300;, score=0.726 total time=  16.1s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.725 total time=   9.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.729 total time=  17.9s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.726 total time=  26.7s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=log2, n_estimators=100;, score=0.726 total time=   1.6s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=log2, n_estimators=200;, score=0.713 total time=   3.3s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=log2, n_estimators=300;, score=0.712 total time=   5.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.727 total time=   3.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.713 total time=   6.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.714 total time=   9.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=0.723 total time=   2.8s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=0.720 total time=   5.6s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=log2, n_estimators=300;, score=0.720 total time=   8.5s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.725 total time=   5.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.722 total time=  10.1s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.709 total time=  15.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=log2, n_estimators=100;, score=0.726 total time=   5.1s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=log2, n_estimators=200;, score=0.719 total time=  10.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=log2, n_estimators=300;, score=0.726 total time=  15.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.712 total time=   8.7s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.727 total time=  17.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.711 total time=  25.7s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=100;, score=0.728 total time=   1.6s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=200;, score=0.729 total time=   3.3s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=300;, score=0.717 total time=   5.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.723 total time=   2.9s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.720 total time=   6.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.715 total time=   9.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=100;, score=0.725 total time=   2.8s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=200;, score=0.722 total time=   5.7s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=300;, score=0.709 total time=   8.5s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.728 total time=   5.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.721 total time=  10.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.715 total time=  15.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=log2, n_estimators=100;, score=0.716 total time=   5.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=log2, n_estimators=200;, score=0.723 total time=  10.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=log2, n_estimators=300;, score=0.718 total time=  15.3s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.724 total time=   8.7s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.720 total time=  17.3s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.717 total time=  25.9s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, n_estimators=100;, score=0.722 total time=   1.6s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, n_estimators=200;, score=0.705 total time=   3.3s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, n_estimators=300;, score=0.709 total time=   5.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.714 total time=   2.9s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.704 total time=   5.9s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.715 total time=   8.9s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=0.718 total time=   2.8s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=0.714 total time=   5.6s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, n_estimators=300;, score=0.717 total time=   8.5s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.716 total time=   5.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.711 total time=  10.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.708 total time=  15.1s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, n_estimators=100;, score=0.725 total time=   5.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, n_estimators=200;, score=0.715 total time=  10.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, n_estimators=300;, score=0.726 total time=  15.1s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.718 total time=   8.6s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.726 total time=  17.2s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.714 total time=  25.8s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, n_estimators=100;, score=0.719 total time=   1.7s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, n_estimators=200;, score=0.720 total time=   3.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, n_estimators=300;, score=0.707 total time=   5.1s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.719 total time=   3.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.711 total time=   6.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.712 total time=   8.9s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=log2, n_estimators=100;, score=0.719 total time=   2.8s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=log2, n_estimators=200;, score=0.710 total time=   5.6s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=log2, n_estimators=300;, score=0.715 total time=   8.5s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.723 total time=   4.9s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.723 total time=  10.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.708 total time=  15.1s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=log2, n_estimators=100;, score=0.725 total time=   5.1s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=log2, n_estimators=200;, score=0.728 total time=  10.3s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=log2, n_estimators=300;, score=0.725 total time=  15.3s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.716 total time=   8.6s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.723 total time=  17.3s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.725 total time=  25.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "54 fits failed out of a total of 162.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.69411765 0.72058824 0.71960784 0.70196078 0.71960784 0.71764706\n",
      " 0.72156863 0.72352941 0.72254902 0.7245098  0.72156863 0.72156863\n",
      " 0.71960784 0.71960784 0.71666667 0.71960784 0.72843137 0.7245098\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.69019608 0.7254902  0.7127451  0.70392157 0.71960784 0.72156863\n",
      " 0.72352941 0.72254902 0.72254902 0.7254902  0.72254902 0.7245098\n",
      " 0.73039216 0.72352941 0.72647059 0.7254902  0.72941176 0.72647059\n",
      " 0.72647059 0.7127451  0.71176471 0.72745098 0.7127451  0.71372549\n",
      " 0.72254902 0.71960784 0.71960784 0.7254902  0.72156863 0.70882353\n",
      " 0.72647059 0.71862745 0.72647059 0.71176471 0.72745098 0.71078431\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.72843137 0.72941176 0.71666667 0.72254902 0.71960784 0.71470588\n",
      " 0.7245098  0.72156863 0.70882353 0.72843137 0.72058824 0.71470588\n",
      " 0.71568627 0.72254902 0.71764706 0.72352941 0.71960784 0.71666667\n",
      " 0.72156863 0.70490196 0.70882353 0.71372549 0.70392157 0.71470588\n",
      " 0.71764706 0.71372549 0.71666667 0.71568627 0.71078431 0.70784314\n",
      " 0.7245098  0.71470588 0.72647059 0.71764706 0.72647059 0.71372549\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.71862745 0.71960784 0.70686275 0.71862745 0.71078431 0.71176471\n",
      " 0.71862745 0.70980392 0.71470588 0.72254902 0.72254902 0.70784314\n",
      " 0.7254902  0.72843137 0.7254902  0.71568627 0.72254902 0.7254902 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 8, 'max_features': 'log2', 'n_estimators': 100}\n",
      "Accuracy: 71.84\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.49      0.59      1829\n",
      "           1       0.71      0.88      0.79      2543\n",
      "\n",
      "    accuracy                           0.72      4372\n",
      "   macro avg       0.73      0.69      0.69      4372\n",
      "weighted avg       0.73      0.72      0.70      4372\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 891  938]\n",
      " [ 293 2250]]\n"
     ]
    }
   ],
   "source": [
    "# Define the Random Forest model\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'loss': ['log_loss', 'deviance', 'exponential'],  # Loss function\n",
    "    'learning_rate': [0.01, 0.05, 0.1],  # Learning rate (eta)\n",
    "    'max_depth': [3, 5, 8],  # Maximum depth of each tree\n",
    "    'max_features': ['log2', 'sqrt'],  # Maximum number of features considered for splitting\n",
    "    'n_estimators': [100, 200, 300]  # Number of trees\n",
    "}\n",
    "\n",
    "filename = 'gradient_boosting.pkl'\n",
    "\n",
    "train_test_save(gbc, param_grid, filename, n_splits=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Span: 3 -----\n",
      "12390 train examples\n",
      "5310 test examples\n",
      "Fitting 1 folds for each of 120 candidates, totalling 120 fits\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.730 total time=   3.5s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.737 total time=   3.0s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.729 total time=   3.3s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.716 total time=   1.7s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.735 total time=   2.9s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.680 total time=   1.8s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.703 total time=   2.3s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.732 total time=   2.7s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.703 total time=   2.1s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.504 total time=   3.7s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.722 total time=   3.1s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.727 total time=   2.6s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.722 total time=   2.4s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.730 total time=   5.6s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.705 total time=   3.6s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.714 total time=   1.5s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.727 total time=   4.7s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.713 total time=   2.2s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.719 total time=   2.5s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.598 total time=   0.9s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.714 total time=   1.8s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.701 total time=   3.1s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.598 total time=   1.0s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.707 total time=   2.3s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.735 total time=   4.6s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.734 total time=   4.3s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.594 total time=   2.8s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.682 total time=   2.9s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.733 total time=   6.8s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.720 total time=   2.3s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.696 total time=   2.9s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.722 total time=   1.3s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.724 total time=   1.8s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.725 total time=   2.2s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.738 total time=   2.0s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.726 total time=   1.8s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.697 total time=   1.5s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.729 total time=   3.2s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.705 total time=   1.2s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.650 total time=   2.1s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.719 total time=   0.9s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.667 total time=   2.4s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.584 total time=   3.7s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.733 total time=   0.9s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.635 total time=   2.6s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.718 total time=   2.3s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.733 total time=   1.9s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.730 total time=   2.0s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.689 total time=   3.0s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.718 total time=   2.1s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.706 total time=   1.6s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.717 total time=   1.5s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.723 total time=   1.8s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.522 total time=   2.4s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.548 total time=   3.6s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.693 total time=   1.3s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.684 total time=   2.5s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.617 total time=   3.2s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.716 total time=   1.6s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.697 total time=   2.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.703 total time=   2.8s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.726 total time=   2.5s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.720 total time=   2.7s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.730 total time=   3.4s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.710 total time=   4.3s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.714 total time=   1.4s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.709 total time=   2.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.724 total time=   3.8s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.719 total time=   1.8s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.715 total time=   1.8s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.711 total time=   4.1s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.723 total time=   3.5s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.722 total time=   2.3s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.722 total time=   5.2s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.724 total time=   4.1s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.718 total time=   3.7s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.722 total time=   4.2s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.721 total time=   2.3s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.740 total time=   3.9s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.726 total time=   3.3s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.713 total time=   3.4s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.720 total time=   1.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.725 total time=   3.0s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.725 total time=   3.2s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.723 total time=   3.9s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.721 total time=   4.7s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.716 total time=   6.0s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.723 total time=   2.3s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.726 total time=   4.8s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.701 total time=   4.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.598 total time=   0.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.599 total time=   0.5s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.711 total time=   1.0s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.700 total time=   1.7s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.710 total time=   2.7s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.709 total time=   3.7s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.713 total time=   1.9s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.719 total time=   2.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.680 total time=   3.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.722 total time=   3.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.707 total time=   2.5s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.685 total time=   4.2s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.705 total time=   2.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.701 total time=   4.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.688 total time=   4.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.598 total time=   0.9s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.724 total time=   1.8s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.699 total time=   2.2s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.721 total time=   2.6s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.717 total time=   1.5s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.676 total time=   1.2s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.703 total time=   1.5s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.718 total time=   3.6s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.704 total time=   3.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.698 total time=   4.6s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.699 total time=   1.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.718 total time=   2.0s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.696 total time=   2.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.711 total time=   2.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.722 total time=   5.2s\n",
      "Best hyperparameters: {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': (23,), 'solver': 'adam'}\n",
      "Accuracy: 72.81\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.60      0.65      2199\n",
      "           1       0.74      0.82      0.78      3111\n",
      "\n",
      "    accuracy                           0.73      5310\n",
      "   macro avg       0.72      0.71      0.71      5310\n",
      "weighted avg       0.73      0.73      0.72      5310\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1326  873]\n",
      " [ 571 2540]]\n",
      "----- Span: 5 -----\n",
      "11282 train examples\n",
      "4836 test examples\n",
      "Fitting 1 folds for each of 120 candidates, totalling 120 fits\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.744 total time=   2.7s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.577 total time=   0.9s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.735 total time=   2.0s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.701 total time=   2.0s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.577 total time=   0.4s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.709 total time=   2.1s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.683 total time=   2.2s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.745 total time=   2.4s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.729 total time=   1.9s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.743 total time=   1.2s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.733 total time=   3.8s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.678 total time=   1.7s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.718 total time=   3.0s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.736 total time=   3.1s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.717 total time=   1.8s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.724 total time=   1.9s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.733 total time=   2.4s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.700 total time=   1.4s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.711 total time=   2.6s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.741 total time=   2.8s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.701 total time=   2.4s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.729 total time=   3.7s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.733 total time=   6.4s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.712 total time=   3.1s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.729 total time=   2.1s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.736 total time=   1.6s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.751 total time=   3.1s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.727 total time=   1.8s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.746 total time=   6.6s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.728 total time=   1.9s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.693 total time=   3.1s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.744 total time=   0.7s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.655 total time=   2.1s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.681 total time=   2.1s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.735 total time=   2.7s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.733 total time=   1.4s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.709 total time=   1.4s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.746 total time=   2.1s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.620 total time=   1.3s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.638 total time=   1.9s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.740 total time=   1.3s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.728 total time=   1.8s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.729 total time=   1.4s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.751 total time=   1.5s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.700 total time=   2.7s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.660 total time=   1.8s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.740 total time=   1.6s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.730 total time=   2.5s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.713 total time=   1.7s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.740 total time=   1.2s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.725 total time=   2.4s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.692 total time=   2.2s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.730 total time=   1.4s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.715 total time=   2.0s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.740 total time=   1.9s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.745 total time=   1.5s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.633 total time=   1.8s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.597 total time=   1.3s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.742 total time=   2.1s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.645 total time=   1.7s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.693 total time=   2.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.739 total time=   2.8s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.730 total time=   2.1s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.733 total time=   2.3s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.717 total time=   3.7s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.678 total time=   1.8s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.732 total time=   1.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.741 total time=   4.5s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.735 total time=   1.8s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.721 total time=   2.2s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.733 total time=   4.1s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.736 total time=   1.3s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.732 total time=   3.1s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.736 total time=   4.5s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.742 total time=   1.8s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.735 total time=   1.7s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.719 total time=   2.5s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.733 total time=   3.1s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.742 total time=   1.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.741 total time=   2.1s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.731 total time=   1.2s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.736 total time=   2.5s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.728 total time=   2.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.738 total time=   2.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.732 total time=   2.5s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.740 total time=   4.9s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.731 total time=   3.0s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.712 total time=   1.5s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.740 total time=   3.9s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.738 total time=   3.0s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.738 total time=   1.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.703 total time=   1.1s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.577 total time=   0.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.743 total time=   1.9s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.742 total time=   2.1s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.719 total time=   3.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.726 total time=   1.0s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.713 total time=   2.5s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.693 total time=   2.0s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.711 total time=   1.0s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.698 total time=   1.5s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.710 total time=   1.6s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.693 total time=   2.2s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.733 total time=   2.6s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.734 total time=   2.2s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.720 total time=   1.6s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.666 total time=   1.9s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.577 total time=   0.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.739 total time=   2.1s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.725 total time=   1.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.733 total time=   2.0s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.697 total time=   3.1s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.739 total time=   2.2s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.733 total time=   2.7s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.736 total time=   1.5s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.719 total time=   2.2s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.738 total time=   2.9s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.736 total time=   1.9s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.730 total time=   3.0s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.732 total time=   2.6s\n",
      "Best hyperparameters: {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (91,), 'solver': 'adam'}\n",
      "Accuracy: 72.02\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.61      0.64      1992\n",
      "           1       0.75      0.79      0.77      2844\n",
      "\n",
      "    accuracy                           0.72      4836\n",
      "   macro avg       0.71      0.70      0.71      4836\n",
      "weighted avg       0.72      0.72      0.72      4836\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1225  767]\n",
      " [ 586 2258]]\n",
      "----- Span: 7 -----\n",
      "10200 train examples\n",
      "4372 test examples\n",
      "Fitting 1 folds for each of 120 candidates, totalling 120 fits\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.709 total time=   1.6s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.575 total time=   0.3s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.575 total time=   0.7s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.735 total time=   1.8s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.734 total time=   4.2s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.716 total time=   2.2s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.738 total time=   2.2s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.727 total time=   1.3s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.713 total time=   2.0s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.706 total time=   1.8s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.721 total time=   1.5s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.730 total time=   1.1s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.734 total time=   1.5s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.725 total time=   2.6s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.731 total time=   1.7s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.722 total time=   1.8s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.575 total time=   0.3s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.712 total time=   2.0s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.638 total time=   3.0s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.575 total time=   0.7s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.707 total time=   1.3s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.717 total time=   2.0s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.575 total time=   0.9s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.727 total time=   1.5s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.731 total time=   1.1s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.733 total time=   2.1s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.656 total time=   2.5s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.635 total time=   3.2s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.730 total time=   4.2s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.698 total time=   2.4s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.723 total time=   2.5s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.735 total time=   1.4s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.722 total time=   1.6s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.722 total time=   1.2s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.733 total time=   1.5s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.698 total time=   1.9s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.725 total time=   1.5s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.737 total time=   2.4s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.679 total time=   1.0s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.578 total time=   1.8s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.735 total time=   1.0s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.671 total time=   1.9s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.715 total time=   1.6s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.736 total time=   1.3s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.717 total time=   1.8s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.714 total time=   2.1s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.740 total time=   1.9s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.692 total time=   1.6s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.688 total time=   0.8s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.736 total time=   1.4s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.694 total time=   1.7s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.720 total time=   1.0s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.734 total time=   1.4s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.608 total time=   0.6s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.462 total time=   1.2s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.726 total time=   1.0s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.636 total time=   1.2s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.578 total time=   1.8s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.729 total time=   1.7s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.658 total time=   1.7s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.733 total time=   2.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.725 total time=   4.4s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.731 total time=   2.9s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.727 total time=   1.1s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.740 total time=   2.7s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.725 total time=   2.4s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.725 total time=   2.0s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.734 total time=   3.3s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.737 total time=   1.2s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.735 total time=   1.8s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.736 total time=   3.2s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.725 total time=   2.4s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.702 total time=   2.8s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.732 total time=   5.0s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.735 total time=   3.0s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.733 total time=   1.7s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.575 total time=   0.3s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.720 total time=   2.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.730 total time=   1.7s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.737 total time=   2.5s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.727 total time=   1.5s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.734 total time=   1.4s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.731 total time=   4.2s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.728 total time=   2.8s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.724 total time=   1.2s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.726 total time=   4.4s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.719 total time=   1.8s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.712 total time=   2.8s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.737 total time=   4.4s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.710 total time=   1.8s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.575 total time=   0.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.654 total time=   1.7s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.575 total time=   0.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.575 total time=   0.5s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.575 total time=   0.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.734 total time=   2.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.679 total time=   2.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.668 total time=   1.5s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.729 total time=   2.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.738 total time=   3.6s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.725 total time=   1.9s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.728 total time=   2.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.721 total time=   2.8s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.721 total time=   1.6s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.718 total time=   1.7s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.575 total time=   0.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.695 total time=   0.9s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.575 total time=   0.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.729 total time=   1.2s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.730 total time=   1.6s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.575 total time=   0.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.690 total time=   0.9s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.689 total time=   1.8s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.732 total time=   2.7s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.732 total time=   1.5s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.715 total time=   1.8s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.712 total time=   2.0s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.675 total time=   1.1s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.732 total time=   1.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.712 total time=   1.8s\n",
      "Best hyperparameters: {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': (12,), 'solver': 'sgd'}\n",
      "Accuracy: 73.15\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.66      0.67      1829\n",
      "           1       0.76      0.78      0.77      2543\n",
      "\n",
      "    accuracy                           0.73      4372\n",
      "   macro avg       0.72      0.72      0.72      4372\n",
      "weighted avg       0.73      0.73      0.73      4372\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1213  616]\n",
      " [ 558 1985]]\n"
     ]
    }
   ],
   "source": [
    "# Define the MLP model\n",
    "mlp_model = MLPClassifier()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(12,), (23,), (45,), (91,), (181,)],  # Vary the number of neurons in the hidden layer\n",
    "    'activation': ['relu', 'identity', 'logistic', 'tanh'],  # Vary the activation function\n",
    "    'solver': ['adam', 'sgd', 'adam'],  # Vary the solver\n",
    "    'alpha': [0.0001, 0.001],  # Vary the L2 regularization strength\n",
    "}\n",
    "\n",
    "filename = 'multilayer_perceptron.pkl'\n",
    "\n",
    "train_test_save(mlp_model, param_grid, filename, n_splits=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlmb-utils",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
