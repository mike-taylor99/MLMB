{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import ShuffleSplit, GridSearchCV\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(span = 5):\n",
    "    path = os.path.abspath(f'../../data/{span}span_training_set.csv')\n",
    "    training_df = pd.read_csv(path)\n",
    "\n",
    "    path = os.path.abspath(f'../../data/{span}span_testing_set.csv')\n",
    "    testing_df = pd.read_csv(path)\n",
    "\n",
    "    train_true, test_true = training_df.pop('Win'), testing_df.pop('Win')\n",
    "\n",
    "    print(f'{len(training_df)} train examples')\n",
    "    print(f'{len(testing_df)} test examples')\n",
    "\n",
    "    return training_df, testing_df, train_true, test_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(estimator, param_grid, training_df, train_true, n_splits = 5):\n",
    "    # Create the grid search object\n",
    "    grid_search = GridSearchCV(estimator, param_grid, cv=ShuffleSplit(n_splits), verbose=5)\n",
    "\n",
    "    # Fit the grid search to the data\n",
    "    grid_search.fit(training_df, train_true)\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(clf, testing_df, test_true):\n",
    "    y_pred = clf.predict(testing_df)\n",
    "\n",
    "    accuracy = accuracy_score(test_true, y_pred)\n",
    "    print(f\"Accuracy: {(accuracy*100):.2f}\")\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(test_true, y_pred))\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(test_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename):\n",
    "    path = os.path.abspath(f'../model/mens/{filename}')\n",
    "    pickle.dump(model, open(path, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPANS = [3, 5, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_save(estimator, param_grid, filename, spans = [3, 5, 7], n_splits = 5):\n",
    "    for span in spans:\n",
    "        print(f'----- Span: {span} -----')\n",
    "        \n",
    "        training_df, testing_df, train_true, test_true = get_datasets(span)\n",
    "        clf = train_model(estimator, param_grid, training_df, train_true, n_splits)\n",
    "        test_model(clf, testing_df, test_true)\n",
    "        save_model(clf, f'{span}span_{filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Span: 3 -----\n",
      "14373 train examples\n",
      "6160 test examples\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[CV 1/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.713 total time=   1.3s\n",
      "[CV 2/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.671 total time=   1.6s\n",
      "[CV 3/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.693 total time=   1.1s\n",
      "[CV 4/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.673 total time=   1.5s\n",
      "[CV 5/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.688 total time=   1.1s\n",
      "[CV 1/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.713 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.669 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.693 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.673 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.688 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.714 total time=   3.6s\n",
      "[CV 2/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.680 total time=   4.1s\n",
      "[CV 3/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.691 total time=   4.3s\n",
      "[CV 4/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.674 total time=   4.1s\n",
      "[CV 5/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.692 total time=   4.4s\n",
      "[CV 1/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.715 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.681 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.694 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.675 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.689 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.715 total time=  11.5s\n",
      "[CV 2/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.686 total time=   9.8s\n",
      "[CV 3/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.686 total time=   9.1s\n",
      "[CV 4/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.666 total time=   8.4s\n",
      "[CV 5/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.687 total time=   8.4s\n",
      "[CV 1/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.712 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.686 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.686 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.666 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.688 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.716 total time=  20.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.686 total time=  24.8s\n",
      "[CV 3/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.686 total time=  22.2s\n",
      "[CV 4/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.666 total time=  20.0s\n",
      "[CV 5/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.686 total time=  21.5s\n",
      "[CV 1/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.687 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.684 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.669 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.687 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.718 total time=  27.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.687 total time=  26.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.684 total time=  27.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.666 total time=  25.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.688 total time=  26.4s\n",
      "[CV 1/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.716 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.688 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.681 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.669 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.688 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.717 total time=  26.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.690 total time=  25.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.685 total time=  26.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.668 total time=  26.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.690 total time=  26.0s\n",
      "[CV 1/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.711 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.683 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.679 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.670 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.684 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.718 total time=  25.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.686 total time=  25.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.687 total time=  25.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.666 total time=  26.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.687 total time=  25.3s\n",
      "[CV 1/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.708 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.684 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.676 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.668 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.684 total time=   0.0s\n",
      "Best hyperparameters: {'C': 0.01, 'max_iter': 100000000000, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n",
      "Accuracy: 68.25\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.48      0.55      2507\n",
      "           1       0.70      0.82      0.75      3653\n",
      "\n",
      "    accuracy                           0.68      6160\n",
      "   macro avg       0.67      0.65      0.65      6160\n",
      "weighted avg       0.68      0.68      0.67      6160\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1200 1307]\n",
      " [ 649 3004]]\n",
      "----- Span: 5 -----\n",
      "13093 train examples\n",
      "5612 test examples\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[CV 1/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.671 total time=   0.8s\n",
      "[CV 2/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.669 total time=   0.9s\n",
      "[CV 3/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.670 total time=   0.9s\n",
      "[CV 4/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.675 total time=   1.0s\n",
      "[CV 5/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.693 total time=   0.9s\n",
      "[CV 1/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.669 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.672 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.676 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.695 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.669 total time=   2.3s\n",
      "[CV 2/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.682 total time=   2.4s\n",
      "[CV 3/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.671 total time=   2.5s\n",
      "[CV 4/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.679 total time=   2.6s\n",
      "[CV 5/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.691 total time=   2.2s\n",
      "[CV 1/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.670 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.682 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.670 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.677 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.692 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.666 total time=   7.1s\n",
      "[CV 2/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.682 total time=   5.7s\n",
      "[CV 3/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.669 total time=   6.9s\n",
      "[CV 4/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.676 total time=   6.4s\n",
      "[CV 5/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.689 total time=   6.4s\n",
      "[CV 1/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.666 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.682 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.669 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.674 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.690 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.666 total time=  15.3s\n",
      "[CV 2/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.685 total time=  13.5s\n",
      "[CV 3/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.669 total time=  18.1s\n",
      "[CV 4/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.676 total time=  16.1s\n",
      "[CV 5/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.687 total time=  15.2s\n",
      "[CV 1/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.667 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.684 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.669 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.679 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.690 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.666 total time=  19.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.681 total time=  20.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.673 total time=  20.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.676 total time=  20.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.687 total time=  19.4s\n",
      "[CV 1/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.664 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.681 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.669 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.676 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.687 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.665 total time=  19.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.679 total time=  19.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.671 total time=  19.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.677 total time=  21.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.689 total time=  21.9s\n",
      "[CV 1/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.669 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.679 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.676 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.678 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.686 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.664 total time=  22.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.683 total time=  23.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.673 total time=  22.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.682 total time=  21.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.690 total time=  21.2s\n",
      "[CV 1/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.667 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.674 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.673 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.679 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.683 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 1000, 'max_iter': 100000000000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Accuracy: 67.75\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.51      0.55      2224\n",
      "           1       0.71      0.79      0.75      3388\n",
      "\n",
      "    accuracy                           0.68      5612\n",
      "   macro avg       0.66      0.65      0.65      5612\n",
      "weighted avg       0.67      0.68      0.67      5612\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1128 1096]\n",
      " [ 714 2674]]\n",
      "----- Span: 7 -----\n",
      "11907 train examples\n",
      "5104 test examples\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[CV 1/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.680 total time=   0.8s\n",
      "[CV 2/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.672 total time=   0.8s\n",
      "[CV 3/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.678 total time=   0.9s\n",
      "[CV 4/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.697 total time=   0.8s\n",
      "[CV 5/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.679 total time=   0.8s\n",
      "[CV 1/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.678 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.672 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.678 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.697 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.679 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.679 total time=   2.3s\n",
      "[CV 2/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.677 total time=   2.0s\n",
      "[CV 3/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.688 total time=   2.0s\n",
      "[CV 4/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.699 total time=   2.2s\n",
      "[CV 5/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.686 total time=   1.8s\n",
      "[CV 1/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.679 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.677 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.688 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.699 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.686 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.670 total time=   4.9s\n",
      "[CV 2/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.681 total time=   5.3s\n",
      "[CV 3/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.679 total time=   6.0s\n",
      "[CV 4/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.698 total time=   6.4s\n",
      "[CV 5/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.674 total time=   5.3s\n",
      "[CV 1/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.673 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.680 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.678 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.699 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.678 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.668 total time=  15.0s\n",
      "[CV 2/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.683 total time=  11.9s\n",
      "[CV 3/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.679 total time=  13.0s\n",
      "[CV 4/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.697 total time=  12.6s\n",
      "[CV 5/5] END C=1, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.678 total time=  14.4s\n",
      "[CV 1/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.668 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.682 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.679 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.696 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.677 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.673 total time=  16.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.683 total time=  16.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.683 total time=  18.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.694 total time=  19.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.680 total time=  19.3s\n",
      "[CV 1/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.674 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.682 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.680 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.694 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.679 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.674 total time=  19.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.685 total time=  20.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.683 total time=  19.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.695 total time=  18.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.678 total time=  16.3s\n",
      "[CV 1/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.677 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.678 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.681 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.696 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.677 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.673 total time=  16.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.684 total time=  17.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.687 total time=  17.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.693 total time=  18.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1000, max_iter=100000000000, penalty=l2, solver=lbfgs;, score=0.677 total time=  19.2s\n",
      "[CV 1/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.677 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.678 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.679 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.696 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=100000000000, penalty=l2, solver=newton-cholesky;, score=0.673 total time=   0.0s\n",
      "Best hyperparameters: {'C': 0.01, 'max_iter': 100000000000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Accuracy: 69.02\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.51      0.57      2060\n",
      "           1       0.71      0.81      0.76      3044\n",
      "\n",
      "    accuracy                           0.69      5104\n",
      "   macro avg       0.68      0.66      0.66      5104\n",
      "weighted avg       0.68      0.69      0.68      5104\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1060 1000]\n",
      " [ 581 2463]]\n"
     ]
    }
   ],
   "source": [
    "# Define the Logistic Regression model\n",
    "logreg_model = LogisticRegression()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'penalty': ['l2'],  # Vary the regularization type\n",
    "    'solver': ['lbfgs', 'newton-cholesky'],\n",
    "    'max_iter': [int(10e10)]\n",
    "}\n",
    "\n",
    "filename = 'logistic_regression_model.pkl'\n",
    "\n",
    "train_test_save(logreg_model, param_grid, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Span: 3 -----\n",
      "14373 train examples\n",
      "6160 test examples\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "[CV 1/1] END C=0.01, gamma=0.1, kernel=linear, probability=True;, score=0.670 total time= 2.6min\n",
      "Best hyperparameters: {'C': 0.01, 'gamma': 0.1, 'kernel': 'linear', 'probability': True}\n",
      "Accuracy: 68.02\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.47      0.55      2507\n",
      "           1       0.69      0.82      0.75      3653\n",
      "\n",
      "    accuracy                           0.68      6160\n",
      "   macro avg       0.67      0.65      0.65      6160\n",
      "weighted avg       0.67      0.68      0.67      6160\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1186 1321]\n",
      " [ 649 3004]]\n",
      "----- Span: 5 -----\n",
      "13093 train examples\n",
      "5612 test examples\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "[CV 1/1] END C=0.01, gamma=0.1, kernel=linear, probability=True;, score=0.669 total time= 1.9min\n",
      "Best hyperparameters: {'C': 0.01, 'gamma': 0.1, 'kernel': 'linear', 'probability': True}\n",
      "Accuracy: 67.78\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.49      0.55      2224\n",
      "           1       0.71      0.80      0.75      3388\n",
      "\n",
      "    accuracy                           0.68      5612\n",
      "   macro avg       0.66      0.65      0.65      5612\n",
      "weighted avg       0.67      0.68      0.67      5612\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1099 1125]\n",
      " [ 683 2705]]\n",
      "----- Span: 7 -----\n",
      "11907 train examples\n",
      "5104 test examples\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "[CV 1/1] END C=0.01, gamma=0.1, kernel=linear, probability=True;, score=0.690 total time= 1.4min\n",
      "Best hyperparameters: {'C': 0.01, 'gamma': 0.1, 'kernel': 'linear', 'probability': True}\n",
      "Accuracy: 68.32\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.50      0.56      2060\n",
      "           1       0.70      0.81      0.75      3044\n",
      "\n",
      "    accuracy                           0.68      5104\n",
      "   macro avg       0.67      0.65      0.66      5104\n",
      "weighted avg       0.68      0.68      0.67      5104\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1030 1030]\n",
      " [ 587 2457]]\n"
     ]
    }
   ],
   "source": [
    "# Define the SVM model\n",
    "svm_model = SVC()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "# param_grid = {\n",
    "#     'C': [0.01, 0.1, 1, 10],\n",
    "#     'kernel': ['linear', 'rbf', 'sigmoid'],\n",
    "#     'gamma': [0.1, 0.01, 0.001],\n",
    "#     # 'probability': [True]\n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01],\n",
    "    'kernel': ['linear'],\n",
    "    'gamma': [0.1],\n",
    "    'probability': [True]\n",
    "}\n",
    "\n",
    "filename = 'support_vector_machine_model.pkl'\n",
    "\n",
    "train_test_save(svm_model, param_grid, filename, n_splits=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Span: 3 -----\n",
      "14373 train examples\n",
      "6160 test examples\n",
      "Fitting 1 folds for each of 240 candidates, totalling 240 fits\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=1, p=1, weights=uniform;, score=0.583 total time=   0.4s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=1, p=1, weights=distance;, score=0.583 total time=   0.4s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=1, p=2, weights=uniform;, score=0.552 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=1, p=2, weights=distance;, score=0.552 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.601 total time=   0.4s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=3, p=1, weights=distance;, score=0.601 total time=   0.4s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.581 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=3, p=2, weights=distance;, score=0.581 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.631 total time=   0.4s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=5, p=1, weights=distance;, score=0.631 total time=   0.4s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.615 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=5, p=2, weights=distance;, score=0.615 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.640 total time=   0.5s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=7, p=1, weights=distance;, score=0.640 total time=   0.4s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.634 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=7, p=2, weights=distance;, score=0.634 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=10, p=1, weights=uniform;, score=0.637 total time=   0.4s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=10, p=1, weights=distance;, score=0.640 total time=   0.4s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=10, p=2, weights=uniform;, score=0.628 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=10, p=2, weights=distance;, score=0.637 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=1, p=1, weights=uniform;, score=0.583 total time=   0.4s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=1, p=1, weights=distance;, score=0.583 total time=   0.4s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=1, p=2, weights=uniform;, score=0.552 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=1, p=2, weights=distance;, score=0.552 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.601 total time=   0.5s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=3, p=1, weights=distance;, score=0.601 total time=   0.4s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.581 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=3, p=2, weights=distance;, score=0.581 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.631 total time=   0.5s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=5, p=1, weights=distance;, score=0.631 total time=   0.4s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.615 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=5, p=2, weights=distance;, score=0.615 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.640 total time=   0.4s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=7, p=1, weights=distance;, score=0.640 total time=   0.4s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.634 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=7, p=2, weights=distance;, score=0.634 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=10, p=1, weights=uniform;, score=0.637 total time=   0.4s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=10, p=1, weights=distance;, score=0.640 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=10, p=2, weights=uniform;, score=0.628 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=10, p=2, weights=distance;, score=0.637 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=1, p=1, weights=uniform;, score=0.583 total time=   0.4s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=1, p=1, weights=distance;, score=0.583 total time=   0.4s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=1, p=2, weights=uniform;, score=0.552 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=1, p=2, weights=distance;, score=0.552 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.601 total time=   0.4s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=3, p=1, weights=distance;, score=0.601 total time=   0.4s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.581 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=3, p=2, weights=distance;, score=0.581 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.631 total time=   0.5s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=5, p=1, weights=distance;, score=0.631 total time=   0.4s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.615 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=5, p=2, weights=distance;, score=0.615 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.640 total time=   0.4s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=7, p=1, weights=distance;, score=0.640 total time=   0.4s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.634 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=7, p=2, weights=distance;, score=0.634 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=10, p=1, weights=uniform;, score=0.637 total time=   0.4s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=10, p=1, weights=distance;, score=0.640 total time=   0.4s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=10, p=2, weights=uniform;, score=0.628 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=10, p=2, weights=distance;, score=0.637 total time=   0.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=1, p=1, weights=uniform;, score=0.583 total time=   4.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=1, p=1, weights=distance;, score=0.583 total time=   4.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=1, p=2, weights=uniform;, score=0.552 total time=   4.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=1, p=2, weights=distance;, score=0.552 total time=   4.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.601 total time=   4.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=3, p=1, weights=distance;, score=0.601 total time=   4.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.581 total time=   4.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=3, p=2, weights=distance;, score=0.581 total time=   5.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.631 total time=   5.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=5, p=1, weights=distance;, score=0.631 total time=   5.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.615 total time=   5.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=5, p=2, weights=distance;, score=0.615 total time=   4.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.640 total time=   5.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=7, p=1, weights=distance;, score=0.640 total time=   4.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.634 total time=   4.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=7, p=2, weights=distance;, score=0.634 total time=   4.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=10, p=1, weights=uniform;, score=0.637 total time=   4.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=10, p=1, weights=distance;, score=0.640 total time=   4.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=10, p=2, weights=uniform;, score=0.628 total time=   4.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=10, p=2, weights=distance;, score=0.637 total time=   4.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=1, p=1, weights=uniform;, score=0.583 total time=   4.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=1, p=1, weights=distance;, score=0.583 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=1, p=2, weights=uniform;, score=0.552 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=1, p=2, weights=distance;, score=0.552 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.601 total time=   4.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=3, p=1, weights=distance;, score=0.601 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.581 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=3, p=2, weights=distance;, score=0.581 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.631 total time=   4.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=5, p=1, weights=distance;, score=0.631 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.615 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=5, p=2, weights=distance;, score=0.615 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.640 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=7, p=1, weights=distance;, score=0.640 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.634 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=7, p=2, weights=distance;, score=0.634 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=10, p=1, weights=uniform;, score=0.637 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=10, p=1, weights=distance;, score=0.640 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=10, p=2, weights=uniform;, score=0.628 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=10, p=2, weights=distance;, score=0.637 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=1, p=1, weights=uniform;, score=0.583 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=1, p=1, weights=distance;, score=0.583 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=1, p=2, weights=uniform;, score=0.552 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=1, p=2, weights=distance;, score=0.552 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.601 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=3, p=1, weights=distance;, score=0.601 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.581 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=3, p=2, weights=distance;, score=0.581 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.631 total time=   4.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=5, p=1, weights=distance;, score=0.631 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.615 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=5, p=2, weights=distance;, score=0.615 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.640 total time=   4.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=7, p=1, weights=distance;, score=0.640 total time=   4.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.634 total time=   4.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=7, p=2, weights=distance;, score=0.634 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=10, p=1, weights=uniform;, score=0.637 total time=   4.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=10, p=1, weights=distance;, score=0.640 total time=   4.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=10, p=2, weights=uniform;, score=0.628 total time=   4.7s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=10, p=2, weights=distance;, score=0.637 total time=   4.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=1, p=1, weights=uniform;, score=0.583 total time=   5.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=1, p=1, weights=distance;, score=0.583 total time=   5.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=1, p=2, weights=uniform;, score=0.552 total time=   6.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=1, p=2, weights=distance;, score=0.552 total time=   6.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.601 total time=   5.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=3, p=1, weights=distance;, score=0.601 total time=   5.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.581 total time=   7.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=3, p=2, weights=distance;, score=0.581 total time=   7.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.631 total time=   5.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=5, p=1, weights=distance;, score=0.631 total time=   5.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.615 total time=   7.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=5, p=2, weights=distance;, score=0.615 total time=   7.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.640 total time=   5.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=7, p=1, weights=distance;, score=0.640 total time=   5.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.634 total time=   7.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=7, p=2, weights=distance;, score=0.634 total time=   7.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=10, p=1, weights=uniform;, score=0.637 total time=   5.9s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=10, p=1, weights=distance;, score=0.640 total time=   5.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=10, p=2, weights=uniform;, score=0.628 total time=   7.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=10, p=2, weights=distance;, score=0.637 total time=   7.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=1, p=1, weights=uniform;, score=0.583 total time=   5.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=1, p=1, weights=distance;, score=0.583 total time=   5.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=1, p=2, weights=uniform;, score=0.552 total time=   5.5s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=1, p=2, weights=distance;, score=0.552 total time=   5.5s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.601 total time=   5.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=3, p=1, weights=distance;, score=0.601 total time=   5.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.581 total time=   5.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=3, p=2, weights=distance;, score=0.581 total time=   5.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.631 total time=   5.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=5, p=1, weights=distance;, score=0.631 total time=   5.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.615 total time=   5.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=5, p=2, weights=distance;, score=0.615 total time=   5.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.640 total time=   5.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=7, p=1, weights=distance;, score=0.640 total time=   5.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.634 total time=   5.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=7, p=2, weights=distance;, score=0.634 total time=   5.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=10, p=1, weights=uniform;, score=0.637 total time=   5.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=10, p=1, weights=distance;, score=0.640 total time=   5.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=10, p=2, weights=uniform;, score=0.628 total time=   5.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=10, p=2, weights=distance;, score=0.637 total time=   5.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=1, p=1, weights=uniform;, score=0.583 total time=   5.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=1, p=1, weights=distance;, score=0.583 total time=   5.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=1, p=2, weights=uniform;, score=0.552 total time=   5.5s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=1, p=2, weights=distance;, score=0.552 total time=   5.5s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.601 total time=   5.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=3, p=1, weights=distance;, score=0.601 total time=   5.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.581 total time=   5.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=3, p=2, weights=distance;, score=0.581 total time=   5.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.631 total time=   5.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=5, p=1, weights=distance;, score=0.631 total time=   5.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.615 total time=   5.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=5, p=2, weights=distance;, score=0.615 total time=   5.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.640 total time=   5.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=7, p=1, weights=distance;, score=0.640 total time=   5.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.634 total time=   5.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=7, p=2, weights=distance;, score=0.634 total time=   5.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=10, p=1, weights=uniform;, score=0.637 total time=   5.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=10, p=1, weights=distance;, score=0.640 total time=   5.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=10, p=2, weights=uniform;, score=0.628 total time=   5.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=10, p=2, weights=distance;, score=0.637 total time=   5.7s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=1, p=1, weights=uniform;, score=0.583 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=1, p=1, weights=distance;, score=0.583 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=1, p=2, weights=uniform;, score=0.552 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=1, p=2, weights=distance;, score=0.552 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.601 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=3, p=1, weights=distance;, score=0.601 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.581 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=3, p=2, weights=distance;, score=0.581 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.631 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=5, p=1, weights=distance;, score=0.631 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.615 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=5, p=2, weights=distance;, score=0.615 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.640 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=7, p=1, weights=distance;, score=0.640 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.634 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=7, p=2, weights=distance;, score=0.634 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=10, p=1, weights=uniform;, score=0.637 total time=   0.5s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=10, p=1, weights=distance;, score=0.640 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=10, p=2, weights=uniform;, score=0.628 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=10, p=2, weights=distance;, score=0.637 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=1, p=1, weights=uniform;, score=0.583 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=1, p=1, weights=distance;, score=0.583 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=1, p=2, weights=uniform;, score=0.552 total time=   0.1s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=1, p=2, weights=distance;, score=0.552 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.601 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=3, p=1, weights=distance;, score=0.601 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.581 total time=   0.1s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=3, p=2, weights=distance;, score=0.581 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.631 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=5, p=1, weights=distance;, score=0.631 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.615 total time=   0.1s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=5, p=2, weights=distance;, score=0.615 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.640 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=7, p=1, weights=distance;, score=0.640 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.634 total time=   0.1s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=7, p=2, weights=distance;, score=0.634 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=10, p=1, weights=uniform;, score=0.637 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=10, p=1, weights=distance;, score=0.640 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=10, p=2, weights=uniform;, score=0.628 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=10, p=2, weights=distance;, score=0.637 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=1, p=1, weights=uniform;, score=0.583 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=1, p=1, weights=distance;, score=0.583 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=1, p=2, weights=uniform;, score=0.552 total time=   0.1s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=1, p=2, weights=distance;, score=0.552 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.601 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=3, p=1, weights=distance;, score=0.601 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.581 total time=   0.1s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=3, p=2, weights=distance;, score=0.581 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.631 total time=   0.5s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=5, p=1, weights=distance;, score=0.631 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.615 total time=   0.1s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=5, p=2, weights=distance;, score=0.615 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.640 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=7, p=1, weights=distance;, score=0.640 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.634 total time=   0.1s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=7, p=2, weights=distance;, score=0.634 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=10, p=1, weights=uniform;, score=0.637 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=10, p=1, weights=distance;, score=0.640 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=10, p=2, weights=uniform;, score=0.628 total time=   0.1s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=10, p=2, weights=distance;, score=0.637 total time=   0.0s\n",
      "Best hyperparameters: {'algorithm': 'auto', 'leaf_size': 15, 'n_neighbors': 7, 'p': 1, 'weights': 'uniform'}\n",
      "Accuracy: 62.18\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.43      0.48      2507\n",
      "           1       0.66      0.75      0.70      3653\n",
      "\n",
      "    accuracy                           0.62      6160\n",
      "   macro avg       0.60      0.59      0.59      6160\n",
      "weighted avg       0.61      0.62      0.61      6160\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1088 1419]\n",
      " [ 911 2742]]\n",
      "----- Span: 5 -----\n",
      "13093 train examples\n",
      "5612 test examples\n",
      "Fitting 1 folds for each of 240 candidates, totalling 240 fits\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=1, p=1, weights=uniform;, score=0.581 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=1, p=1, weights=distance;, score=0.581 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=1, p=2, weights=uniform;, score=0.574 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=1, p=2, weights=distance;, score=0.574 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.582 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=3, p=1, weights=distance;, score=0.583 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.592 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=3, p=2, weights=distance;, score=0.592 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.613 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=5, p=1, weights=distance;, score=0.612 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.606 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=5, p=2, weights=distance;, score=0.605 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.615 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=7, p=1, weights=distance;, score=0.615 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.620 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=7, p=2, weights=distance;, score=0.619 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=10, p=1, weights=uniform;, score=0.628 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=10, p=1, weights=distance;, score=0.624 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=10, p=2, weights=uniform;, score=0.618 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=10, p=2, weights=distance;, score=0.617 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=1, p=1, weights=uniform;, score=0.581 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=1, p=1, weights=distance;, score=0.581 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=1, p=2, weights=uniform;, score=0.574 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=1, p=2, weights=distance;, score=0.574 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.582 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=3, p=1, weights=distance;, score=0.583 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.592 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=3, p=2, weights=distance;, score=0.592 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.613 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=5, p=1, weights=distance;, score=0.612 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.606 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=5, p=2, weights=distance;, score=0.605 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.615 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=7, p=1, weights=distance;, score=0.615 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.620 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=7, p=2, weights=distance;, score=0.619 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=10, p=1, weights=uniform;, score=0.628 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=10, p=1, weights=distance;, score=0.624 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=10, p=2, weights=uniform;, score=0.618 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=10, p=2, weights=distance;, score=0.617 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=1, p=1, weights=uniform;, score=0.581 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=1, p=1, weights=distance;, score=0.581 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=1, p=2, weights=uniform;, score=0.574 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=1, p=2, weights=distance;, score=0.574 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.582 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=3, p=1, weights=distance;, score=0.583 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.592 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=3, p=2, weights=distance;, score=0.592 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.613 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=5, p=1, weights=distance;, score=0.612 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.606 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=5, p=2, weights=distance;, score=0.605 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.615 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=7, p=1, weights=distance;, score=0.615 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.620 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=7, p=2, weights=distance;, score=0.619 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=10, p=1, weights=uniform;, score=0.628 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=10, p=1, weights=distance;, score=0.624 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=10, p=2, weights=uniform;, score=0.618 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=10, p=2, weights=distance;, score=0.617 total time=   0.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=1, p=1, weights=uniform;, score=0.581 total time=   4.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=1, p=1, weights=distance;, score=0.581 total time=   4.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=1, p=2, weights=uniform;, score=0.574 total time=   4.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=1, p=2, weights=distance;, score=0.574 total time=   3.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.582 total time=   4.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=3, p=1, weights=distance;, score=0.583 total time=   4.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.592 total time=   4.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=3, p=2, weights=distance;, score=0.592 total time=   4.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.613 total time=   4.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=5, p=1, weights=distance;, score=0.612 total time=   4.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.606 total time=   4.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=5, p=2, weights=distance;, score=0.605 total time=   4.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.615 total time=   4.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=7, p=1, weights=distance;, score=0.615 total time=   4.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.620 total time=   4.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=7, p=2, weights=distance;, score=0.619 total time=   4.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=10, p=1, weights=uniform;, score=0.628 total time=   4.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=10, p=1, weights=distance;, score=0.624 total time=   4.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=10, p=2, weights=uniform;, score=0.618 total time=   4.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=10, p=2, weights=distance;, score=0.617 total time=   4.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=1, p=1, weights=uniform;, score=0.581 total time=   3.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=1, p=1, weights=distance;, score=0.581 total time=   4.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=1, p=2, weights=uniform;, score=0.574 total time=   4.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=1, p=2, weights=distance;, score=0.574 total time=   3.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.582 total time=   4.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=3, p=1, weights=distance;, score=0.583 total time=   3.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.592 total time=   3.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=3, p=2, weights=distance;, score=0.592 total time=   3.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.613 total time=   3.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=5, p=1, weights=distance;, score=0.612 total time=   3.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.606 total time=   3.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=5, p=2, weights=distance;, score=0.605 total time=   3.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.615 total time=   3.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=7, p=1, weights=distance;, score=0.615 total time=   3.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.620 total time=   3.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=7, p=2, weights=distance;, score=0.619 total time=   3.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=10, p=1, weights=uniform;, score=0.628 total time=   3.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=10, p=1, weights=distance;, score=0.624 total time=   3.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=10, p=2, weights=uniform;, score=0.618 total time=   3.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=10, p=2, weights=distance;, score=0.617 total time=   3.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=1, p=1, weights=uniform;, score=0.581 total time=   3.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=1, p=1, weights=distance;, score=0.581 total time=   3.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=1, p=2, weights=uniform;, score=0.574 total time=   3.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=1, p=2, weights=distance;, score=0.574 total time=   3.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.582 total time=   3.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=3, p=1, weights=distance;, score=0.583 total time=   3.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.592 total time=   3.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=3, p=2, weights=distance;, score=0.592 total time=   3.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.613 total time=   3.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=5, p=1, weights=distance;, score=0.612 total time=   3.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.606 total time=   3.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=5, p=2, weights=distance;, score=0.605 total time=   3.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.615 total time=   3.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=7, p=1, weights=distance;, score=0.615 total time=   3.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.620 total time=   3.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=7, p=2, weights=distance;, score=0.619 total time=   3.8s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=10, p=1, weights=uniform;, score=0.628 total time=   3.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=10, p=1, weights=distance;, score=0.624 total time=   3.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=10, p=2, weights=uniform;, score=0.618 total time=   3.9s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=10, p=2, weights=distance;, score=0.617 total time=   3.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=1, p=1, weights=uniform;, score=0.581 total time=   4.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=1, p=1, weights=distance;, score=0.581 total time=   4.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=1, p=2, weights=uniform;, score=0.574 total time=   5.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=1, p=2, weights=distance;, score=0.574 total time=   5.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.582 total time=   4.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=3, p=1, weights=distance;, score=0.583 total time=   4.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.592 total time=   6.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=3, p=2, weights=distance;, score=0.592 total time=   6.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.613 total time=   4.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=5, p=1, weights=distance;, score=0.612 total time=   4.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.606 total time=   6.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=5, p=2, weights=distance;, score=0.605 total time=   6.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.615 total time=   4.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=7, p=1, weights=distance;, score=0.615 total time=   4.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.620 total time=   6.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=7, p=2, weights=distance;, score=0.619 total time=   6.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=10, p=1, weights=uniform;, score=0.628 total time=   4.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=10, p=1, weights=distance;, score=0.624 total time=   4.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=10, p=2, weights=uniform;, score=0.618 total time=   6.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=10, p=2, weights=distance;, score=0.617 total time=   6.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=1, p=1, weights=uniform;, score=0.581 total time=   4.3s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=1, p=1, weights=distance;, score=0.581 total time=   4.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=1, p=2, weights=uniform;, score=0.574 total time=   4.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=1, p=2, weights=distance;, score=0.574 total time=   4.5s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.582 total time=   4.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=3, p=1, weights=distance;, score=0.583 total time=   4.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.592 total time=   4.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=3, p=2, weights=distance;, score=0.592 total time=   4.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.613 total time=   4.3s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=5, p=1, weights=distance;, score=0.612 total time=   4.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.606 total time=   4.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=5, p=2, weights=distance;, score=0.605 total time=   4.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.615 total time=   4.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=7, p=1, weights=distance;, score=0.615 total time=   4.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.620 total time=   4.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=7, p=2, weights=distance;, score=0.619 total time=   4.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=10, p=1, weights=uniform;, score=0.628 total time=   4.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=10, p=1, weights=distance;, score=0.624 total time=   4.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=10, p=2, weights=uniform;, score=0.618 total time=   4.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=10, p=2, weights=distance;, score=0.617 total time=   4.9s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=1, p=1, weights=uniform;, score=0.581 total time=   4.5s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=1, p=1, weights=distance;, score=0.581 total time=   4.3s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=1, p=2, weights=uniform;, score=0.574 total time=   4.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=1, p=2, weights=distance;, score=0.574 total time=   4.5s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.582 total time=   4.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=3, p=1, weights=distance;, score=0.583 total time=   4.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.592 total time=   4.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=3, p=2, weights=distance;, score=0.592 total time=   4.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.613 total time=   4.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=5, p=1, weights=distance;, score=0.612 total time=   4.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.606 total time=   4.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=5, p=2, weights=distance;, score=0.605 total time=   4.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.615 total time=   4.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=7, p=1, weights=distance;, score=0.615 total time=   4.3s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.620 total time=   4.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=7, p=2, weights=distance;, score=0.619 total time=   4.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=10, p=1, weights=uniform;, score=0.628 total time=   4.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=10, p=1, weights=distance;, score=0.624 total time=   4.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=10, p=2, weights=uniform;, score=0.618 total time=   4.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=10, p=2, weights=distance;, score=0.617 total time=   4.8s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=1, p=1, weights=uniform;, score=0.581 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=1, p=1, weights=distance;, score=0.581 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=1, p=2, weights=uniform;, score=0.574 total time=   0.1s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=1, p=2, weights=distance;, score=0.574 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.582 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=3, p=1, weights=distance;, score=0.583 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.592 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=3, p=2, weights=distance;, score=0.592 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.613 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=5, p=1, weights=distance;, score=0.612 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.606 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=5, p=2, weights=distance;, score=0.605 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.615 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=7, p=1, weights=distance;, score=0.615 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.620 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=7, p=2, weights=distance;, score=0.619 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=10, p=1, weights=uniform;, score=0.628 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=10, p=1, weights=distance;, score=0.624 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=10, p=2, weights=uniform;, score=0.618 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=10, p=2, weights=distance;, score=0.617 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=1, p=1, weights=uniform;, score=0.581 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=1, p=1, weights=distance;, score=0.581 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=1, p=2, weights=uniform;, score=0.574 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=1, p=2, weights=distance;, score=0.574 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.582 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=3, p=1, weights=distance;, score=0.583 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.592 total time=   0.1s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=3, p=2, weights=distance;, score=0.592 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.613 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=5, p=1, weights=distance;, score=0.612 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.606 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=5, p=2, weights=distance;, score=0.605 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.615 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=7, p=1, weights=distance;, score=0.615 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.620 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=7, p=2, weights=distance;, score=0.619 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=10, p=1, weights=uniform;, score=0.628 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=10, p=1, weights=distance;, score=0.624 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=10, p=2, weights=uniform;, score=0.618 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=10, p=2, weights=distance;, score=0.617 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=1, p=1, weights=uniform;, score=0.581 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=1, p=1, weights=distance;, score=0.581 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=1, p=2, weights=uniform;, score=0.574 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=1, p=2, weights=distance;, score=0.574 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.582 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=3, p=1, weights=distance;, score=0.583 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.592 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=3, p=2, weights=distance;, score=0.592 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.613 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=5, p=1, weights=distance;, score=0.612 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.606 total time=   0.1s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=5, p=2, weights=distance;, score=0.605 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.615 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=7, p=1, weights=distance;, score=0.615 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.620 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=7, p=2, weights=distance;, score=0.619 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=10, p=1, weights=uniform;, score=0.628 total time=   0.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=10, p=1, weights=distance;, score=0.624 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=10, p=2, weights=uniform;, score=0.618 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=10, p=2, weights=distance;, score=0.617 total time=   0.0s\n",
      "Best hyperparameters: {'algorithm': 'auto', 'leaf_size': 15, 'n_neighbors': 10, 'p': 1, 'weights': 'uniform'}\n",
      "Accuracy: 63.42\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.57      0.55      2224\n",
      "           1       0.71      0.67      0.69      3388\n",
      "\n",
      "    accuracy                           0.63      5612\n",
      "   macro avg       0.62      0.62      0.62      5612\n",
      "weighted avg       0.64      0.63      0.64      5612\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1278  946]\n",
      " [1107 2281]]\n",
      "----- Span: 7 -----\n",
      "11907 train examples\n",
      "5104 test examples\n",
      "Fitting 1 folds for each of 240 candidates, totalling 240 fits\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=1, p=1, weights=uniform;, score=0.598 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=1, p=1, weights=distance;, score=0.598 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=1, p=2, weights=uniform;, score=0.586 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=1, p=2, weights=distance;, score=0.586 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.646 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=3, p=1, weights=distance;, score=0.646 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.605 total time=   0.1s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=3, p=2, weights=distance;, score=0.607 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.641 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=5, p=1, weights=distance;, score=0.641 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.625 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=5, p=2, weights=distance;, score=0.626 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.636 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=7, p=1, weights=distance;, score=0.641 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.631 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=7, p=2, weights=distance;, score=0.631 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=10, p=1, weights=uniform;, score=0.621 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=10, p=1, weights=distance;, score=0.654 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=10, p=2, weights=uniform;, score=0.636 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=15, n_neighbors=10, p=2, weights=distance;, score=0.648 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=1, p=1, weights=uniform;, score=0.598 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=1, p=1, weights=distance;, score=0.598 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=1, p=2, weights=uniform;, score=0.586 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=1, p=2, weights=distance;, score=0.586 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.646 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=3, p=1, weights=distance;, score=0.646 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.605 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=3, p=2, weights=distance;, score=0.607 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.641 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=5, p=1, weights=distance;, score=0.641 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.625 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=5, p=2, weights=distance;, score=0.626 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.636 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=7, p=1, weights=distance;, score=0.641 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.631 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=7, p=2, weights=distance;, score=0.631 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=10, p=1, weights=uniform;, score=0.621 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=10, p=1, weights=distance;, score=0.654 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=10, p=2, weights=uniform;, score=0.636 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=30, n_neighbors=10, p=2, weights=distance;, score=0.648 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=1, p=1, weights=uniform;, score=0.598 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=1, p=1, weights=distance;, score=0.598 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=1, p=2, weights=uniform;, score=0.586 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=1, p=2, weights=distance;, score=0.586 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.646 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=3, p=1, weights=distance;, score=0.646 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.605 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=3, p=2, weights=distance;, score=0.607 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.641 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=5, p=1, weights=distance;, score=0.641 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.625 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=5, p=2, weights=distance;, score=0.626 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.636 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=7, p=1, weights=distance;, score=0.641 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.631 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=7, p=2, weights=distance;, score=0.631 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=10, p=1, weights=uniform;, score=0.621 total time=   0.3s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=10, p=1, weights=distance;, score=0.654 total time=   0.2s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=10, p=2, weights=uniform;, score=0.636 total time=   0.0s\n",
      "[CV 1/1] END algorithm=auto, leaf_size=45, n_neighbors=10, p=2, weights=distance;, score=0.648 total time=   0.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=1, p=1, weights=uniform;, score=0.598 total time=   3.4s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=1, p=1, weights=distance;, score=0.598 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=1, p=2, weights=uniform;, score=0.586 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=1, p=2, weights=distance;, score=0.586 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.646 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=3, p=1, weights=distance;, score=0.646 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.605 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=3, p=2, weights=distance;, score=0.607 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.641 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=5, p=1, weights=distance;, score=0.641 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.625 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=5, p=2, weights=distance;, score=0.626 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.636 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=7, p=1, weights=distance;, score=0.641 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.631 total time=   3.4s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=7, p=2, weights=distance;, score=0.631 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=10, p=1, weights=uniform;, score=0.621 total time=   3.4s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=10, p=1, weights=distance;, score=0.654 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=10, p=2, weights=uniform;, score=0.636 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=15, n_neighbors=10, p=2, weights=distance;, score=0.648 total time=   3.3s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=1, p=1, weights=uniform;, score=0.598 total time=   3.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=1, p=1, weights=distance;, score=0.598 total time=   3.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=1, p=2, weights=uniform;, score=0.586 total time=   3.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=1, p=2, weights=distance;, score=0.586 total time=   3.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.646 total time=   3.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=3, p=1, weights=distance;, score=0.646 total time=   3.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.605 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=3, p=2, weights=distance;, score=0.607 total time=   3.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.641 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=5, p=1, weights=distance;, score=0.641 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.625 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=5, p=2, weights=distance;, score=0.626 total time=   3.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.636 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=7, p=1, weights=distance;, score=0.641 total time=   3.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.631 total time=   3.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=7, p=2, weights=distance;, score=0.631 total time=   3.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=10, p=1, weights=uniform;, score=0.621 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=10, p=1, weights=distance;, score=0.654 total time=   3.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=10, p=2, weights=uniform;, score=0.636 total time=   3.2s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=30, n_neighbors=10, p=2, weights=distance;, score=0.648 total time=   3.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=1, p=1, weights=uniform;, score=0.598 total time=   3.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=1, p=1, weights=distance;, score=0.598 total time=   3.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=1, p=2, weights=uniform;, score=0.586 total time=   3.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=1, p=2, weights=distance;, score=0.586 total time=   3.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.646 total time=   3.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=3, p=1, weights=distance;, score=0.646 total time=   3.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.605 total time=   3.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=3, p=2, weights=distance;, score=0.607 total time=   3.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.641 total time=   3.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=5, p=1, weights=distance;, score=0.641 total time=   3.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.625 total time=   3.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=5, p=2, weights=distance;, score=0.626 total time=   3.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.636 total time=   3.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=7, p=1, weights=distance;, score=0.641 total time=   3.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.631 total time=   3.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=7, p=2, weights=distance;, score=0.631 total time=   3.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=10, p=1, weights=uniform;, score=0.621 total time=   3.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=10, p=1, weights=distance;, score=0.654 total time=   3.0s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=10, p=2, weights=uniform;, score=0.636 total time=   3.1s\n",
      "[CV 1/1] END algorithm=ball_tree, leaf_size=45, n_neighbors=10, p=2, weights=distance;, score=0.648 total time=   3.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=1, p=1, weights=uniform;, score=0.598 total time=   3.9s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=1, p=1, weights=distance;, score=0.598 total time=   3.8s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=1, p=2, weights=uniform;, score=0.586 total time=   4.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=1, p=2, weights=distance;, score=0.586 total time=   4.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.646 total time=   3.9s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=3, p=1, weights=distance;, score=0.646 total time=   3.9s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.605 total time=   5.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=3, p=2, weights=distance;, score=0.607 total time=   5.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.641 total time=   3.9s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=5, p=1, weights=distance;, score=0.641 total time=   3.9s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.625 total time=   5.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=5, p=2, weights=distance;, score=0.626 total time=   5.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.636 total time=   3.9s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=7, p=1, weights=distance;, score=0.641 total time=   3.9s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.631 total time=   5.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=7, p=2, weights=distance;, score=0.631 total time=   5.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=10, p=1, weights=uniform;, score=0.621 total time=   3.9s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=10, p=1, weights=distance;, score=0.654 total time=   3.9s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=10, p=2, weights=uniform;, score=0.636 total time=   5.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=15, n_neighbors=10, p=2, weights=distance;, score=0.648 total time=   5.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=1, p=1, weights=uniform;, score=0.598 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=1, p=1, weights=distance;, score=0.598 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=1, p=2, weights=uniform;, score=0.586 total time=   3.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=1, p=2, weights=distance;, score=0.586 total time=   3.7s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.646 total time=   3.5s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=3, p=1, weights=distance;, score=0.646 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.605 total time=   3.9s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=3, p=2, weights=distance;, score=0.607 total time=   3.9s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.641 total time=   3.5s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=5, p=1, weights=distance;, score=0.641 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.625 total time=   4.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=5, p=2, weights=distance;, score=0.626 total time=   3.9s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.636 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=7, p=1, weights=distance;, score=0.641 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.631 total time=   4.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=7, p=2, weights=distance;, score=0.631 total time=   3.9s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=10, p=1, weights=uniform;, score=0.621 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=10, p=1, weights=distance;, score=0.654 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=10, p=2, weights=uniform;, score=0.636 total time=   4.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=30, n_neighbors=10, p=2, weights=distance;, score=0.648 total time=   4.0s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=1, p=1, weights=uniform;, score=0.598 total time=   3.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=1, p=1, weights=distance;, score=0.598 total time=   3.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=1, p=2, weights=uniform;, score=0.586 total time=   3.3s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=1, p=2, weights=distance;, score=0.586 total time=   3.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.646 total time=   3.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=3, p=1, weights=distance;, score=0.646 total time=   3.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.605 total time=   3.3s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=3, p=2, weights=distance;, score=0.607 total time=   3.3s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.641 total time=   3.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=5, p=1, weights=distance;, score=0.641 total time=   3.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.625 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=5, p=2, weights=distance;, score=0.626 total time=   3.5s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.636 total time=   3.3s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=7, p=1, weights=distance;, score=0.641 total time=   3.2s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.631 total time=   3.6s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=7, p=2, weights=distance;, score=0.631 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=10, p=1, weights=uniform;, score=0.621 total time=   3.3s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=10, p=1, weights=distance;, score=0.654 total time=   3.1s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=10, p=2, weights=uniform;, score=0.636 total time=   3.4s\n",
      "[CV 1/1] END algorithm=kd_tree, leaf_size=45, n_neighbors=10, p=2, weights=distance;, score=0.648 total time=   3.4s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=1, p=1, weights=uniform;, score=0.598 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=1, p=1, weights=distance;, score=0.598 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=1, p=2, weights=uniform;, score=0.586 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=1, p=2, weights=distance;, score=0.586 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.646 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=3, p=1, weights=distance;, score=0.646 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.605 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=3, p=2, weights=distance;, score=0.607 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.641 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=5, p=1, weights=distance;, score=0.641 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.625 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=5, p=2, weights=distance;, score=0.626 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.636 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=7, p=1, weights=distance;, score=0.641 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.631 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=7, p=2, weights=distance;, score=0.631 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=10, p=1, weights=uniform;, score=0.621 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=10, p=1, weights=distance;, score=0.654 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=10, p=2, weights=uniform;, score=0.636 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=15, n_neighbors=10, p=2, weights=distance;, score=0.648 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=1, p=1, weights=uniform;, score=0.598 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=1, p=1, weights=distance;, score=0.598 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=1, p=2, weights=uniform;, score=0.586 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=1, p=2, weights=distance;, score=0.586 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.646 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=3, p=1, weights=distance;, score=0.646 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.605 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=3, p=2, weights=distance;, score=0.607 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.641 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=5, p=1, weights=distance;, score=0.641 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.625 total time=   0.1s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=5, p=2, weights=distance;, score=0.626 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.636 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=7, p=1, weights=distance;, score=0.641 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.631 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=7, p=2, weights=distance;, score=0.631 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=10, p=1, weights=uniform;, score=0.621 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=10, p=1, weights=distance;, score=0.654 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=10, p=2, weights=uniform;, score=0.636 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=30, n_neighbors=10, p=2, weights=distance;, score=0.648 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=1, p=1, weights=uniform;, score=0.598 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=1, p=1, weights=distance;, score=0.598 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=1, p=2, weights=uniform;, score=0.586 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=1, p=2, weights=distance;, score=0.586 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.646 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=3, p=1, weights=distance;, score=0.646 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.605 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=3, p=2, weights=distance;, score=0.607 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.641 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=5, p=1, weights=distance;, score=0.641 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.625 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=5, p=2, weights=distance;, score=0.626 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.636 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=7, p=1, weights=distance;, score=0.641 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.631 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=7, p=2, weights=distance;, score=0.631 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=10, p=1, weights=uniform;, score=0.621 total time=   0.3s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=10, p=1, weights=distance;, score=0.654 total time=   0.2s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=10, p=2, weights=uniform;, score=0.636 total time=   0.0s\n",
      "[CV 1/1] END algorithm=brute, leaf_size=45, n_neighbors=10, p=2, weights=distance;, score=0.648 total time=   0.0s\n",
      "Best hyperparameters: {'algorithm': 'auto', 'leaf_size': 15, 'n_neighbors': 10, 'p': 1, 'weights': 'distance'}\n",
      "Accuracy: 64.64\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.48      0.52      2060\n",
      "           1       0.68      0.76      0.72      3044\n",
      "\n",
      "    accuracy                           0.65      5104\n",
      "   macro avg       0.63      0.62      0.62      5104\n",
      "weighted avg       0.64      0.65      0.64      5104\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 985 1075]\n",
      " [ 730 2314]]\n"
     ]
    }
   ],
   "source": [
    "# Define the KNN model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_neighbors': [1, 3, 5, 7, 10],  # Number of neighbors\n",
    "    'weights': ['uniform', 'distance'],  # Weighting scheme\n",
    "    'p': [1, 2],  # Distance metric (1 for Manhattan, 2 for Euclidean)\n",
    "    'leaf_size': [15, 30, 45],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "filename = 'knn_model.pkl'\n",
    "\n",
    "train_test_save(knn, param_grid, filename, n_splits=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Span: 3 -----\n",
      "14373 train examples\n",
      "6160 test examples\n",
      "Fitting 1 folds for each of 162 candidates, totalling 162 fits\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100;, score=0.665 total time=   3.5s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.663 total time=   7.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.665 total time=  17.7s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100;, score=0.650 total time=   1.9s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=log2, n_estimators=200;, score=0.654 total time=   4.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=log2, n_estimators=500;, score=0.652 total time=   9.9s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.672 total time=   4.4s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.669 total time=   8.9s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.672 total time=  22.2s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100;, score=0.663 total time=   2.4s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=log2, n_estimators=200;, score=0.656 total time=   5.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=log2, n_estimators=500;, score=0.662 total time=  12.4s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=100;, score=0.665 total time=   5.3s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.670 total time=  10.6s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.672 total time=  26.6s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=log2, n_estimators=100;, score=0.663 total time=   2.9s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=log2, n_estimators=200;, score=0.670 total time=   5.8s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=log2, n_estimators=500;, score=0.668 total time=  14.8s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=100;, score=0.673 total time=   6.1s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.674 total time=  12.4s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.669 total time=  31.2s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=log2, n_estimators=100;, score=0.669 total time=   3.4s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=log2, n_estimators=200;, score=0.666 total time=   6.8s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=log2, n_estimators=500;, score=0.668 total time=  17.4s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.675 total time=   7.3s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.676 total time=  14.2s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.675 total time=  35.2s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=log2, n_estimators=100;, score=0.669 total time=   3.9s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=log2, n_estimators=200;, score=0.670 total time=   7.8s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=log2, n_estimators=500;, score=0.670 total time=  19.6s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100;, score=0.673 total time=  13.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=200;, score=0.677 total time=  26.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=500;, score=0.669 total time= 1.1min\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100;, score=0.668 total time=   7.1s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=log2, n_estimators=200;, score=0.675 total time=  14.2s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=log2, n_estimators=500;, score=0.667 total time=  35.8s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100;, score=0.661 total time=   4.7s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.661 total time=   9.7s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.661 total time=  24.2s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100;, score=0.659 total time=   2.6s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=200;, score=0.656 total time=   5.3s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=500;, score=0.652 total time=  13.6s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.666 total time=   6.1s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.668 total time=  12.1s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.670 total time=  30.2s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100;, score=0.658 total time=   3.3s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=200;, score=0.661 total time=   6.7s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=500;, score=0.659 total time=  16.7s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=100;, score=0.675 total time=   7.3s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.673 total time=  14.6s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.672 total time=  36.5s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=100;, score=0.669 total time=   4.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=200;, score=0.666 total time=   8.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=500;, score=0.668 total time=  20.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=100;, score=0.672 total time=   8.5s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.670 total time=  17.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.675 total time=  42.8s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=100;, score=0.670 total time=   4.7s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=200;, score=0.670 total time=   9.4s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=500;, score=0.662 total time=  23.7s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.666 total time=   9.8s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.675 total time=  19.7s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.672 total time=  49.3s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=100;, score=0.675 total time=   5.3s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=200;, score=0.672 total time=  10.8s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=500;, score=0.670 total time=  27.1s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100;, score=0.672 total time=  17.1s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=200;, score=0.668 total time=  34.2s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=500;, score=0.676 total time= 1.4min\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100;, score=0.674 total time=   9.7s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=200;, score=0.669 total time=  19.4s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=500;, score=0.670 total time=  49.1s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=100;, score=0.662 total time=   4.7s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.666 total time=   9.5s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.663 total time=  23.9s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=100;, score=0.652 total time=   2.6s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=200;, score=0.650 total time=   5.3s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=500;, score=0.656 total time=  13.3s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.668 total time=   6.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.673 total time=  12.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.674 total time=  30.2s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=0.663 total time=   3.3s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=0.664 total time=   6.7s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=500;, score=0.661 total time=  16.8s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=100;, score=0.671 total time=   7.2s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.671 total time=  14.7s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.670 total time=  36.7s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=log2, n_estimators=100;, score=0.665 total time=   4.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=log2, n_estimators=200;, score=0.667 total time=   8.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=log2, n_estimators=500;, score=0.666 total time=  20.3s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=100;, score=0.673 total time=   8.6s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.670 total time=  17.2s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.674 total time=  43.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=log2, n_estimators=100;, score=0.673 total time=   4.6s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=log2, n_estimators=200;, score=0.668 total time=   9.3s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=log2, n_estimators=500;, score=0.669 total time=  23.6s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.682 total time=   9.8s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.672 total time=  19.7s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.670 total time=  49.2s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=log2, n_estimators=100;, score=0.675 total time=   5.3s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=log2, n_estimators=200;, score=0.666 total time=  10.7s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=log2, n_estimators=500;, score=0.670 total time=  27.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100;, score=0.672 total time=  17.1s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=200;, score=0.675 total time=  34.2s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=500;, score=0.676 total time= 1.4min\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100;, score=0.673 total time=   9.8s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=200;, score=0.677 total time=  19.6s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=500;, score=0.670 total time=  49.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "54 fits failed out of a total of 162.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.66481224 0.66272601 0.66481224\n",
      " 0.65020862 0.65438108 0.65229485        nan        nan        nan\n",
      " 0.67246175 0.6689847  0.67246175 0.66272601 0.65646732 0.6620306\n",
      "        nan        nan        nan 0.66481224 0.67037552 0.67246175\n",
      " 0.66342142 0.67037552 0.66828929        nan        nan        nan\n",
      " 0.67315716 0.67385257 0.6689847  0.6689847  0.66620306 0.66828929\n",
      "        nan        nan        nan 0.67524339 0.6759388  0.67524339\n",
      " 0.6689847  0.66968011 0.66968011        nan        nan        nan\n",
      " 0.67315716 0.67663421 0.6689847  0.66759388 0.67524339 0.66689847\n",
      "        nan        nan        nan 0.66133519 0.66063978 0.66063978\n",
      " 0.65924896 0.65577191 0.65159944        nan        nan        nan\n",
      " 0.66620306 0.66828929 0.67037552 0.65785814 0.66063978 0.65924896\n",
      "        nan        nan        nan 0.67454798 0.67315716 0.67176634\n",
      " 0.6689847  0.66620306 0.66759388        nan        nan        nan\n",
      " 0.67176634 0.66968011 0.67524339 0.66968011 0.66968011 0.6620306\n",
      "        nan        nan        nan 0.66620306 0.67454798 0.67176634\n",
      " 0.67524339 0.67246175 0.67037552        nan        nan        nan\n",
      " 0.67246175 0.66759388 0.6759388  0.67385257 0.6689847  0.67037552\n",
      "        nan        nan        nan 0.6620306  0.66620306 0.66342142\n",
      " 0.65159944 0.65020862 0.65646732        nan        nan        nan\n",
      " 0.66759388 0.67315716 0.67385257 0.66342142 0.66411683 0.66133519\n",
      "        nan        nan        nan 0.67107093 0.67107093 0.66968011\n",
      " 0.66481224 0.66689847 0.66550765        nan        nan        nan\n",
      " 0.67315716 0.67037552 0.67385257 0.67315716 0.66828929 0.6689847\n",
      "        nan        nan        nan 0.6821975  0.67246175 0.66968011\n",
      " 0.67454798 0.66550765 0.67037552        nan        nan        nan\n",
      " 0.67176634 0.67454798 0.6759388  0.67315716 0.67663421 0.66968011]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'criterion': 'log_loss', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "Accuracy: 66.74\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.38      0.48      2507\n",
      "           1       0.67      0.87      0.76      3653\n",
      "\n",
      "    accuracy                           0.67      6160\n",
      "   macro avg       0.66      0.62      0.62      6160\n",
      "weighted avg       0.67      0.67      0.64      6160\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 946 1561]\n",
      " [ 488 3165]]\n",
      "----- Span: 5 -----\n",
      "13093 train examples\n",
      "5612 test examples\n",
      "Fitting 1 folds for each of 162 candidates, totalling 162 fits\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100;, score=0.650 total time=   3.4s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.659 total time=   6.8s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.655 total time=  17.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100;, score=0.644 total time=   1.9s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=log2, n_estimators=200;, score=0.648 total time=   3.8s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=log2, n_estimators=500;, score=0.647 total time=   9.6s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.667 total time=   4.1s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.668 total time=   8.4s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.672 total time=  21.1s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100;, score=0.657 total time=   2.3s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=log2, n_estimators=200;, score=0.659 total time=   4.7s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=log2, n_estimators=500;, score=0.660 total time=  11.8s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=100;, score=0.665 total time=   5.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.667 total time=  10.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.673 total time=  25.1s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=log2, n_estimators=100;, score=0.675 total time=   2.7s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=log2, n_estimators=200;, score=0.670 total time=   5.6s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=log2, n_estimators=500;, score=0.671 total time=  14.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=100;, score=0.666 total time=   5.8s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.672 total time=  11.7s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.674 total time=  29.2s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=log2, n_estimators=100;, score=0.666 total time=   3.2s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=log2, n_estimators=200;, score=0.669 total time=   6.4s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=log2, n_estimators=500;, score=0.672 total time=  16.2s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.660 total time=   6.6s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.671 total time=  13.3s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.672 total time=  33.2s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=log2, n_estimators=100;, score=0.669 total time=   3.6s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=log2, n_estimators=200;, score=0.670 total time=   7.4s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=log2, n_estimators=500;, score=0.669 total time=  18.5s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100;, score=0.669 total time=  11.8s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=200;, score=0.675 total time=  23.7s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=500;, score=0.681 total time=  59.7s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100;, score=0.669 total time=   6.5s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=log2, n_estimators=200;, score=0.668 total time=  13.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=log2, n_estimators=500;, score=0.666 total time=  32.5s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100;, score=0.657 total time=   4.5s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.664 total time=   9.1s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.660 total time=  22.8s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100;, score=0.647 total time=   2.5s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=200;, score=0.657 total time=   5.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=500;, score=0.648 total time=  12.7s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.669 total time=   5.7s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.668 total time=  11.4s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.668 total time=  28.9s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100;, score=0.658 total time=   3.1s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=200;, score=0.661 total time=   6.4s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=500;, score=0.666 total time=  16.1s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=100;, score=0.674 total time=   7.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.668 total time=  13.9s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.667 total time=  34.8s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=100;, score=0.663 total time=   3.8s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=200;, score=0.671 total time=   7.6s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=500;, score=0.672 total time=  19.1s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=100;, score=0.673 total time=   8.1s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.664 total time=  16.2s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.674 total time=  40.7s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=100;, score=0.667 total time=   4.4s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=200;, score=0.676 total time=   8.9s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=500;, score=0.666 total time=  22.4s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.664 total time=   9.3s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.673 total time=  18.8s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.672 total time=  46.9s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=100;, score=0.659 total time=   5.1s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=200;, score=0.676 total time=  10.2s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=500;, score=0.668 total time=  25.7s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100;, score=0.670 total time=  15.7s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=200;, score=0.668 total time=  31.6s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=500;, score=0.666 total time= 1.3min\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100;, score=0.662 total time=   8.9s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=200;, score=0.660 total time=  17.9s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=500;, score=0.672 total time=  45.1s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=100;, score=0.659 total time=   4.6s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.659 total time=   9.1s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.659 total time=  22.9s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=100;, score=0.646 total time=   2.5s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=200;, score=0.644 total time=   5.1s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=500;, score=0.646 total time=  12.8s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.667 total time=   5.7s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.671 total time=  11.6s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.663 total time=  29.1s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=0.663 total time=   3.1s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=0.660 total time=   6.4s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=500;, score=0.661 total time=  16.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=100;, score=0.670 total time=   7.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.668 total time=  13.8s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.676 total time=  34.9s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=log2, n_estimators=100;, score=0.660 total time=   3.8s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=log2, n_estimators=200;, score=0.671 total time=   7.6s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=log2, n_estimators=500;, score=0.670 total time=  19.2s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=100;, score=0.671 total time=   8.1s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.673 total time=  16.2s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.679 total time=  41.2s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=log2, n_estimators=100;, score=0.664 total time=   4.5s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=log2, n_estimators=200;, score=0.669 total time=   9.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=log2, n_estimators=500;, score=0.667 total time=  22.6s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.669 total time=   9.4s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.676 total time=  18.8s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.673 total time=  47.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=log2, n_estimators=100;, score=0.669 total time=   5.1s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=log2, n_estimators=200;, score=0.672 total time=  10.2s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=log2, n_estimators=500;, score=0.672 total time=19.2min\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100;, score=0.664 total time=  17.7s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=200;, score=0.666 total time=  31.8s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=500;, score=0.676 total time= 1.2min\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100;, score=0.674 total time=   9.1s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=200;, score=0.678 total time=  18.1s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=500;, score=0.665 total time=  45.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "54 fits failed out of a total of 162.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.65038168 0.65877863 0.65496183\n",
      " 0.64351145 0.6480916  0.64732824        nan        nan        nan\n",
      " 0.66717557 0.66793893 0.67175573 0.65725191 0.65877863 0.66030534\n",
      "        nan        nan        nan 0.6648855  0.66717557 0.67251908\n",
      " 0.67480916 0.67022901 0.67099237        nan        nan        nan\n",
      " 0.66641221 0.67175573 0.6740458  0.66641221 0.66870229 0.67175573\n",
      "        nan        nan        nan 0.66030534 0.67099237 0.67175573\n",
      " 0.66870229 0.67022901 0.66946565        nan        nan        nan\n",
      " 0.66946565 0.67480916 0.68091603 0.66870229 0.66793893 0.66641221\n",
      "        nan        nan        nan 0.65725191 0.66412214 0.65954198\n",
      " 0.64732824 0.65725191 0.6480916         nan        nan        nan\n",
      " 0.66870229 0.66793893 0.66793893 0.65801527 0.6610687  0.66564885\n",
      "        nan        nan        nan 0.6740458  0.66793893 0.66717557\n",
      " 0.66335878 0.67099237 0.67175573        nan        nan        nan\n",
      " 0.67251908 0.66412214 0.6740458  0.66717557 0.67633588 0.66641221\n",
      "        nan        nan        nan 0.66412214 0.67328244 0.67175573\n",
      " 0.65877863 0.67633588 0.66793893        nan        nan        nan\n",
      " 0.67022901 0.66793893 0.66641221 0.66183206 0.65954198 0.67175573\n",
      "        nan        nan        nan 0.65877863 0.65877863 0.65877863\n",
      " 0.64580153 0.64351145 0.64580153        nan        nan        nan\n",
      " 0.66717557 0.67099237 0.66259542 0.66335878 0.66030534 0.6610687\n",
      "        nan        nan        nan 0.67022901 0.66793893 0.67633588\n",
      " 0.65954198 0.67099237 0.67022901        nan        nan        nan\n",
      " 0.67099237 0.67328244 0.67862595 0.66412214 0.66870229 0.66717557\n",
      "        nan        nan        nan 0.66870229 0.67633588 0.67328244\n",
      " 0.66870229 0.67175573 0.67175573        nan        nan        nan\n",
      " 0.66412214 0.66641221 0.67633588 0.6740458  0.6778626  0.6648855 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Accuracy: 67.59\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.45      0.52      2224\n",
      "           1       0.70      0.82      0.75      3388\n",
      "\n",
      "    accuracy                           0.68      5612\n",
      "   macro avg       0.66      0.64      0.64      5612\n",
      "weighted avg       0.67      0.68      0.66      5612\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1002 1222]\n",
      " [ 597 2791]]\n",
      "----- Span: 7 -----\n",
      "11907 train examples\n",
      "5104 test examples\n",
      "Fitting 1 folds for each of 162 candidates, totalling 162 fits\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100;, score=0.657 total time=   3.1s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.654 total time=   6.3s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.659 total time=  16.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100;, score=0.643 total time=   1.7s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=log2, n_estimators=200;, score=0.644 total time=   3.6s\n",
      "[CV 1/1] END criterion=gini, max_depth=4, max_features=log2, n_estimators=500;, score=0.647 total time=   9.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.663 total time=   3.9s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.660 total time=   7.9s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.662 total time=  19.7s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100;, score=0.670 total time=   2.1s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=log2, n_estimators=200;, score=0.663 total time=   4.4s\n",
      "[CV 1/1] END criterion=gini, max_depth=5, max_features=log2, n_estimators=500;, score=0.656 total time=  11.1s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=100;, score=0.673 total time=   4.6s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.666 total time=   9.4s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.666 total time=  23.6s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=log2, n_estimators=100;, score=0.667 total time=   2.6s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=log2, n_estimators=200;, score=0.664 total time=   5.2s\n",
      "[CV 1/1] END criterion=gini, max_depth=6, max_features=log2, n_estimators=500;, score=0.664 total time=  13.2s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=100;, score=0.680 total time=   5.4s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.667 total time=  10.9s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.671 total time=  27.3s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=log2, n_estimators=100;, score=0.655 total time=   3.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=log2, n_estimators=200;, score=0.667 total time=   6.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=7, max_features=log2, n_estimators=500;, score=0.669 total time=  15.3s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.672 total time=   6.2s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.671 total time=  12.4s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.671 total time=  31.1s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=log2, n_estimators=100;, score=0.669 total time=   3.4s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=log2, n_estimators=200;, score=0.668 total time=   6.8s\n",
      "[CV 1/1] END criterion=gini, max_depth=8, max_features=log2, n_estimators=500;, score=0.673 total time=  17.1s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100;, score=0.673 total time=  10.8s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=200;, score=0.679 total time=  21.8s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=500;, score=0.684 total time=  54.5s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100;, score=0.672 total time=   6.0s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=log2, n_estimators=200;, score=0.676 total time=  11.8s\n",
      "[CV 1/1] END criterion=gini, max_depth=None, max_features=log2, n_estimators=500;, score=0.675 total time=  29.7s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100;, score=0.664 total time=   4.2s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.657 total time=   8.5s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.657 total time=  21.5s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100;, score=0.651 total time=   2.4s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=200;, score=0.647 total time=   4.7s\n",
      "[CV 1/1] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=500;, score=0.645 total time=  12.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.666 total time=   5.4s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.661 total time=  10.8s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.665 total time=  27.1s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100;, score=0.653 total time=   2.9s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=200;, score=0.657 total time=   5.9s\n",
      "[CV 1/1] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=500;, score=0.660 total time=  14.9s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=100;, score=0.668 total time=   6.5s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.666 total time=  13.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.667 total time=  32.5s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=100;, score=0.667 total time=   3.5s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=200;, score=0.664 total time=   7.2s\n",
      "[CV 1/1] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=500;, score=0.662 total time=  18.2s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=100;, score=0.662 total time=   7.5s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.674 total time=  15.2s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.668 total time=  38.3s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=100;, score=0.671 total time=   4.2s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=200;, score=0.662 total time=   8.4s\n",
      "[CV 1/1] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=500;, score=0.670 total time=  21.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.680 total time=   8.6s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.676 total time=  17.3s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.674 total time=  43.4s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=100;, score=0.667 total time=   4.8s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=200;, score=0.663 total time=   9.5s\n",
      "[CV 1/1] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=500;, score=0.673 total time=  23.9s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100;, score=0.673 total time=  14.4s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=200;, score=0.673 total time=  28.6s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=500;, score=0.679 total time= 1.2min\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100;, score=0.677 total time=   8.2s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=200;, score=0.678 total time=  16.5s\n",
      "[CV 1/1] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=500;, score=0.679 total time=  40.9s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=100;, score=0.656 total time=   4.3s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.660 total time=   8.5s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.657 total time=  21.4s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=100;, score=0.654 total time=   2.3s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=200;, score=0.646 total time=   4.7s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=500;, score=0.645 total time=  12.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.664 total time=   5.3s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.665 total time=  10.8s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.657 total time=  26.8s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=0.662 total time=   2.9s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=0.661 total time=   5.9s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=500;, score=0.660 total time=  14.9s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=100;, score=0.665 total time=   6.5s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.662 total time=  12.9s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.666 total time=325.4min\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=log2, n_estimators=100;, score=0.666 total time=   3.7s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=log2, n_estimators=200;, score=0.662 total time=   7.4s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=6, max_features=log2, n_estimators=500;, score=0.657 total time=  18.2s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=100;, score=0.667 total time=   7.6s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.672 total time=  15.3s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.671 total time=  38.2s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=log2, n_estimators=100;, score=0.668 total time=   4.1s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=log2, n_estimators=200;, score=0.668 total time=   8.3s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=7, max_features=log2, n_estimators=500;, score=0.676 total time=  21.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.679 total time=   8.7s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.669 total time=  17.3s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.673 total time=  43.3s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=log2, n_estimators=100;, score=0.673 total time=   4.7s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=log2, n_estimators=200;, score=0.665 total time=   9.5s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=8, max_features=log2, n_estimators=500;, score=0.676 total time=  23.9s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=auto, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=auto, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100;, score=0.657 total time=  14.4s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=200;, score=0.678 total time=  28.8s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=500;, score=0.678 total time= 1.2min\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100;, score=0.674 total time=   8.4s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=200;, score=0.675 total time=  16.7s\n",
      "[CV 1/1] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=500;, score=0.679 total time=  41.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "54 fits failed out of a total of 162.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.6565911  0.65407221 0.65910999\n",
      " 0.64315701 0.64399664 0.64651553        nan        nan        nan\n",
      " 0.66330814 0.65994962 0.66246851 0.67002519 0.66330814 0.65575147\n",
      "        nan        nan        nan 0.67338371 0.66582704 0.66582704\n",
      " 0.66666667 0.66414777 0.66414777        nan        nan        nan\n",
      " 0.68010076 0.66666667 0.67086482 0.65491184 0.66666667 0.66918556\n",
      "        nan        nan        nan 0.67170445 0.67086482 0.67086482\n",
      " 0.66918556 0.6675063  0.67338371        nan        nan        nan\n",
      " 0.67338371 0.67926113 0.68429891 0.67170445 0.6759026  0.67506297\n",
      "        nan        nan        nan 0.66414777 0.6565911  0.65743073\n",
      " 0.65071369 0.64651553 0.64483627        nan        nan        nan\n",
      " 0.66582704 0.66078925 0.66498741 0.65323258 0.6565911  0.65994962\n",
      "        nan        nan        nan 0.6675063  0.66582704 0.66666667\n",
      " 0.66666667 0.66414777 0.66162888        nan        nan        nan\n",
      " 0.66246851 0.67422334 0.66834593 0.67086482 0.66246851 0.67002519\n",
      "        nan        nan        nan 0.68010076 0.6759026  0.67422334\n",
      " 0.66666667 0.66330814 0.67338371        nan        nan        nan\n",
      " 0.67338371 0.67338371 0.67926113 0.67674223 0.67842149 0.67926113\n",
      "        nan        nan        nan 0.65575147 0.65994962 0.6565911\n",
      " 0.65407221 0.6456759  0.64483627        nan        nan        nan\n",
      " 0.66414777 0.66498741 0.6565911  0.66162888 0.66078925 0.65994962\n",
      "        nan        nan        nan 0.66498741 0.66162888 0.66582704\n",
      " 0.66582704 0.66162888 0.65743073        nan        nan        nan\n",
      " 0.66666667 0.67170445 0.67086482 0.66834593 0.6675063  0.6759026\n",
      "        nan        nan        nan 0.67926113 0.66918556 0.67254408\n",
      " 0.67254408 0.66498741 0.6759026         nan        nan        nan\n",
      " 0.65743073 0.67758186 0.67758186 0.67422334 0.67506297 0.67926113]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Accuracy: 68.30\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.47      0.55      2060\n",
      "           1       0.70      0.82      0.76      3044\n",
      "\n",
      "    accuracy                           0.68      5104\n",
      "   macro avg       0.67      0.65      0.65      5104\n",
      "weighted avg       0.68      0.68      0.67      5104\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 976 1084]\n",
      " [ 534 2510]]\n"
     ]
    }
   ],
   "source": [
    "# Define the Random Forest model\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],  # Number of trees in the forest\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # Maximum number of features considered for splitting\n",
    "    'max_depth': [4, 5, 6, 7, 8, None],  # Maximum depth of each tree\n",
    "    'criterion': ['gini', 'entropy', 'log_loss']  # Split quality criterion\n",
    "}\n",
    "\n",
    "filename = 'random_forest.pkl'\n",
    "\n",
    "train_test_save(rfc, param_grid, filename, n_splits=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Span: 3 -----\n",
      "14373 train examples\n",
      "6160 test examples\n",
      "Fitting 1 folds for each of 162 candidates, totalling 162 fits\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, n_estimators=100;, score=0.619 total time=   2.1s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, n_estimators=200;, score=0.644 total time=   4.4s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, n_estimators=300;, score=0.656 total time=   6.6s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.634 total time=   3.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.656 total time=   7.7s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.661 total time=  11.7s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=0.647 total time=   3.7s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=0.656 total time=   7.4s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, n_estimators=300;, score=0.656 total time=  11.1s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.645 total time=   6.6s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.664 total time=  13.2s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.666 total time=  19.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, n_estimators=100;, score=0.652 total time=   6.7s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, n_estimators=200;, score=0.659 total time=  13.5s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, n_estimators=300;, score=0.660 total time=  20.2s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.664 total time=  11.5s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.654 total time=  23.6s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.660 total time=  36.3s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, n_estimators=100;, score=0.615 total time=   2.2s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, n_estimators=200;, score=0.645 total time=   4.6s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, n_estimators=300;, score=0.654 total time=   6.9s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.629 total time=   4.1s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.652 total time=   8.2s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.663 total time=  12.3s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, n_estimators=100;, score=0.642 total time=   3.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, n_estimators=200;, score=0.668 total time=   7.5s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, n_estimators=300;, score=0.661 total time=  11.3s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.651 total time=   6.7s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.657 total time=  13.3s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.656 total time=  20.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=log2, n_estimators=100;, score=0.652 total time=   6.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=log2, n_estimators=200;, score=0.661 total time=  13.7s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=log2, n_estimators=300;, score=0.666 total time=  20.4s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.655 total time=  11.6s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.652 total time=  23.2s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.653 total time=  34.5s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=log2, n_estimators=100;, score=0.653 total time=   2.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=log2, n_estimators=200;, score=0.666 total time=   4.3s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=log2, n_estimators=300;, score=0.660 total time=   6.5s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.661 total time=   3.9s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.659 total time=   7.7s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.666 total time=  11.6s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=0.660 total time=   3.6s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=0.665 total time=   7.3s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=log2, n_estimators=300;, score=0.674 total time=  10.9s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.663 total time=   6.5s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.667 total time=  13.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.675 total time=  19.5s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=log2, n_estimators=100;, score=0.659 total time=   6.5s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=log2, n_estimators=200;, score=0.670 total time=  12.9s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=log2, n_estimators=300;, score=0.670 total time=  19.4s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.663 total time=  11.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.657 total time=  22.3s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.674 total time=  33.3s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=100;, score=0.659 total time=   2.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=200;, score=0.654 total time=   4.3s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=300;, score=0.659 total time=   6.5s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.664 total time=   3.9s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.664 total time=   7.7s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.659 total time=  11.6s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=100;, score=0.652 total time=   3.7s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=200;, score=0.666 total time=   7.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=300;, score=0.666 total time=  10.9s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.655 total time=   6.5s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.660 total time=  13.1s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.657 total time=  19.5s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=log2, n_estimators=100;, score=0.656 total time=   6.6s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=log2, n_estimators=200;, score=0.651 total time=  13.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=log2, n_estimators=300;, score=0.663 total time=  19.6s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.663 total time=  11.7s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.661 total time=107.9min\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.661 total time=  33.9s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, n_estimators=100;, score=0.667 total time=   2.2s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, n_estimators=200;, score=0.663 total time=   4.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, n_estimators=300;, score=0.667 total time=   6.5s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.656 total time=   3.8s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.658 total time=   7.7s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.662 total time=  11.6s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=0.667 total time=   3.6s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=0.663 total time=   7.3s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, n_estimators=300;, score=0.666 total time=  10.9s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.666 total time=   6.5s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.672 total time=  13.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.666 total time=  19.5s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, n_estimators=100;, score=0.654 total time=   6.5s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, n_estimators=200;, score=0.645 total time=  13.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, n_estimators=300;, score=0.663 total time=  19.6s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.663 total time=  11.1s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.660 total time=  22.3s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.663 total time=  33.6s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, n_estimators=100;, score=0.666 total time=   2.1s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, n_estimators=200;, score=0.659 total time=   4.3s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, n_estimators=300;, score=0.660 total time=   6.5s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.662 total time=   3.9s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.662 total time=   7.7s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.653 total time=  11.6s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=log2, n_estimators=100;, score=0.662 total time=   3.6s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=log2, n_estimators=200;, score=0.677 total time=   7.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=log2, n_estimators=300;, score=0.656 total time=  10.9s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.659 total time=   6.5s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.675 total time=  13.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.670 total time=  19.6s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=log2, n_estimators=100;, score=0.666 total time=   6.5s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=log2, n_estimators=200;, score=0.663 total time=  13.1s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=log2, n_estimators=300;, score=0.666 total time=  19.6s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.664 total time=  11.2s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.668 total time=  22.6s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.659 total time=  33.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "54 fits failed out of a total of 162.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.61891516 0.64394993 0.65577191 0.63351878 0.65646732 0.66133519\n",
      " 0.64742698 0.65577191 0.65646732 0.64464534 0.66411683 0.66620306\n",
      " 0.65159944 0.65924896 0.65994437 0.66411683 0.65438108 0.65994437\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.61543811 0.64534075 0.65438108 0.62934631 0.65159944 0.66342142\n",
      " 0.6418637  0.66759388 0.66063978 0.65090403 0.65716273 0.65577191\n",
      " 0.65229485 0.66133519 0.66550765 0.6550765  0.65229485 0.65299026\n",
      " 0.65299026 0.66550765 0.65994437 0.66063978 0.65855355 0.66620306\n",
      " 0.65994437 0.66481224 0.67385257 0.66342142 0.66689847 0.67454798\n",
      " 0.65924896 0.66968011 0.66968011 0.66342142 0.65716273 0.67385257\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.65924896 0.65368567 0.65855355 0.66411683 0.66411683 0.65924896\n",
      " 0.65229485 0.66550765 0.66620306 0.6550765  0.65994437 0.65716273\n",
      " 0.65646732 0.65090403 0.66342142 0.66342142 0.66133519 0.66063978\n",
      " 0.66689847 0.66272601 0.66689847 0.65646732 0.65785814 0.6620306\n",
      " 0.66689847 0.66342142 0.66620306 0.66620306 0.67246175 0.66550765\n",
      " 0.65438108 0.64534075 0.66272601 0.66342142 0.65994437 0.66272601\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66550765 0.65924896 0.65994437 0.6620306  0.6620306  0.65299026\n",
      " 0.6620306  0.67663421 0.65646732 0.65924896 0.67454798 0.66968011\n",
      " 0.66550765 0.66272601 0.66620306 0.66411683 0.66759388 0.65924896]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 5, 'max_features': 'log2', 'n_estimators': 200}\n",
      "Accuracy: 67.45\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.49      0.55      2507\n",
      "           1       0.70      0.80      0.74      3653\n",
      "\n",
      "    accuracy                           0.67      6160\n",
      "   macro avg       0.66      0.65      0.65      6160\n",
      "weighted avg       0.67      0.67      0.67      6160\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1238 1269]\n",
      " [ 736 2917]]\n",
      "----- Span: 5 -----\n",
      "13093 train examples\n",
      "5612 test examples\n",
      "Fitting 1 folds for each of 162 candidates, totalling 162 fits\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, n_estimators=100;, score=0.618 total time=   2.1s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, n_estimators=200;, score=0.662 total time=   4.2s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, n_estimators=300;, score=0.679 total time=   6.3s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.628 total time=   3.7s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.674 total time=   7.5s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.683 total time=  11.4s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=0.649 total time=   3.5s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=0.673 total time=   7.2s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, n_estimators=300;, score=0.693 total time=  10.7s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.668 total time=   6.4s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.685 total time=  12.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.692 total time=  18.9s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, n_estimators=100;, score=0.671 total time=   6.6s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, n_estimators=200;, score=0.689 total time=  13.1s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, n_estimators=300;, score=0.704 total time=  19.7s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.669 total time=  11.1s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.689 total time=  22.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.704 total time=  33.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, n_estimators=100;, score=0.621 total time=   2.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, n_estimators=200;, score=0.661 total time=   4.2s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, n_estimators=300;, score=0.679 total time=   6.3s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.623 total time=   3.7s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.673 total time=   7.5s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.680 total time=  11.2s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, n_estimators=100;, score=0.642 total time=   3.5s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, n_estimators=200;, score=0.681 total time=   7.1s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, n_estimators=300;, score=0.692 total time=  10.7s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.661 total time=   6.3s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.692 total time=  12.6s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.690 total time=  18.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=log2, n_estimators=100;, score=0.672 total time=   6.6s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=log2, n_estimators=200;, score=0.692 total time=  13.1s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=log2, n_estimators=300;, score=0.690 total time=  19.7s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.667 total time=  11.1s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.684 total time=  22.1s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.696 total time=  33.1s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=log2, n_estimators=100;, score=0.698 total time=   2.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=log2, n_estimators=200;, score=0.697 total time=   4.1s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=log2, n_estimators=300;, score=0.703 total time=   6.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.685 total time=   3.6s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.692 total time=   7.4s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.702 total time=  11.1s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=0.687 total time=   3.5s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=0.691 total time=   7.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=log2, n_estimators=300;, score=0.695 total time=  10.5s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.704 total time=   6.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.703 total time=  12.4s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.700 total time=  18.6s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=log2, n_estimators=100;, score=0.692 total time=   6.3s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=log2, n_estimators=200;, score=0.692 total time=  12.5s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=log2, n_estimators=300;, score=0.686 total time=  18.9s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.685 total time=  10.8s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.695 total time=  21.4s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.696 total time=  32.1s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=100;, score=0.689 total time=   2.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=200;, score=0.695 total time=   4.1s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=300;, score=0.698 total time=   6.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.701 total time=   3.6s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.696 total time=   7.4s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.691 total time=  11.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=100;, score=0.692 total time=   3.5s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=200;, score=0.699 total time=   7.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=300;, score=0.697 total time=  10.5s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.699 total time=   6.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.698 total time=  12.5s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.689 total time=  18.6s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=log2, n_estimators=100;, score=0.692 total time=   6.5s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=log2, n_estimators=200;, score=0.689 total time=  12.8s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=log2, n_estimators=300;, score=0.697 total time=  19.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.696 total time=  10.9s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.689 total time=  21.6s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.698 total time=  32.3s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, n_estimators=100;, score=0.693 total time=   2.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, n_estimators=200;, score=0.704 total time=   4.1s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, n_estimators=300;, score=0.700 total time=   6.2s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.697 total time=   3.7s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.693 total time=   7.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.690 total time=  11.1s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=0.697 total time=   3.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=0.686 total time=   6.9s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, n_estimators=300;, score=0.689 total time=  10.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.692 total time=   6.1s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.685 total time=  12.3s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.689 total time=  18.5s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, n_estimators=100;, score=0.685 total time=   6.1s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, n_estimators=200;, score=0.689 total time=  12.3s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, n_estimators=300;, score=0.696 total time=  18.5s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.688 total time=  10.5s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.684 total time=  21.1s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.687 total time=  31.7s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, n_estimators=100;, score=0.700 total time=   2.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, n_estimators=200;, score=0.698 total time=   4.1s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, n_estimators=300;, score=0.694 total time=   6.2s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.697 total time=   3.6s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.702 total time=   7.3s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.692 total time=  11.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=log2, n_estimators=100;, score=0.691 total time=   3.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=log2, n_estimators=200;, score=0.699 total time=   6.9s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=log2, n_estimators=300;, score=0.692 total time=  10.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.689 total time=   6.1s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.698 total time=  12.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.681 total time=  18.6s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=log2, n_estimators=100;, score=0.676 total time=   6.2s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=log2, n_estimators=200;, score=0.679 total time=  12.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=log2, n_estimators=300;, score=0.694 total time=  18.7s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.682 total time=  10.6s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.689 total time=  21.2s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.705 total time=  32.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "54 fits failed out of a total of 162.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.61832061 0.66183206 0.67862595 0.62824427 0.6740458  0.68320611\n",
      " 0.64885496 0.67328244 0.69312977 0.66793893 0.68473282 0.69160305\n",
      " 0.67099237 0.68931298 0.70381679 0.66870229 0.68931298 0.70381679\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.62061069 0.6610687  0.67862595 0.62290076 0.67251908 0.68015267\n",
      " 0.64198473 0.68091603 0.69160305 0.6610687  0.69160305 0.69007634\n",
      " 0.67175573 0.69236641 0.69007634 0.66717557 0.68396947 0.69618321\n",
      " 0.69770992 0.69694656 0.70305344 0.68549618 0.69236641 0.70229008\n",
      " 0.6870229  0.69083969 0.69541985 0.70381679 0.70305344 0.7\n",
      " 0.69236641 0.69236641 0.68625954 0.68473282 0.69541985 0.69618321\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.68854962 0.69541985 0.69847328 0.70076336 0.69618321 0.69083969\n",
      " 0.69236641 0.69923664 0.69694656 0.69923664 0.69847328 0.68931298\n",
      " 0.69236641 0.68931298 0.69694656 0.69618321 0.68854962 0.69847328\n",
      " 0.69312977 0.70381679 0.7        0.69694656 0.69312977 0.69007634\n",
      " 0.69694656 0.68625954 0.68854962 0.69236641 0.68549618 0.68854962\n",
      " 0.68549618 0.68854962 0.69618321 0.68778626 0.68396947 0.6870229\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.7        0.69847328 0.69389313 0.69694656 0.70152672 0.69236641\n",
      " 0.69083969 0.69923664 0.69160305 0.68931298 0.69847328 0.68091603\n",
      " 0.67633588 0.67938931 0.69389313 0.68244275 0.68931298 0.70534351]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 300}\n",
      "Accuracy: 66.39\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.49      0.53      2224\n",
      "           1       0.70      0.78      0.74      3388\n",
      "\n",
      "    accuracy                           0.66      5612\n",
      "   macro avg       0.65      0.63      0.64      5612\n",
      "weighted avg       0.66      0.66      0.66      5612\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1082 1142]\n",
      " [ 744 2644]]\n",
      "----- Span: 7 -----\n",
      "11907 train examples\n",
      "5104 test examples\n",
      "Fitting 1 folds for each of 162 candidates, totalling 162 fits\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, n_estimators=100;, score=0.631 total time=   1.9s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, n_estimators=200;, score=0.676 total time=   3.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, n_estimators=300;, score=0.683 total time=   5.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.646 total time=   3.4s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.678 total time=   6.9s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.678 total time=  10.3s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=0.665 total time=   3.3s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=0.680 total time=   6.6s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, n_estimators=300;, score=0.679 total time=   9.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.661 total time=   5.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.683 total time=  11.7s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.686 total time=  17.4s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, n_estimators=100;, score=0.668 total time=   6.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, n_estimators=200;, score=0.685 total time=  12.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, n_estimators=300;, score=0.686 total time=  17.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.671 total time=  10.1s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.683 total time=  20.1s\n",
      "[CV 1/1] END learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.692 total time=  30.2s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, n_estimators=100;, score=0.628 total time=   1.9s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, n_estimators=200;, score=0.668 total time=   3.9s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, n_estimators=300;, score=0.681 total time=   5.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.641 total time=   3.4s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.682 total time=   6.9s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.683 total time=  10.3s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, n_estimators=100;, score=0.652 total time=   3.2s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, n_estimators=200;, score=0.681 total time=   6.5s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, n_estimators=300;, score=0.687 total time=   9.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.668 total time=   5.8s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.676 total time=  11.6s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.688 total time=  17.3s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=log2, n_estimators=100;, score=0.671 total time=   6.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=log2, n_estimators=200;, score=0.681 total time=  12.0s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=log2, n_estimators=300;, score=0.689 total time=  17.9s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.678 total time=  10.1s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.684 total time=  20.1s\n",
      "[CV 1/1] END learning_rate=0.01, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.693 total time=  30.4s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=log2, n_estimators=100;, score=0.678 total time=   1.9s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=log2, n_estimators=200;, score=0.700 total time=   3.8s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=log2, n_estimators=300;, score=0.682 total time=   5.7s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.691 total time=   3.4s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.696 total time=   6.8s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.697 total time=  10.3s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=0.688 total time=   3.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=0.693 total time=   6.4s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=log2, n_estimators=300;, score=0.689 total time=   9.7s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.683 total time=   5.7s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.686 total time=  11.5s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.682 total time=  17.1s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=log2, n_estimators=100;, score=0.684 total time=   5.8s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=log2, n_estimators=200;, score=0.695 total time=  11.4s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=log2, n_estimators=300;, score=0.699 total time=  17.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.689 total time=   9.9s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.673 total time=  19.4s\n",
      "[CV 1/1] END learning_rate=0.05, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.682 total time=  29.3s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=100;, score=0.688 total time=   1.9s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=200;, score=0.692 total time=   3.8s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=300;, score=0.694 total time=   5.8s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.683 total time=   3.4s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.691 total time=   6.9s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.694 total time=  10.3s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=100;, score=0.690 total time=   3.3s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=200;, score=0.683 total time=   6.5s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=300;, score=0.691 total time=   9.8s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.688 total time=   5.8s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.696 total time=  11.5s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.688 total time=  17.2s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=log2, n_estimators=100;, score=0.690 total time=   5.8s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=log2, n_estimators=200;, score=0.696 total time=  11.6s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=log2, n_estimators=300;, score=0.673 total time=  17.4s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.689 total time=  10.0s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.681 total time=  19.7s\n",
      "[CV 1/1] END learning_rate=0.05, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.698 total time=  29.7s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, n_estimators=100;, score=0.696 total time=   1.9s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, n_estimators=200;, score=0.697 total time=   3.8s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, n_estimators=300;, score=0.694 total time=   5.7s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.688 total time=   3.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.693 total time=   6.8s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.683 total time=  10.2s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=0.698 total time=   3.2s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=0.687 total time=   6.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, n_estimators=300;, score=0.678 total time=   9.7s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.702 total time=   5.7s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.673 total time=  11.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.686 total time=  17.1s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, n_estimators=100;, score=0.673 total time=   5.7s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, n_estimators=200;, score=0.686 total time=  11.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, n_estimators=300;, score=0.680 total time=  17.2s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.673 total time=   9.8s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.683 total time=  19.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.683 total time=  29.5s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=log2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=log2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=log2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=deviance, max_depth=8, max_features=sqrt, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, n_estimators=100;, score=0.684 total time=   1.9s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, n_estimators=200;, score=0.694 total time=   3.8s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, n_estimators=300;, score=0.687 total time=   5.7s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100;, score=0.689 total time=   3.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200;, score=0.684 total time=   6.8s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300;, score=0.689 total time=  10.2s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=log2, n_estimators=100;, score=0.692 total time=   3.2s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=log2, n_estimators=200;, score=0.686 total time=   6.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=log2, n_estimators=300;, score=0.695 total time=   9.7s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100;, score=0.684 total time=   5.7s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.686 total time=  11.4s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300;, score=0.680 total time=  17.3s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=log2, n_estimators=100;, score=0.692 total time=   5.8s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=log2, n_estimators=200;, score=0.694 total time=  11.5s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=log2, n_estimators=300;, score=0.690 total time=  17.2s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=100;, score=0.683 total time=   9.8s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.669 total time=  19.7s\n",
      "[CV 1/1] END learning_rate=0.1, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=300;, score=0.683 total time=  29.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "54 fits failed out of a total of 162.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.63056255 0.6759026  0.68261965 0.6456759  0.67758186 0.67758186\n",
      " 0.66498741 0.68010076 0.67926113 0.66078925 0.68345928 0.68597817\n",
      " 0.6675063  0.68513854 0.68597817 0.67086482 0.68345928 0.69185558\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.62804366 0.6675063  0.68094039 0.64063812 0.68178002 0.68345928\n",
      " 0.65239295 0.68094039 0.6868178  0.66834593 0.6759026  0.68849706\n",
      " 0.67086482 0.68094039 0.68933669 0.67758186 0.68429891 0.69269521\n",
      " 0.67758186 0.70025189 0.68178002 0.69101595 0.69605374 0.69689337\n",
      " 0.68849706 0.69269521 0.68933669 0.68345928 0.68597817 0.68178002\n",
      " 0.68429891 0.69521411 0.69857263 0.68933669 0.67254408 0.68178002\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.68765743 0.69185558 0.69353484 0.68261965 0.69101595 0.69437448\n",
      " 0.69017632 0.68345928 0.69101595 0.68765743 0.69605374 0.68765743\n",
      " 0.69017632 0.69605374 0.67338371 0.68933669 0.68094039 0.697733\n",
      " 0.69605374 0.69689337 0.69437448 0.68849706 0.69269521 0.68345928\n",
      " 0.697733   0.6868178  0.67758186 0.70193115 0.67338371 0.68597817\n",
      " 0.67338371 0.68597817 0.68010076 0.67254408 0.68345928 0.68261965\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.68429891 0.69353484 0.6868178  0.68933669 0.68429891 0.68933669\n",
      " 0.69185558 0.68597817 0.69521411 0.68429891 0.68597817 0.68010076\n",
      " 0.69185558 0.69437448 0.69017632 0.68261965 0.66918556 0.68345928]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "Accuracy: 68.01\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.50      0.56      2060\n",
      "           1       0.70      0.80      0.75      3044\n",
      "\n",
      "    accuracy                           0.68      5104\n",
      "   macro avg       0.67      0.65      0.65      5104\n",
      "weighted avg       0.67      0.68      0.67      5104\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1033 1027]\n",
      " [ 606 2438]]\n"
     ]
    }
   ],
   "source": [
    "# Define the Random Forest model\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'loss': ['log_loss', 'deviance', 'exponential'],  # Loss function\n",
    "    'learning_rate': [0.01, 0.05, 0.1],  # Learning rate (eta)\n",
    "    'max_depth': [3, 5, 8],  # Maximum depth of each tree\n",
    "    'max_features': ['log2', 'sqrt'],  # Maximum number of features considered for splitting\n",
    "    'n_estimators': [100, 200, 300]  # Number of trees\n",
    "}\n",
    "\n",
    "filename = 'gradient_boosting.pkl'\n",
    "\n",
    "train_test_save(gbc, param_grid, filename, n_splits=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Span: 3 -----\n",
      "14373 train examples\n",
      "6160 test examples\n",
      "Fitting 1 folds for each of 120 candidates, totalling 120 fits\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.660 total time=   1.9s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.698 total time=   3.4s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.689 total time=   2.9s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.707 total time=   2.1s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.679 total time=   4.3s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.706 total time=   2.3s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.608 total time=   1.4s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.586 total time=   1.1s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.666 total time=   1.7s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.667 total time=   2.9s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.695 total time=   4.6s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.586 total time=   3.2s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.702 total time=   5.0s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.699 total time=   4.6s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.615 total time=   3.5s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.668 total time=   2.4s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.682 total time=   4.3s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.674 total time=   2.0s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.677 total time=   1.9s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.660 total time=   3.8s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.684 total time=   4.0s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.597 total time=   2.2s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.704 total time=   4.0s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.664 total time=   2.6s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.701 total time=   2.1s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.706 total time=   5.6s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.671 total time=   2.4s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.595 total time=   4.6s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.690 total time=   3.2s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.682 total time=   2.4s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.668 total time=   3.2s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.707 total time=   2.1s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.707 total time=   1.6s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.696 total time=   1.3s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.672 total time=   1.4s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.693 total time=   2.2s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.681 total time=   1.5s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.701 total time=   2.2s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.666 total time=   1.7s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.602 total time=   2.3s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.695 total time=   3.0s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.645 total time=   4.1s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.701 total time=   2.0s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.663 total time=   4.7s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.667 total time=   4.7s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.678 total time=   2.6s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.659 total time=   2.3s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.615 total time=   2.3s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.698 total time=   1.9s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.711 total time=   1.6s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.706 total time=   2.4s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.651 total time=   1.4s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.715 total time=   1.3s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.709 total time=   2.0s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.667 total time=   2.2s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.697 total time=   2.2s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.691 total time=   1.6s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.674 total time=   2.8s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.696 total time=   1.7s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.591 total time=   4.5s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.695 total time=   2.5s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.586 total time=   0.4s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.586 total time=   0.5s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.691 total time=   1.7s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.586 total time=   0.4s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.586 total time=   0.4s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.698 total time=   3.1s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.682 total time=   3.9s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.695 total time=   3.1s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.702 total time=   3.4s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.704 total time=   3.7s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.693 total time=   4.0s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.691 total time=   3.1s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.697 total time=   5.1s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.704 total time=   5.8s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.586 total time=   0.4s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.671 total time=   3.1s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.704 total time=   2.2s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.586 total time=   0.4s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.700 total time=   3.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.696 total time=   3.4s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.702 total time=   2.9s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.701 total time=   3.4s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.704 total time=   3.2s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.702 total time=   4.2s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.696 total time=   4.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.697 total time=   5.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.692 total time=   5.5s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.701 total time=   8.5s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.688 total time=   3.5s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.689 total time=   2.5s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.586 total time=   0.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.586 total time=   0.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.586 total time=   0.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.586 total time=   0.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.586 total time=   0.5s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.652 total time=   3.1s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.666 total time=   3.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.680 total time=   1.2s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.706 total time=   5.1s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.522 total time=   2.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.649 total time=   5.6s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.694 total time=   6.9s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.644 total time=   4.1s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.684 total time=   9.5s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.586 total time=   0.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.586 total time=   0.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.613 total time=   2.1s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.659 total time=   2.0s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.586 total time=   0.5s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.691 total time=   5.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.639 total time=   3.7s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.606 total time=   1.1s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.672 total time=   3.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.696 total time=   5.2s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.659 total time=   1.7s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.694 total time=   3.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.682 total time=   3.7s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.663 total time=   2.5s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.657 total time=   3.3s\n",
      "Best hyperparameters: {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': (45,), 'solver': 'sgd'}\n",
      "Accuracy: 67.06\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.49      0.55      2507\n",
      "           1       0.69      0.79      0.74      3653\n",
      "\n",
      "    accuracy                           0.67      6160\n",
      "   macro avg       0.66      0.64      0.64      6160\n",
      "weighted avg       0.66      0.67      0.66      6160\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1229 1278]\n",
      " [ 751 2902]]\n",
      "----- Span: 5 -----\n",
      "13093 train examples\n",
      "5612 test examples\n",
      "Fitting 1 folds for each of 120 candidates, totalling 120 fits\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.678 total time=   4.6s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.674 total time=   2.7s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.662 total time=   2.0s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.664 total time=   2.6s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.592 total time=   0.8s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.622 total time=   2.3s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.660 total time=   2.3s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.673 total time=   5.0s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.672 total time=   2.1s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.646 total time=   1.9s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.682 total time=   2.6s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.664 total time=   1.7s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.689 total time=   4.4s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.668 total time=   2.8s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.414 total time=   1.8s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.670 total time=   2.4s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.682 total time=   2.0s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.669 total time=   1.6s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.663 total time=   1.8s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.686 total time=   3.5s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.664 total time=   2.0s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.618 total time=   1.5s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.670 total time=   3.4s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.659 total time=   2.3s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.631 total time=   1.2s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.674 total time=   3.5s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.608 total time=   1.6s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.644 total time=   2.5s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.676 total time=   5.4s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.667 total time=   3.2s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.628 total time=   2.5s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.680 total time=   0.9s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.645 total time=   1.6s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.635 total time=   2.3s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.669 total time=   3.2s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.656 total time=   2.0s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.598 total time=   2.5s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.673 total time=   1.4s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.620 total time=   1.5s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.673 total time=   1.8s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.668 total time=   2.3s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.639 total time=   1.2s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.637 total time=   2.8s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.670 total time=   1.9s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.666 total time=   2.4s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.575 total time=   2.5s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.676 total time=   1.7s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.656 total time=   1.4s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.656 total time=   1.7s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.672 total time=   1.4s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.672 total time=   1.3s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.667 total time=   2.5s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.670 total time=   1.1s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.616 total time=   1.1s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.674 total time=   2.0s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.666 total time=   2.1s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.611 total time=   2.2s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.482 total time=   3.1s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.668 total time=   3.5s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.572 total time=   3.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.675 total time=   2.1s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.662 total time=   1.9s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.672 total time=   2.7s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.675 total time=   3.2s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.677 total time=   2.7s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.651 total time=   2.5s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.672 total time=   1.3s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.660 total time=   4.3s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.676 total time=   4.5s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.661 total time=   2.5s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.675 total time=   2.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.673 total time=   2.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.659 total time=   3.7s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.673 total time=   5.3s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.644 total time=   3.3s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.675 total time=   2.5s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.668 total time=   2.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.671 total time=   2.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.674 total time=   2.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.676 total time=   2.9s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.650 total time=   2.8s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.666 total time=   2.3s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.667 total time=   2.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.686 total time=   1.9s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.640 total time=   2.3s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.681 total time=   4.2s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.670 total time=   1.2s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.659 total time=   2.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.673 total time=   7.8s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.671 total time=   3.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.592 total time=   0.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.592 total time=   0.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.592 total time=   0.5s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.592 total time=   0.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.665 total time=   1.8s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.607 total time=   3.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.637 total time=   1.0s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.627 total time=   1.2s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.586 total time=   2.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.603 total time=   4.1s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.657 total time=   3.1s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.643 total time=   3.2s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.645 total time=   5.6s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.641 total time=   1.6s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.671 total time=   4.6s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.554 total time=   1.5s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.592 total time=   0.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.592 total time=   0.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.635 total time=   2.2s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.592 total time=   0.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.592 total time=   0.6s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.634 total time=   2.7s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.637 total time=   1.1s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.655 total time=   2.6s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.669 total time=   4.1s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.653 total time=   1.2s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.673 total time=   3.6s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.629 total time=   4.8s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.639 total time=   2.6s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.608 total time=   5.4s\n",
      "Best hyperparameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (181,), 'solver': 'adam'}\n",
      "Accuracy: 68.09\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.38      0.49      2224\n",
      "           1       0.68      0.88      0.77      3388\n",
      "\n",
      "    accuracy                           0.68      5612\n",
      "   macro avg       0.68      0.63      0.63      5612\n",
      "weighted avg       0.68      0.68      0.66      5612\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 844 1380]\n",
      " [ 411 2977]]\n",
      "----- Span: 7 -----\n",
      "11907 train examples\n",
      "5104 test examples\n",
      "Fitting 1 folds for each of 120 candidates, totalling 120 fits\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.622 total time=   1.6s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.560 total time=   0.3s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.670 total time=   1.7s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.626 total time=   1.6s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.560 total time=   0.7s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.646 total time=   2.3s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.605 total time=   1.9s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.663 total time=   1.8s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.657 total time=   1.8s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.588 total time=   2.2s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.668 total time=   6.0s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.641 total time=   1.8s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.585 total time=   2.1s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.668 total time=   4.8s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.655 total time=   1.8s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.649 total time=   1.7s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.669 total time=   2.3s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.658 total time=   2.9s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.622 total time=   1.5s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.665 total time=   2.2s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.631 total time=   1.9s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.666 total time=   2.0s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.560 total time=   0.8s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.594 total time=   1.4s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.553 total time=   1.4s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.668 total time=   2.3s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.597 total time=   2.7s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.653 total time=   4.7s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.652 total time=   2.7s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.609 total time=   1.9s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.636 total time=   1.2s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.658 total time=   1.3s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.607 total time=   1.5s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.623 total time=   1.4s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.673 total time=   1.2s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.577 total time=   1.7s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.666 total time=   2.0s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.669 total time=   1.7s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.629 total time=   1.0s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.641 total time=   2.9s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.654 total time=   1.3s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.631 total time=   2.0s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.460 total time=   1.7s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.654 total time=   2.7s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.482 total time=   2.2s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.646 total time=   2.0s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.657 total time=   1.4s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.595 total time=   1.6s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.594 total time=   1.7s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.637 total time=   1.2s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.642 total time=   1.1s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.550 total time=   1.3s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.635 total time=   1.1s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.563 total time=   2.0s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.656 total time=   1.6s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.674 total time=   2.9s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.658 total time=   0.8s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.625 total time=   1.8s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.672 total time=   3.3s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.646 total time=   4.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.560 total time=   0.3s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.560 total time=   0.3s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.560 total time=   0.3s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.560 total time=   0.4s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.656 total time=   2.4s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.662 total time=   1.8s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.656 total time=   1.7s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.626 total time=   4.2s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.669 total time=   2.5s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.662 total time=   2.9s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.673 total time=   2.4s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.666 total time=   2.7s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.653 total time=   3.9s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.669 total time=   4.1s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.672 total time=   2.1s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.664 total time=   1.9s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.641 total time=   2.1s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.661 total time=   2.5s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.665 total time=   2.0s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.662 total time=   2.4s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.658 total time=   2.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.672 total time=   2.2s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.640 total time=   1.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.660 total time=   2.3s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.660 total time=   1.3s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.670 total time=   4.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.657 total time=   2.2s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.658 total time=   2.7s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.657 total time=   5.7s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.652 total time=   3.5s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.626 total time=   2.9s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.669 total time=   1.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.560 total time=   0.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.645 total time=   1.8s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.560 total time=   0.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.638 total time=   2.0s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.634 total time=   1.7s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.668 total time=   1.8s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.654 total time=   2.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.659 total time=   1.9s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.668 total time=   1.1s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.560 total time=   0.6s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.646 total time=   3.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.652 total time=   2.6s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.639 total time=   4.1s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.560 total time=   0.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.675 total time=   1.6s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.560 total time=   1.5s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.662 total time=   1.6s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.560 total time=   0.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.633 total time=   1.8s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.636 total time=   0.8s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.631 total time=   1.6s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.560 total time=   0.7s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.652 total time=   3.5s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.661 total time=   1.9s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.632 total time=   2.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.635 total time=   4.7s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.667 total time=   2.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.646 total time=   3.3s\n",
      "Best hyperparameters: {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (12,), 'solver': 'sgd'}\n",
      "Accuracy: 59.64\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2060\n",
      "           1       0.60      1.00      0.75      3044\n",
      "\n",
      "    accuracy                           0.60      5104\n",
      "   macro avg       0.30      0.50      0.37      5104\n",
      "weighted avg       0.36      0.60      0.45      5104\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[   0 2060]\n",
      " [   0 3044]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Define the MLP model\n",
    "mlp_model = MLPClassifier()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(12,), (23,), (45,), (91,), (181,)],  # Vary the number of neurons in the hidden layer\n",
    "    'activation': ['relu', 'identity', 'logistic', 'tanh'],  # Vary the activation function\n",
    "    'solver': ['adam', 'sgd', 'adam'],  # Vary the solver\n",
    "    'alpha': [0.0001, 0.001],  # Vary the L2 regularization strength\n",
    "}\n",
    "\n",
    "filename = 'multilayer_perceptron.pkl'\n",
    "\n",
    "train_test_save(mlp_model, param_grid, filename, n_splits=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Span: 7 -----\n",
      "11907 train examples\n",
      "5104 test examples\n",
      "Fitting 1 folds for each of 120 candidates, totalling 120 fits\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.667 total time=   2.5s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.594 total time=   0.6s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.663 total time=   2.9s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.688 total time=   1.6s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.682 total time=   3.2s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.676 total time=   1.3s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.664 total time=   1.1s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.594 total time=   0.6s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.664 total time=   2.0s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.679 total time=   2.3s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.643 total time=   3.1s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.678 total time=   3.4s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.684 total time=   2.6s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.661 total time=   2.6s\n",
      "[CV 1/1] END activation=relu, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.601 total time=   2.0s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.631 total time=   1.5s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.683 total time=   2.1s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.652 total time=   1.9s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.656 total time=   1.6s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.594 total time=   0.3s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.680 total time=   2.0s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.694 total time=   3.0s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.680 total time=   4.1s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.671 total time=   1.5s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.662 total time=   1.2s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.677 total time=   5.5s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.678 total time=   2.9s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.647 total time=   2.7s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.685 total time=   3.3s\n",
      "[CV 1/1] END activation=relu, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.644 total time=   2.8s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.652 total time=   2.4s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.674 total time=   1.7s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.652 total time=   1.4s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.624 total time=   1.6s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.683 total time=   1.0s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.622 total time=   1.7s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.673 total time=   1.5s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.688 total time=   0.5s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.673 total time=   1.4s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.652 total time=   1.0s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.685 total time=   1.8s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.610 total time=   0.9s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.626 total time=   2.2s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.683 total time=   2.5s\n",
      "[CV 1/1] END activation=identity, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.685 total time=   2.1s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.641 total time=   1.1s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.688 total time=   0.8s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.655 total time=   1.7s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.659 total time=   1.6s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.685 total time=   1.6s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.685 total time=   2.1s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.596 total time=   1.1s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.664 total time=   1.8s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.543 total time=   1.4s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.614 total time=   2.7s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.689 total time=   1.7s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.657 total time=   1.0s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.666 total time=   2.5s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.694 total time=   2.8s\n",
      "[CV 1/1] END activation=identity, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.500 total time=   3.1s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.594 total time=   0.3s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.639 total time=   2.5s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.663 total time=   1.7s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.666 total time=   2.1s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.678 total time=   3.0s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.687 total time=   1.2s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.688 total time=   2.4s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.678 total time=   2.4s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.670 total time=   1.3s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.681 total time=   2.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.678 total time=   3.3s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.647 total time=   1.9s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.678 total time=   3.4s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.673 total time=   5.1s\n",
      "[CV 1/1] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.683 total time=   3.5s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.675 total time=   2.4s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.681 total time=   1.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.594 total time=   0.3s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.670 total time=   1.8s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.682 total time=   2.1s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.689 total time=   1.4s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.691 total time=   2.3s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.684 total time=   2.2s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.683 total time=   1.8s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.683 total time=   4.1s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.683 total time=   3.6s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.672 total time=   2.4s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.688 total time=   1.9s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.686 total time=   6.5s\n",
      "[CV 1/1] END activation=logistic, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.692 total time=   4.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.594 total time=   0.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(12,), solver=sgd;, score=0.673 total time=   1.0s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(12,), solver=adam;, score=0.594 total time=   0.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.594 total time=   0.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(23,), solver=sgd;, score=0.594 total time=   0.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(23,), solver=adam;, score=0.662 total time=   1.1s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.662 total time=   2.5s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(45,), solver=sgd;, score=0.563 total time=   1.0s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(45,), solver=adam;, score=0.671 total time=   2.1s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.652 total time=   1.2s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(91,), solver=sgd;, score=0.677 total time=   1.6s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(91,), solver=adam;, score=0.682 total time=   1.6s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.688 total time=   1.7s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(181,), solver=sgd;, score=0.679 total time=   2.9s\n",
      "[CV 1/1] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(181,), solver=adam;, score=0.624 total time=   2.2s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.594 total time=   0.3s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(12,), solver=sgd;, score=0.626 total time=   1.1s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(12,), solver=adam;, score=0.594 total time=   0.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.669 total time=   3.1s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(23,), solver=sgd;, score=0.604 total time=   1.2s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(23,), solver=adam;, score=0.606 total time=   0.7s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.594 total time=   0.7s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(45,), solver=sgd;, score=0.681 total time=   1.6s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(45,), solver=adam;, score=0.594 total time=   0.8s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.659 total time=   2.8s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(91,), solver=sgd;, score=0.666 total time=   1.7s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(91,), solver=adam;, score=0.682 total time=   1.4s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.655 total time=   1.1s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(181,), solver=sgd;, score=0.623 total time=   3.2s\n",
      "[CV 1/1] END activation=tanh, alpha=0.001, hidden_layer_sizes=(181,), solver=adam;, score=0.646 total time=   1.9s\n",
      "Best hyperparameters: {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (45,), 'solver': 'adam'}\n",
      "Accuracy: 65.85\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.23      0.35      2060\n",
      "           1       0.64      0.95      0.77      3044\n",
      "\n",
      "    accuracy                           0.66      5104\n",
      "   macro avg       0.70      0.59      0.56      5104\n",
      "weighted avg       0.69      0.66      0.60      5104\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 464 1596]\n",
      " [ 147 2897]]\n"
     ]
    }
   ],
   "source": [
    "# retrain 7 span\n",
    "train_test_save(mlp_model, param_grid, filename, n_splits=1, spans=[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Server testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3span_gradient_boosting.pkl', '3span_knn_model.pkl', '3span_logistic_regression_model.pkl', '3span_multilayer_perceptron.pkl', '3span_random_forest.pkl', '3span_support_vector_machine_model.pkl', '5span_gradient_boosting.pkl', '5span_knn_model.pkl', '5span_logistic_regression_model.pkl', '5span_multilayer_perceptron.pkl', '5span_random_forest.pkl', '5span_support_vector_machine_model.pkl', '7span_gradient_boosting.pkl', '7span_knn_model.pkl', '7span_logistic_regression_model.pkl', '7span_multilayer_perceptron.pkl', '7span_random_forest.pkl', '7span_support_vector_machine_model.pkl']\n",
      "[1]\n",
      "[[0.14285714 0.85714286]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mtayl\\anaconda3\\envs\\mlmb-model-env\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "mens_model_dir, womens_model_dir = os.path.join(\"../model/mens/\"), os.path.join(\"../model/womens/\")\n",
    "mens_filenames, womens_filenames = [filename for filename in os.listdir(mens_model_dir)], [filename for filename in os.listdir(womens_model_dir)]\n",
    "mens_models, womens_models = {filename.split('.pkl')[0]: joblib.load(f'{mens_model_dir}{filename}') for filename in mens_filenames}, {filename.split('.pkl')[0]: joblib.load(f'{womens_model_dir}{filename}') for filename in womens_filenames}\n",
    "print(mens_filenames)\n",
    "\n",
    "payload = [{\n",
    "    'model': '3span_knn_model',\n",
    "    'isWomens': False,\n",
    "    'team1': [\n",
    "          27.33333333333333,\n",
    "          26.393939393939394,\n",
    "          26.58692363323644,\n",
    "          58.0,\n",
    "          56.90909090909091,\n",
    "          56.277424356201664,\n",
    "          0.4713333333333332,\n",
    "          0.4665757575757576,\n",
    "          0.4721426885365508,\n",
    "          10.333333333333334,\n",
    "          7.090909090909091,\n",
    "          10.582568880636243,\n",
    "          23.666666666666668,\n",
    "          20.03030303030303,\n",
    "          22.62090914323926,\n",
    "          0.4343333333333333,\n",
    "          0.3542424242424242,\n",
    "          0.4643407699386589,\n",
    "          10.666666666666666,\n",
    "          14.787878787878787,\n",
    "          11.464159086113796,\n",
    "          14.333333333333334,\n",
    "          19.51515151515152,\n",
    "          16.123824953334406,\n",
    "          0.757,\n",
    "          0.7663333333333334,\n",
    "          0.7228634019719903,\n",
    "          6.666666666666667,\n",
    "          8.575757575757576,\n",
    "          6.452909055864438,\n",
    "          29.0,\n",
    "          30.939393939393938,\n",
    "          30.71948037599213,\n",
    "          16.666666666666668,\n",
    "          12.424242424242424,\n",
    "          16.448066715849563,\n",
    "          7.333333333333333,\n",
    "          6.151515151515151,\n",
    "          6.840419095475227,\n",
    "          1.6666666666666667,\n",
    "          1.6666666666666667,\n",
    "          2.218273723265156,\n",
    "          9.666666666666666,\n",
    "          9.424242424242424,\n",
    "          9.69409596431069,\n",
    "          17.666666666666668,\n",
    "          15.969696969696969,\n",
    "          17.0706839885097,\n",
    "          113.7,\n",
    "          111.4060606060606,\n",
    "          113.3470722494647,\n",
    "          97.56666666666666,\n",
    "          102.3939393939394,\n",
    "          95.66693762349897,\n",
    "          66.53333333333335,\n",
    "          66.7,\n",
    "          66.28398357145488,\n",
    "          0.2516666666666666,\n",
    "          0.3579393939393939,\n",
    "          0.2917529405199457,\n",
    "          0.409,\n",
    "          0.3535151515151515,\n",
    "          0.4035162461462896,\n",
    "          0.585,\n",
    "          0.5660000000000001,\n",
    "          0.5887726908712647,\n",
    "          51.7,\n",
    "          53.23030303030303,\n",
    "          53.63034644359723,\n",
    "          60.03333333333333,\n",
    "          46.83030303030304,\n",
    "          61.26416795952245,\n",
    "          11.0,\n",
    "          9.190909090909091,\n",
    "          10.294132525194437,\n",
    "          4.966666666666668,\n",
    "          4.578787878787878,\n",
    "          6.817281067278236,\n",
    "          0.5613333333333334,\n",
    "          0.5293030303030303,\n",
    "          0.5664465686886107,\n",
    "          12.933333333333332,\n",
    "          12.412121212121212,\n",
    "          13.108024106733502,\n",
    "          26.066666666666663,\n",
    "          29.1,\n",
    "          24.82206351116765,\n",
    "          0.186,\n",
    "          0.272030303030303,\n",
    "          0.2067422204576433\n",
    "        ],\n",
    "    'team2': [\n",
    "          25.666666666666668,\n",
    "          28.6875,\n",
    "          24.59661942813545,\n",
    "          55.333333333333336,\n",
    "          58.625,\n",
    "          54.18251581070945,\n",
    "          0.4630000000000001,\n",
    "          0.4889375,\n",
    "          0.4534812509915791,\n",
    "          7.666666666666667,\n",
    "          8.4375,\n",
    "          6.992306689731777,\n",
    "          16.0,\n",
    "          20.5625,\n",
    "          16.076059906743467,\n",
    "          0.4733333333333333,\n",
    "          0.406125,\n",
    "          0.4282937919711694,\n",
    "          15.0,\n",
    "          17.84375,\n",
    "          16.7495296751149,\n",
    "          20.666666666666668,\n",
    "          24.78125,\n",
    "          23.68396619334817,\n",
    "          0.7303333333333333,\n",
    "          0.7280625000000001,\n",
    "          0.7151780618028716,\n",
    "          9.0,\n",
    "          11.09375,\n",
    "          8.591873774304986,\n",
    "          31.33333333333333,\n",
    "          37.65625,\n",
    "          31.69479167787358,\n",
    "          20.0,\n",
    "          18.40625,\n",
    "          19.331843585707247,\n",
    "          5.666666666666667,\n",
    "          5.75,\n",
    "          6.041198720224202,\n",
    "          2.6666666666666665,\n",
    "          3.75,\n",
    "          2.86770398914814,\n",
    "          10.666666666666666,\n",
    "          10.84375,\n",
    "          10.759370770305395,\n",
    "          17.0,\n",
    "          14.28125,\n",
    "          16.808736738283187,\n",
    "          110.06666666666666,\n",
    "          118.73125,\n",
    "          108.0258174452465,\n",
    "          100.63333333333333,\n",
    "          99.56875,\n",
    "          98.5662613492459,\n",
    "          67.3,\n",
    "          69.8875,\n",
    "          67.62328939689323,\n",
    "          0.3793333333333333,\n",
    "          0.42921875,\n",
    "          0.4423435214064084,\n",
    "          0.2903333333333334,\n",
    "          0.35075,\n",
    "          0.2971660725474357,\n",
    "          0.5686666666666667,\n",
    "          0.5944375,\n",
    "          0.5581987138292752,\n",
    "          53.13333333333333,\n",
    "          58.196875,\n",
    "          51.86511530568824,\n",
    "          78.7333333333333,\n",
    "          63.640625,\n",
    "          79.51162182725966,\n",
    "          8.433333333333335,\n",
    "          8.103125,\n",
    "          8.951511404290795,\n",
    "          6.666666666666665,\n",
    "          9.65,\n",
    "          6.993118633283302,\n",
    "          0.5316666666666666,\n",
    "          0.560875,\n",
    "          0.5177487884066068,\n",
    "          14.033333333333337,\n",
    "          13.38125,\n",
    "          14.102322203852236,\n",
    "          33.7,\n",
    "          36.621875,\n",
    "          31.172773850290103,\n",
    "          0.276,\n",
    "          0.30946875,\n",
    "          0.3132329415972344\n",
    "        ],\n",
    "    'isNeutral': False\n",
    "}]\n",
    "\n",
    "results = []\n",
    "for matchup in payload:\n",
    "    input = np.array([matchup['team2'] + matchup['team1'] + [int(matchup['isNeutral'])]])\n",
    "    models = mens_models if not matchup['isWomens'] else womens_models\n",
    "    model = models[matchup['model']]\n",
    "    print(model.predict(input))\n",
    "    print(model.predict_proba(input))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlmb-utils",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
